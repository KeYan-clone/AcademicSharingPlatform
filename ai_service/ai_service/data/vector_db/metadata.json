{
  "contents": [
    "项目8 TensorFlow Lite",
    "项目描述",
    "TensorFlow生态系统有着丰富的工具链，TensorFlow Serving是使用广泛的高性能的服务器端部署平台，TensorFlow.js支持使用JavaScript在浏览器端部署，TensorFlow Lite加速了端侧机器学习的发展，它支持Android、IOS、嵌入式设备、以及极小的MCU设备。全球超过40亿设备部署了TensorFlow Lite，谷歌、Uber、网易、爱奇艺、腾讯等公司的应用都使用了TensorFlow Lite。",
    "本项目为一个图像识别项目，基于TensorFlow Lite，优化MobileNet模型并在Android手机上实现识别四种花的种类，掌握如何通过相应工具将模型转化成适合手机设备的格式，并在Android应用中部署转换后的模型。",
    "项目目标",
    "知识目标",
    "了解TensorFlow Lite的发展历史",
    "了解TTensorFlow Lite的应用",
    "掌握TensorFlow Lite的整体架构",
    "掌握TensorFlow Lite转换器作用",
    "掌握FlatBuffers格式",
    "掌握TensorFlow Lite解释执行器特点及工作过程",
    "技能目标",
    "能通过相应工具将模型转化",
    "能在Android应用中部署转换后的模型",
    "能熟练Android Studio",
    "能配置build.gradle构建项目",
    "能熟练掌握迁移学习改造模型，开发相应AI应用",
    "8.1 认识TensorFlow Lite",
    "2015 年底Google 开源了端到端的机器学习开源框架 TensorFlow，它既支持大规模的模型训练，也支持各种环境的部署，包括服务器和移动端的部署，支持各种语言，包括 Python，C++，Java，Swift 甚至 Javascript。而近年来移动化浪潮和交互方式的改变，使得机器学习技术开发也在朝着轻量化的端侧发展，TensorFlow 团队又在 2017 年底上线了 TensorFlow Lite，一个轻量、快速、兼容度高的专门针对移动式应用场景的深度学习工具，把移动端及 IoT 设备端的深度学习技术的门槛再次大大降低。",
    "8.1.1 TensorFlow Lite发展历史",
    "TFLite是在边缘设备上运行TensorFlow模型推理的官方框架，它跨平台运行，包括Android、iOS以及基于Linux的IoT设备和微控制器。",
    "伴随移动和 IoT 设备的普及，世界以超乎想象的方式存在被连接的可能，如今已有超过 32 亿的手机用户和 70 亿的联网 IoT 设备。而随着手机成本不断降低，并且随着微控制器（MCU）和微机电系统（MEMs）的发展，高性能低功耗的芯片使得“万物”智能具有了可能性。Google开始了TF Mobile项目，尝试简化TensorFlow并在移动设备上运行，它是一个缩减版的TensorFlow，简化了算子集，也缩小了运行库。",
    "TFMini是Google内部用于计算机视觉场景的解决方案，它提供了一些转换工具压缩模型，进行算子融合并生成代码。它将模型嵌入到二进制文件中，这样就可以在设备上运行和部署模型。TFMini针对移动设备做了很多优化，但在把模型嵌入到实际的二进制文件中时兼容性存在较大挑战，因此TFMini并没有成为通用的解决方案。",
    "基于TF Mobile的经验，也继承了TFMini和内部其他类似项目的很多优秀工作，Google设计了TFLite：",
    "1) 更轻量。TensorFlow Lite 二进制文件的大小约为 1 MB（针对 32 位 ARM build）；如果仅使用支持常见图像分类模型（InceptionV3 和 MobileNet）所需的运算符，TensorFlow Lite 二进制文件的大小不到 300 KB。",
    "2) 特别为各种端侧设备优化的算子库。",
    "3) 能够利用各种硬件加速。",
    "8.1.2 TensorFlow Lite的应用",
    "全球有超过40亿的设备上部署着TFLite，例如Google Assistant，Google Photos等、Uber、Airbnb、以及国内的许多大公司如网易、爱奇艺和WPS等，都在使用TFLite。端侧机器学习在图像、文本和语音等方面都有非常广泛应用。",
    "TensorFlow Lite能解决的问题越来越多元化，这带来了应用的大量繁荣。在移动应用方面，网易使用TFLite做OCR处理，爱奇艺使用TFLite来进行视频中的AR效果，而WPS用它来做一系列文字处理。图像和视频方面广泛应用，比如Google Photos，Google Arts & Culture。",
    "离线语音识别方面有很多突破，比如Google Assistant宣布了完全基于神经网络的移动端语音识别，效果和服务器端十分接近，服务器模型需要2 GB大小，而手机端只需要80 MB。端侧语音识别非常有挑战，它的进展代表着端侧机器学习时代的逐步到来.一方面依赖于算法的提高，另外一方面TFLite框架的高性能和模型优化工具也起到了很重要的作用。Google Pixel 4手机上发布了Live Caption，自动把视频和对话中的语言转化为文字，大大提高了有听力障碍人群的体验。另外一方面，模型越来越小，无处不再，Google Assistant的语音功能部署在非常多元的设备上，比如手机端、手表、车载和智能音箱上，全球超过10亿设备。",
    "TFLite可以支持微控制器(MCU)，可以应用于IoT领域，MCU是单一芯片的小型计算机，没有操作系统，只有内存，也许内存只有几十KB。TFLite发布了若干MCU上可运行的模型，比如识别若干关键词的语音识别模型和简单的姿态检测模型，模型大小都只有20 KB左右，基于此可构建更智能的IoT应用，例如出门问问智能音箱使用TFLite来做热词唤醒，科沃斯扫地机器人使用TFLite在室内避开障碍物。如何让用户用更少的时间进行清扫工作是科沃斯不断追求的目标，它使用了机器视觉的帮助，可以识别这个过程中的一些障碍物，选择了用 TensorFlow Lite 部署深度神经网络，将推理速度提高了 30%，提高了用户的体验。",
    "TFLite也非常适合工业物联智能设备的开发，因为它很好地支持如树莓派及其他基于Linux SoC的工业自动化系统.创新奇智应用TFLite开发智能质检一体机、智能读码机等产品，应用到服装厂质检等场景",
    "8.2 TensorFlow Lite体系结构",
    "TensorFlow Lite 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。它支持设备端机器学习推断，延迟较低，并且二进制文件很小。",
    "8.2.1 TensorFlow Lite整体架构",
    "TensorFlow Lite 包括两个主要组件：",
    "TensorFlow Lite 解释器(Interpreter)",
    "TensorFlow Lite 转换器(Converter)",
    "算子库(Op kernels)",
    "硬件加速代理(Hardware accelerator delegate)",
    "TFLite采用更小的模型格式，并提供了方便的模型转换器，可将 TensorFlow 模型转换为方便解释器使用的格式，并可引入优化以减小二进制文件的大小和提高性能。比如SavedModel或GraphDef格式的TensorFlow模型，转换成TFLite专用的模型文件格式，在此过程中会进行算子融合和模型优化，以压缩模型，提高性能。",
    "TensorFlow Lite采用更小的解释器，可在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型。安卓应用只需 1 兆左右的运行环境，在 MCU 上甚至可以小于 100KB。",
    "TFLite算子库目前有130个左右，它与TensorFlow的核心算子库略有不同，并做了移动设备相关的优化。",
    "在硬件加速层面，对于 CPU 利用了 ARM 的 NEON 指令集做了大量的优化。同时，Lite 还可以利用手机上的加速器，比如 GPU 或者 DSP等。另外，最新的安卓系统提供了 Android 神经网络 API（Android NN API)，让硬件厂商可以扩展支持这样的接口。",
    "图8-1展示了在TensorFlow 2.0中TFLite模型转换过程，用户在自己的工作台中使用TensorFlow API构造TensorFlow模型，然后使用TFLite模型转换器转换成TFLite文件格式(FlatBuffers格式)。在设备端，TFLite解释器接受TFLite模型，调用不同的硬件加速器比如GPU进行执行。",
    "图8-1 TFLite模型转换过程",
    "8.2.2 TensorFlow Lite转换器",
    "TFLite转换器可以接受不同形式的模型，包括Keras Model和SavedModel，开发者可以用tf.Keras或者低层级的TensorFlow API来构造TensorFlow模型，然后使用Python API或者命令行的方式调用转换器。例如：",
    "Python API",
    "调用tf.lite.TFLiteConverter，可用TFLiteConverter.from_saved_model()，或TFLiteConverter.from_keras_model()；",
    "命令行",
    "tflite_convert --saved_model_dir=width=5,height=17,dpi=110tmpwidth=5,height=17,dpi=110mobilenet_saved_model --output_file=width=5,height=17,dpi=110tmpwidth=5,height=17,dpi=110mobilenet.tflite",
    "转换器做了以下优化工作：",
    "算子优化和常见的编译优化，比如算子融合、常数折叠或无用代码删除等。TFLite实现了一组优化的算子内核，转化成这些算子能在移动设备上实现性能大幅度提升。",
    "量化的原生支持。在模型转换过程中使用训练后量化非常简单，不需要改变模型，最少情况只需多加一行代码，设置converter.optimizations=[tf.lite.Optimize.DEFAULT]。",
    "8.2.3 FlatBuffers格式",
    "TFLite模型文件格式采用FlatBuffers，更注重考虑实时性，内存高效，这在内存有限的移动环境中是极为关键的。它支持将文件映射到内存中，然后直接进行读取和解释，不需要额外解析。将其映射到干净的内存页上，减少了内存碎片化。",
    "TFLite代码中schema.fbs文件使用FlatBuffers定义了TFLite模型文件格式，关键样例代码如图8-2所示。TFLite模型文件是一个层次的结构：",
    "TFLite模型由子图构成，同时包括用到的算子库和共享的内存缓冲区。",
    "张量用于存储模型权重，或者计算节点的输入和输出，它引用Model的内存缓冲区的一片区域，提高内存效率。",
    "每个算子实现有一个OperatorCode，它可以是内置的算子，也可以是自定制算子，有一个名字。",
    "每个模型的计算节点包含用到的算子索引，以及输入输出用到的Tensor索引。",
    "每个子图包含一系列的计算节点、多个张量，以及子图本身的输入和输出。",
    "图8-2 TFLite schema.fbs样例代码",
    "8.2.4 TensorFlow Lite解释执行器",
    "TFLite解释执行器针对移动设备从头开始构建，具有以下特点:",
    "轻量级",
    "在32 b安卓平台下，编译核心运行时得到的库大小只有100 KB左右，如果加上所有TFLite的标准算子，编译后得到的库大小是1 MB左右。它依赖的组件较少，力求实现不依赖任何其他组件。",
    "快速启动",
    "既能够将模型直接映射到内存中，同时又有一个静态执行计划，在转换过程中基本上可以提前直接映射出将要执行的节点序列。采取了简单的调度方式，算子之间没有并行执行，而算子内部可以多线程执行以提高效率。",
    "内存高效",
    "在内存规划方面，采取了静态内存分配。当运行模型时，每个算子会执行prepare函数，它们会分配一个单一的内存块，而这些张量会被整合到这个大的连续内存块中，不同张量之间甚至可以复用内存以减少内存分配.",
    "使用解释执行器通常需要包含四步：",
    "加载模型",
    "将TFLite模型加载到内存中，该内存包含模型的执行图。",
    "转换数据",
    "模型的原始输入数据通常与所期望的输入数据格式不匹配.例如，可能需要调整图像大小，或更改图像格式，以兼容模型。",
    "运行模型推理",
    "使用TFLite API执行模型推理。",
    "解释输出",
    "解释输出模型推理结果，比如模型可能只返回概率列表，而我们需要将概率映射到相关类别，并将其呈现给最终用户。",
    "TFLite提供了多种语言的API，正式支持的有Java，C++和Python，实验性的包括C，Object C，C#和Swift。可以从头自己编译TFLite，也可以利用已编译好的库，Android开发者可以使用JCenter Bintray的TFLite AAR，而iOS开发者可通过CocoaPods在iOS系统上获取。",
    "8.3 任务1：TensorFlow Lite开发工作流程",
    "使用 TensorFlow Lite 的工作流程包括如下步骤，如图8-3：",
    "选择模型",
    "可以使用自己的 TensorFlow 模型、在线查找模型，或者从的TensorFlow预训练模型中选择一个模型直接使用或重新训练。",
    "转换模型",
    "如果使用的是自定义模型，请使用TensorFlow Lite转换器将模型转换为TensorFlow Lite 格式。",
    "部署到设备",
    "使用TensorFlow Lite解释器（提供多种语言的 API）在设备端运行模型。",
    "优化模型",
    "使用模型优化工具包缩减模型的大小并提高其效率，同时最大限度地降低对准确率的影响。",
    "图8-3 TensorFlow Lite 的工作流程",
    "8.3.1 选择模型",
    "TensorFlow Lite 允许在移动端（mobile）、嵌入式（embeded）和物联网（IoT）设备上运行 TensorFlow 模型。TensorFlow 模型是一种数据结构，这种数据结构包含了在解决一个特定问题时，训练得到的机器学习网络的逻辑和知识。",
    "有多种方式可以获得 TensorFlow 模型，从使用预训练模型（pre-trained models）到训练自己的模型。为了在 TensorFlow Lite 中使用模型，模型必须转换成一种特殊格式。TensorFlow Lite 提供了转换 、运行 TensorFlow 模型所需的所有工具。",
    "为了避免重复开发，Google将训练好的模型放在TensorFlow Hub，如图8-4所示。开发人员可以复用这些已经训练好且经过充分认证的模型，节省训练时间和计算资源。这些训练好的模型即可以直接部署，也可以用于迁移学习。",
    "图8-4 TensorFlow Hub",
    "打开TensorFlow Hub网站的主页，在页面左侧可以选取类别，例如Text，Image，Video和Publishers等选项，或在搜索框中输入关键字搜索所需要的模型。",
    "以MobileNet为例，搜索到的模型如图8-5所示，在选择模型是请注意TensorFlow的版本。",
    "可以直接下载模型，或者使用hub.KerasLayer。",
    "m = tf.keras.Sequential([",
    "hub.KerasLayer(\"https://hub.tensorflow.google.cn/google/imagenet/mobilenet_v3_small_100_224/feature_vector/5\", trainable=False),",
    "tf.keras.layers.Dense(num_classes, activation='softmax')",
    "])",
    "m.build([None, 224, 224, 3])  # Batch input shape.",
    "图8-5 MobileNet下载页面",
    "8.3.2 模型转换",
    "TensorFlow Lite转换器将输入的TensorFlow 模型生成 TensorFlow Lite 模型，一种优化的 FlatBuffer 格式，以 .tflite 为文件扩展名，可以通过命令行与Python API使用此转换器。",
    "Google推荐使用Python API进行转换，命令行工具只提供了基本的转化功能。转换后的原模型为 FlatBuffers 格式。 FlatBuffers主要应用于游戏场景，是为了高性能场景创建的序列化库，相比Protocol Buffer有更高的性能和更小的大小等优势，更适合于边缘设备部署。",
    "命令行",
    "TensorFlow Lite 转换器命令行工具 tflite_convert是与TensorFlow一起安装的，在终端运行如下命令：",
    "$ tflite_convert --help",
    "`--output_file`. Type: string. Full path of the output file.",
    "`--saved_model_dir`. Type: string. Full path to the SavedModel directory.",
    "`--keras_model_file`. Type: string. Full path to the Keras H5 model file.",
    "`--enable_v1_converter`. Type: bool. (default False) Enables the converter and flags used in TF 1.x instead of TF 2.x.",
    "参数说明如下：",
    "output_file. 类型: string. 指定输出文件的绝对路径。",
    "saved_model_dir. 类型: string. 指定含有 TensorFlow 1.x 或者 2.0 使用 SavedModel 生成文件的绝对路径目录。",
    "keras_model_file. Type: string. 指定含有 TensorFlow 1.x 或者 2.0 使用 tf.keras model 生成 HDF5 文件的绝对路径目录。",
    "在 TensorFlow模型导出时支持两种模型导出方法和格式SavedModel和Keras Sequential。",
    "转换转换 SavedModel示例如下：",
    "tflite_convert \\",
    "--saved_model_dir=/tmp/mobilenet_saved_model \\",
    "--output_file=/tmp/mobilenet.tflite",
    "转换转换 Keras H5示例如下：",
    "tflite_convert \\",
    "--keras_model_file=/tmp/mobilenet_keras_model.h5 \\",
    "--output_file=/tmp/mobilenet.tflite",
    "Python API",
    "在 TensorFlow 2.0 中，将TensorFlow模型格式转换为TensorFlow Lite 的 Python API 是 tf.lite.TFLiteConverter。在 TFLiteConverter 中有以下的类方法：",
    "TFLiteConverter.from_saved_model()：用来转换 SavedModel 格式模型。",
    "TFLiteConverter.from_keras_model()：用来转换 tf.keras 模型。",
    "TFLiteConverter.from_concrete_functions()：用来转换 concrete functions。",
    "若要详细了解 TensorFlow Lite converter API，请运行 print(help(tf.lite.TFLiteConverter))。TensorFlow 2.x 模型是使用 SavedModel 格式存储的，并通过高阶 tf.keras.* API（Keras 模型）或低阶 tf.* API（用于生成具体函数）生成。",
    "以下示例演示了如何将 SavedModel 转换为 TensorFlow Lite 模型。",
    "import tensorflow as tf",
    "# Convert the model",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) # path to the SavedModel directory",
    "tflite_model = converter.convert()",
    "# Save the model.",
    "with open('model.tflite', 'wb') as f:",
    "f.write(tflite_model)",
    "以下示例演示了如何将 Keras 模型转换为 TensorFlow Lite 模型。",
    "import tensorflow as tf",
    "# Create a model using high-level tf.keras.* APIs",
    "model = tf.keras.models.Sequential([",
    "tf.keras.layers.Dense(units=1, input_shape=[1]),",
    "tf.keras.layers.Dense(units=16, activation='relu'),",
    "tf.keras.layers.Dense(units=1)",
    "])",
    "model.compile(optimizer='sgd', loss='mean_squared_error') # compile the model",
    "model.fit(x=[-1, 0, 1], y=[-3, -1, 1], epochs=5) # train the model",
    "# (to generate a SavedModel) tf.saved_model.save(model, \"saved_model_keras_dir\")",
    "# Convert the model.",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)",
    "tflite_model = converter.convert()",
    "# Save the model.",
    "with open('model.tflite', 'wb') as f:",
    "f.write(tflite_model)",
    "8.3.3 模型推理",
    "TensorFlow Lite 解释器接收一个模型文件，执行模型文件在输入数据上定义的运算符，输出推理结果，通过模型运行数据以获得预测的过程。",
    "解释器适用于多个平台，提供了一个简单的 API，用于从 Java、Swift、Objective-C、C++ 和 Python 运行 TensorFlow Lite 模型。",
    "Java 调用解释器的方式如下：",
    "try (Interpreter interpreter = new Interpreter(tensorflow_lite_model_file)) {",
    "interpreter.run(input, output);",
    "}",
    "如果手机有GPU， GPU 比 CPU 执行更快的浮点矩阵运算，速度提升能有显著效果。例如在有GPU加速的手机上运行MobileNet图像分类，模型运行速度可以提高 5.5 倍。",
    "TensorFlow Lite 解释器可以配置委托（Delegates）以在不同设备上使用硬件加速。GPU 委托（GPU Delegates）允许解释器在设备的 GPU 上运行适当的运算符。",
    "下面的代码显示了从 Java 中使用 GPU 委托的方式:",
    "GpuDelegate delegate = new GpuDelegate();",
    "Interpreter.Options options = (new Interpreter.Options()).addDelegate(delegate);",
    "Interpreter interpreter = new Interpreter(tensorflow_lite_model_file, options);",
    "try {",
    "interpreter.run(input, output);",
    "}",
    "TensorFlow Lite 解释器很容易在Android与iOS平台上使用。Android 开发人员应该使用 TensorFlow Lite AAR。iOS 开发人员应该使用 CocoaPods for Swift or Objective-C。",
    "TensorFlow Lite 解释器同样可以部署在Raspberry Pi 和基于 Arm64 的主板的嵌入式 Linux系统上。",
    "8.3.4 优化模型",
    "TensorFlow Lite 提供了优化模型大小和性能的工具，通常对准确性影响甚微。模型优化的目标是在给定设备上，实现性能、模型大小和准确性的理想平衡。根据任务的不同，你会需要在模型复杂度和大小之间做取舍。如果任务需要高准确率，那么你可能需要一个大而复杂的模型。对于精确度不高的任务，就最好使用小一点的模型，因为小的模型不仅占用更少的磁盘和内存，也一般更快更高效。",
    "量化使用了一些技术，可以降低权重的精确表示，并且可选的降低存储和计算的激活值。量化的好处有:",
    "对现有 CPU 平台的支持。",
    "激活值得的量化降低了用于读取和存储中间激活值的存储器访问成本。",
    "许多 CPU 和硬件加速器实现提供 SIMD 指令功能，这对量化特别有益。",
    "TensorFlow Lite 对量化提供了多种级别的对量化支持。",
    "Tensorflow Lite post-training quantization 量化使权重和激活值的 Post training 更简单。",
    "Quantization-aware training 可以以最小精度下降来训练网络；这仅适用于卷积神经网络的一个子集。",
    "以下的 Python 代码片段展示了如何使用预训练量化进行模型转换：",
    "import tensorflow as tf",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]",
    "tflite_quant_model = converter.convert()",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_quant_model)",
    "8.4 任务2：实现花卉识别",
    "下面将使用TensorFlow Lite实现花卉识别app，在Android设备上运行图像识别模型MobileNets_v2来识别花卉。本项目实施步骤如下：",
    "通过迁移学习实现花卉识别模型",
    "使用TFLite转换器转换模型。",
    "在Android应用中使用TFLite解释器运行它。",
    "使用 TensorFlow Lite支持库预处理模型输入和后处理模型输出。",
    "最后实现一个在手机上运行的app，可以实时识别照相机所拍摄的花卉，如图8-6所示。",
    "图8-6 花卉识别app",
    "8.4.1 选择模型",
    "选择MobileNet V2进行迁移学习，实现识别花卉模型。MobileNet V2是基于一个流线型的架构，它使用深度可分离的卷积来构建轻量级的深层神经网。可用于图像分类任务，比如猫狗分类、花卉分类等等。提供一系列带有标注的花卉数据集，该算法会载入在ImageNet-1000上的预训练模型，在花卉数据集上做迁移学习。",
    "使用小型数据集时，通常会利用在同一域中的较大数据集上训练的模型所学习的特征。通过实例化预先训练的模型，并在顶部添加全连接的分类器来完成的。预训练的模型被“冻结”并且仅在训练期间更新分类器的权重。在这种情况下，卷积基提取了与每幅图像相关的所有特征，只需训练一个分类器，根据所提取的特征集确定图像类。",
    "通过微调进一步提高性能，调整预训练模型的顶层权重，以便模型学习特定于数据集的高级特征，当训练数据集很大并且非常类似于预训练模型训练的原始数据集时，通常建议使用此技术。",
    "导入相关库",
    "In[1]:",
    "import tensorflow as tf",
    "assert tf.__version__.startswith('2')",
    "import os",
    "import numpy as np",
    "import matplotlib.pyplot as plt",
    "准备数据集",
    "该数据集可以在http://download.tensorflow.org/example_images/flower_photos.tgz下载。每个子文件夹都存储了一种类别的花的图片，子文件夹的名称就是花的类别的名称。平均每一种花有734张图片，图片都是RGB色彩模式的。",
    "In[2]:",
    "_URL = \"http://download.tensorflow.org/example_images/flower_photos.tgz\"",
    "zip_file = tf.keras.utils.get_file(origin=_URL,",
    "fname=\"flower_photos.tgz\",",
    "extract=True)",
    "base_dir = os.path.join(os.path.dirname(zip_file), 'flower_photos')",
    "数据集解压后存放在.keras\\datasets\\flower_photos目录下。",
    "2016/02/11  04:52    <DIR>          daisy",
    "2016/02/11  04:52    <DIR>          dandelion",
    "2016/02/09  10:59           418,049 LICENSE.txt",
    "2016/02/11  04:52    <DIR>          roses",
    "2016/02/11  04:52    <DIR>          sunflowers",
    "2016/02/11  04:52    <DIR>          tulips",
    "将数据集划分为训练集和验证集。训练前需要手动加载图像数据，完成包括遍历数据集的目录结构、加载图像数据以及返回输入和输出。可以使用 Keras 提供的 ImageDataGenerator 类，它是keras.preprocessing.image模块中的图片生成器，负责生成一个批次一个批次的图片，以生成器的形式给模型训练",
    "ImageDataGenerator的构造函数包含许多参数，用于指定加载后如何操作图像数据，包括像素缩放和数据增强。",
    "接着需要一个迭代器来逐步加载单个数据集的图像。这需要调用flow_from_directory（）函数并指定该数据集目录，如 train、validation 目录，函数还允许配置与加载图像相关的更多细节。 target_size参数允许将所有图像加载到一个模型需要的特定的大小，设置为大小为(224, 224)的正方形图像。",
    "batch_size默认的为32，意思是训练时从数据集中的不同类中随机选出的32个图像，该值设置为64。 在评估模型时，可能还希望以确定性顺序返回批处理，这可以通过将 shuffle参数设置为False。",
    "In[3]:",
    "IMAGE_SIZE = 224",
    "BATCH_SIZE = 64",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(",
    "rescale=1./255,",
    "validation_split=0.2)",
    "train_generator = datagen.flow_from_directory(",
    "base_dir,",
    "target_size=(IMAGE_SIZE, IMAGE_SIZE),",
    "batch_size=BATCH_SIZE,",
    "subset='training')",
    "val_generator = datagen.flow_from_directory(",
    "base_dir,",
    "target_size=(IMAGE_SIZE, IMAGE_SIZE),",
    "batch_size=BATCH_SIZE,",
    "subset='validation')",
    "Out[3]:",
    "Found 2939 images belonging to 5 classes.",
    "Found 731 images belonging to 5 classes.",
    "In[4]:",
    "for image_batch, label_batch in train_generator:",
    "break",
    "image_batch.shape, label_batch.shape",
    "Out[4]:",
    "((64, 224, 224, 3), (64, 5))",
    "保存标签文件：",
    "In[5]:",
    "print (train_generator.class_indices)",
    "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))",
    "with open('labels.txt', 'w') as f:",
    "f.write(labels)",
    "迁移学习改造模型",
    "实例化一个预加载了ImageNet训练权重的MobileNet V2模型。",
    "In[6]:",
    "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)",
    "# Create the base model from the pre-trained model MobileNet V2",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,",
    "include_top=False,",
    "weights='imagenet')",
    "Out[6]:",
    "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5",
    "9412608/9406464 [==============================] - 2s 0us/step",
    "MobileNet V2模型默认是将图片分类到1000类，每一类都有各自的标注。因为本问题分类只有5类，所以构建模型的时候增加include_top=False参数，表示不需要原有模型中最后的神经网络层（分类到1000类），以便增加自己的输出层。",
    "由于是通过迁移学习改造模型，所以不改变基础模型的各项参数变量，因为这样才能保留原来大规模训练的优势。使用model.trainable = False，设置在训练中，基础模型的各项参数变量不会被新的训练修改数据。",
    "您需要选择用于特征提取的MobileNet V2层，显然，最后一个分类层（在“顶部”，因为大多数机器学习模型的图表从下到上）并不是非常有用。相反，您将遵循通常的做法，在展平操作之前依赖于最后一层，该层称为“瓶颈层”，与最终/顶层相比，瓶颈层保持了很多通用性。随后在原有模型的后面增加一个池化层，对数据降维。最后是一个5个节点的输出层，因为需要的结果只有5类。",
    "要从特征块生成预测，请用5x5在空间位置上进行平均，使用tf.keras.layers.GlobalAveragePooling2D层将特征转换为每个图像对应一个1280元素向量。",
    "In[7]:",
    "base_model.trainable = False",
    "model = tf.keras.Sequential([",
    "base_model,",
    "tf.keras.layers.Conv2D(32, 3, activation='relu'),",
    "tf.keras.layers.Dropout(0.2),",
    "tf.keras.layers.GlobalAveragePooling2D(),",
    "tf.keras.layers.Dense(5, activation='softmax')",
    "])",
    "编译，训练模型",
    "在训练之前先编译模型，损失函数使用类别交叉熵。",
    "In[8]:",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),",
    "loss='categorical_crossentropy',",
    "metrics=['accuracy'])",
    "Out[8]:",
    "Model: \"sequential\"",
    "_________________________________________________________________",
    "Layer (type)                 Output Shape              Param #",
    "=================================================================",
    "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984",
    "_________________________________________________________________",
    "conv2d (Conv2D)              (None, 5, 5, 32)          368672",
    "_________________________________________________________________",
    "dropout (Dropout)            (None, 5, 5, 32)          0",
    "_________________________________________________________________",
    "global_average_pooling2d (Gl (None, 32)                0",
    "_________________________________________________________________",
    "dense (Dense)                (None, 5)                 165",
    "=================================================================",
    "Total params: 2,626,821",
    "Trainable params: 368,837",
    "Non-trainable params: 2,257,984",
    "训练模型，训练和验证准确性/损失的学习曲线如图8-7所示。",
    "In[9]:",
    "epochs = 10",
    "history = model.fit(train_generator, steps_per_epoch=len(train_generator),",
    "epochs=epochs, validation_data=val_generator,",
    "validation_steps=len(val_generator))",
    "图8-7 学习曲线",
    "微调",
    "设置model.trainable = False参数后，训练期间将不更新预训练网络的权重，只在MobileNet V2基础模型上训练了几层。如果希望进一步提高性能的方法是训练预训练模型的顶层的权重以及刚添加的分类器的训练。",
    "只有在训练顶层分类器并将预先训练的模型设置为不可训练之后，才应尝试此操作。如果在预先训练的模型上添加一个随机初始化的分类器并尝试联合训练所有层，则梯度更新的幅度将太大，并且预训练模型将忘记它学到的东西。",
    "应该尝试微调少量顶层而不是整个MobileNet模型，前几层学习非常简单和通用的功能，这些功能可以推广到几乎所有类型的图像，随着层越来越高，这些功能越来越多地针对训练模型的数据集。微调的目的是使这些专用功能适应新数据集，而不是覆盖通用学习。",
    "首先取消冻结模型的顶层，代码如下：",
    "In[10]:",
    "base_model.trainable = True",
    "# Let's take a look to see how many layers are in the base model",
    "print(\"Number of layers in the base model: \", len(base_model.layers))",
    "# Fine tune from this layer onwards",
    "fine_tune_at = 100",
    "# Freeze all the layers before the `fine_tune_at` layer",
    "for layer in base_model.layers[:fine_tune_at]:",
    "layer.trainable =  False",
    "Out[10]:",
    "Number of layers in the base model:  155",
    "取消冻结base_model，MobileNet V2模型网络一共155层，前100层仍设置为无法训练，然后重新编译模型，并恢复训练。使用低学习率编译模型，代码如下：",
    "In[11]:",
    "model.compile(loss='categorical_crossentropy',",
    "optimizer = tf.keras.optimizers.Adam(1e-5),",
    "metrics=['accuracy'])",
    "model.summary()",
    "如果你训练得更早收敛，这将使你的准确率提高几个百分点。",
    "history_fine = model.fit(train_generator,",
    "steps_per_epoch=len(train_generator),",
    "epochs=5,",
    "validation_data=val_generator,",
    "validation_steps=len(val_generator))",
    "经过微调后，模型精度几乎达到98%，当微调MobileNet V2基础模型的最后几层并在其上训练分类器时，验证损失远远高于训练损失，模型可能有一些过度拟合。",
    "转换为TFLite格式",
    "使用tf.saved_model.save保存模型，然后将将模型保存为tf lite兼容格式。",
    "SavedModel 包含一个完整的 TensorFlow 程序——不仅包含权重值，还包含计算。它不需要原始模型构建代码就可以运行。",
    "saved_model_dir = 'save/fine_tuning'",
    "tf.saved_model.save(model, saved_model_dir)",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)",
    "tflite_model = converter.convert()",
    "with open('save/fine_tuning/assets/model.tflite', 'wb') as f:",
    "f.write(tflite_model)",
    "模型文件保存在save\\fine_tuning\\assets目录下。",
    "8.4.2 Android部署",
    "我们已经使用MobileNet V2 创建、训练和导出了自定义TensorFlow Lite模型，已经导出以下经过训练的TF Lite模型文件和标签文件。接下来将在手机端部署，运行一个使用该模型识别花卉图片的Android 应用。",
    "准备工作",
    "Tensor Flow官网提供了很多有趣的TensorFlow Lite示例，可从github下载源码：",
    "git clone https://github.com/tensorflow/examples.git",
    "项目代码位于目录examples/lite/codelabs/flower_classification/android/，start目录下为项目模板，finish目录下是项目完整代码。",
    "安装Android Studio，确认Android Studio版本 3.0+以上，如图8-8。",
    "图8-8 Android Studio版本信息",
    "打开 Android Studio Android Studio“启动”图标。 该工具加载后，从以下弹出式窗口中选择 Android Studio“打开项目”图标“打开现有 Android Studio 项目”(Open an existing  project)：",
    "图8-9 使用 Android Studio 打开项目",
    "工作目录中选择 examples/lite/codelabs/flower_classification/android/finish。",
    "将TensorFlow Lite 模型文件model.tflite，标签文件label.txt 拷贝到项目文件夹下/android/start/app/src/main/assets/。",
    "配置build.gradle",
    "首次打开项目时，会看到一个“Gradle同步”(Gradle Sync) 弹出式窗口，询问是否要使用 Gradle 封装容器。在Gradle同步前先将模型文件拷贝到assets目录下。",
    "要使用tensorflow lite需要导入对应的库，这里通过修改build.gradle来实现。",
    "在dependencies下增加'org.tensorflow:tensorflow-lite:+'，代码如下：",
    "implementation('org.tensorflow:tensorflow-lite:0.0.0-nightly') { changing = true }",
    "implementation('org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly') { changing = true }",
    "implementation('org.tensorflow:tensorflow-lite-support:0.0.0-nightly') { changing = true }",
    "在android下增加 aaptOptions，以防止Android在生成应用程序二进制文件时压缩TensorFlow Lite模型文件。代码如下：",
    "aaptOptions {",
    "noCompress \"tflite\"",
    "}",
    "运行Sync Gradle开始Android环境部署， 运行结果如图8-10：",
    "图8-10  Gradle同步结果",
    "因为获取SDK和gradle编译环境等资源，需要先给Android Studio配置proxy或者使用国内的镜像。可将 build.gradle 中的maven源 google() 和 jcenter() 分别替换为国内镜像，如下：",
    "buildscript {",
    "repositories {",
    "maven { url ' https://maven.aliyun.com/repository/google '}",
    "maven { url ' https://maven.aliyun.com/repository/jcenter '}",
    "}",
    "dependencies {",
    "classpath 'com.android.tools.build:gradle:3.5.1'",
    "}",
    "}",
    "allprojects {",
    "repositories {",
    "maven { url ' https://maven.aliyun.com/repository/google '}",
    "maven { url ' https://maven.aliyun.com/repository/jcenter '}",
    "}",
    "}",
    "初始化TensorFlow Lite解释器",
    "推理过程是通过解释器（interpreter）来执行，首先是读取模型，将.tflite模型加载到内存中，其中包含了模型的执行流图。",
    "修改ClassifierFloatMobileNet.java文件的ClassifierFloatMobileNet类，添加model.tflite 和 label.txt，代码如下：",
    "public class ClassifierFloatMobileNet extends Classifier {",
    "...",
    "// TODO: Specify model.tflite as the model file and labels.txt as the label file",
    "@Override",
    "protected String getModelPath() {",
    "return \"model.tflite\";",
    "}",
    "@Override",
    "protected String getLabelPath() {",
    "return \"labels.txt\";",
    "}",
    "...",
    "}",
    "在Classifier.java文件中的Classifier类里声明TFLite 解释器tflite，如果有GPU，还需要声明GPU代理gpuDelegate。",
    "protected Classifier(Activity activity, Device device, int numThreads) throws IOException {",
    "...",
    "// TODO: Declare a GPU delegate",
    "private GpuDelegate gpuDelegate = null;",
    "/** An instance of the driver class to run model inference with Tensorflow Lite. */",
    "// TODO: Declare a TFLite interpreter",
    "protected Interpreter tflite;",
    "...",
    "}",
    "在Classifier类构造函数中创建tflite实例。",
    "protected Classifier(Activity activity, Device device, int numThreads) throws IOException {",
    "...",
    "switch (device) {",
    "case GPU:",
    "// TODO: Create a GPU delegate instance and add it to the interpreter options",
    "gpuDelegate = new GpuDelegate();",
    "tfliteOptions.addDelegate(gpuDelegate);",
    "break;",
    "case CPU:",
    "break;",
    "}",
    "tfliteOptions.setNumThreads(numThreads);",
    "// TODO: Create a TFLite interpreter instance",
    "tflite = new Interpreter(tfliteModel, tfliteOptions);",
    "...",
    "}",
    "执行推理",
    "TensorFlow Lite解释器初始化后，开始编写代码以识别输入图像。 TensorFlow Lite无需使用ByteBuffer来处理图像， 它提供了一个方便的支持库来简化图像预处理，同样还可以处理模型的输出，并使TensorFlow Lite解释器更易于使用。下面需要做的工作有：",
    "数据转换（Transforming Data）：将输入数据转换成模型接收的形式或排布，如resize原始图像到模型输入大小；",
    "执行推理（Running Inference）：这一步使用API来执行模型。其中包括了创建解释器、分配张量等；",
    "解释输出（Interpreting Output）：用户取出模型推理的结果，并解读输出，如分类结果的概率。",
    "首先处理摄像头的输入图像，修改Classifier.java文件中的loadImage方法，代码如下：",
    "private TensorImage loadImage(final Bitmap bitmap, int sensorOrientation) {",
    "...",
    "// TODO: Define an ImageProcessor from TFLite Support Library to do preprocessing",
    "ImageProcessor imageProcessor =",
    "new ImageProcessor.Builder()",
    ".add(new ResizeWithCropOrPadOp(cropSize, cropSize))",
    ".add(new ResizeOp(imageSizeX, imageSizeY, ResizeMethod.NEAREST_NEIGHBOR))",
    ".add(new Rot90Op(numRoration))",
    ".add(getPreprocessNormalizeOp())",
    ".build();",
    "return imageProcessor.process(inputImageBuffer);",
    "...",
    "}",
    "修改recognizeImage方法执行推理，将预处理后的图像提供给TensorFlow Lite解释器。代码如下:",
    "public List<Recognition> recognizeImage(final Bitmap bitmap, int sensorOrientation) {",
    "...",
    "// TODO: Run TFLite inference",
    "tflite.run(inputImageBuffer.getBuffer(), outputProbabilityBuffer.getBuffer().rewind());",
    "...",
    "}",
    "最后从模型输出中获取类别及其概率。",
    "public List<Recognition> recognizeImage(final Bitmap bitmap, int sensorOrientation) {",
    "...",
    "// TODO: Use TensorLabel from TFLite Support Library to associate the probabilities with category labels\n    Map<String, Float> labeledProbability =",
    "new TensorLabel(labels, probabilityProcessor.process(outputProbabilityBuffer))",
    ".getMapWithFloatValue();",
    "...",
    "}",
    "labeledProbability是将每个类别映射到其概率的对象。 TensorFlow Lite支持库提供了一个方便的实用程序，可将模型输出转换为概率图，使用getTopKProbability（..）方法从labeledProbability中提取前几名最可能的标签。",
    "试运行应用",
    "应用可以在Android 设备上运行，也可以在 Android Studio 模拟器中运行。如果计算机没有摄像头就必须选择Android 设备运行该应用。",
    "图8-11  设置模拟器",
    "Android Studio 可轻松设置模拟器，选择“Tools”， “AVD Manager”。",
    "如需设置模拟器的相机，需要在“Android 虚拟设备管理器”(Android Virtual Device Manager)中创建一个新设备。从 ADVM 主页面中选择“创建虚拟设备”(Create Virtual Device)：",
    "图8-12 创建虚拟设备",
    "然后在“验证配置”(Verify Configuration) 页面（虚拟设备设置的最后一页）上，选择“显示高级设置”(Show Advanced Settings)：",
    "图8-13 高级设置",
    "如图在Android 设备上运行，设置手机启用“开发者模式”和“USB 调试”，否则无法将该应用从 Android Studio 加载到您的手机上。",
    "如需启动构建和安装过程，运行Gradle同步。",
    "图8-14 运行 Gradle 同步",
    "运行 Gradle 同步后，请选择单击Android Studio“开始”图标，需要从如图8-15窗口中选择设备，运行结果如图8-16所示。",
    "图8-15 选择设备                       图8-16 运行结果",
    "拓展项目",
    "TensorFlow 官网提供了很多TensorFlow Lite 示例应用，探索经过预先训练的 TensorFlow Lite 模型，了解如何在示例应用中针对各种机器学习应用场景使用这些模型。并且分别提供了Android设备、iOS设备以及Raspberry Pi上的应用实现代码，如图8-17所示。",
    "本项目任务要求是基于TensorFlow Lite开发一个安卓示例应用程序，应用程序利用设备的摄像头来实时地检测和显示一个人的关键部位。",
    "通过PoseNet模型实现人体姿势估计，PoseNet可以通过检测关键身体部位的位置来估计图像或者视频中的人体姿势。例如，该模型可以估计图像中人的手肘和/或膝盖位置。",
    "可参考示例代码：",
    "https://github.com/tensorflow/examples/tree/master/lite/examples/posenet/android。",
    "图8-17 图像分类示例应用",
    "该PoseNet示例应用程序功能是捕捉摄像头拍摄的帧，并实时覆盖图像上的关键点。应用程序对每张传入的摄像头图像执行以下操作：",
    "从摄像头预览中获取图像数据并转换成格式。",
    "创建一个位图对象来保存来自 RGB 格式帧数据的像素。将位图裁剪并缩放到模型输入的大小，以便将其传递给模型。",
    "从 PoseNet 库中调用estimateSinglePose()函数来获取Person对象。",
    "将位图缩放回屏幕大小，在Canvas对象上绘制新的位图。",
    "使用从Person对象中获取的关键点位置在画布上绘制骨架。显示置信度超过特定阈值（默认值为 0.2）的关键点。",
    "使用TenzeFullLight的工作流,包括如下步骤,包括选择模型,转换模型,部署到我们的设备,优化模型。",
    "第一,选择模型,可以使用自己的TenzeFullLight模型,再线查找模型,或者从TenzeFullLight预讯练模型中选择一个模型,直接使用或重新训练。",
    "二,转换模型,如果使用的是制定一模型,可以使用TenzeFullLight转换器,将模型转换为TenzeFullLight格式。",
    "三,部署到设备,使用TenzeFullLight解释器,在设备端运行模型。",
    "四,优化模型,使用模型优化工具包,缩减模型的大小,并提高起效率,同时最大线度的降低对准确力的影响。",
    "TenzeFullLight,允许在移动端,签入式和无连网设备上运行TenzeFullLight模型。",
    "有多种方式可以获得TenzeFullLight模型。",
    "为了避免重复开发,Google将训练好的模型放在TenzeFullLight Hub。",
    "开发人员可以复用这些已经训练好且经过充分认证的模型。",
    "结成训练时间和计算资源。",
    "这些训练好的模型,即可以直接部署,也可以用于签议学习。",
    "打开TenzeFullLight Hub的网站的主页,在页面左侧可以选取类别,例如Paxx,Image, Widow和Publicsir等选项。",
    "或在搜索框中输入关键字搜索所需要的模型。",
    "以Mobile Night为例,搜索到的模型如土所市。",
    "在选择模型时,请注意TenzeFullLight的版本。",
    "可以直接下载模型,或者使用HobbyCarrie Slayer。",
    "为了在TenzeFullLight中使用模型,模型必须转换成一种特殊格式。",
    "TenzeFullLight提供了转换运行TenzeFullLight模型所需的所有工具。",
    "TenzeFullLight需要将模型转换为一种优化的FlightBuffer格式,以点TFLight为文件扩展名。",
    "可以通过命令行与PaxxApi使用磁转换器。",
    "Google推荐使用PaxxApi进行转换。",
    "命令行工具只提供了基本的转换功能。",
    "转换后的原模型为FlightBuffer格式,FlightBuffer主要应用于游戏场景,是为了高性能场景创建的序列化库。",
    "相比Portoco Buffer有更高的性能和更小的大小等优势,更适合与边缘设备部署。",
    "有了模型后,我们就可以在设备端使用TenzeFullLight模型,根据输入数据进行预测。",
    "需要使用TenzeFullLight模型进行推理,就必须通过解释器运行该模型。",
    "TenzeFullLight解释器使用近太计算图排序和自定议内存分配器。",
    "来确保最小的复杂、处使化和执行掩饰。",
    "TenzeFullLight推理通常遵循以下步骤,以加载模型。",
    "我们必须将点TFlight模型加载到内存中,其中包含模型的执行计算图。",
    "2.转换数据。模型的原始输入数据,通常与模型期望的输入数据格式不匹配。",
    "例如,我们可能需要调整图像大小或更改图像格式才能与模型肩融。",
    "3.运行推理。",
    "此步骤设夕使用TenzeFullLight api来执行模型。",
    "如以下各部分所数,它设极构建解释器和分配张量等热干部种。",
    "4.解释输出。",
    "当我们从模型推理,进收到结果后,必须对我们的应用有意义的方式来解释张量。",
    "例如模型可能只会返回概率列表,由我们自己来将概率应设到相关的设计。",
    "而在我们的内边,并呈现给最终用户。",
    "TenzeFullLight支持大多数常见的移动或签入视频台,例如安卓、IOS和Linux。",
    "TenzeFullLight,装位在小型设备上进行快速推理而设计。",
    "因此,API试图以新生变力性,为代价来避免不必要的复制,也就不足为其了。",
    "在安卓上,可以使用Java或CjjAPI来执行TenzeFullLight推理。",
    "JavaAPI提供了变力性,并且可以直接带安卓Ectivity内中使用。",
    "CjjAPI提供了更好的灵活性和速度,但可能需要编写,G&I封装容器才能在Java和Cjj曾之间移动数据。",
    "对于使用元数据增强的TenzeFullLight模型,开发者可以使用TenzeFullLight安卓封装容器代码生成器,",
    "来创建平台特定的封装容器代码。",
    "封装容器代码无需在安卓上直接与Bike Buffer进行交互。",
    "在IOS上,TenzeFullLight使用于Ectivity和Objective C编写的原生LSQ。",
    "我们也可以直接在Objective C代码中使用CAPI。",
    "在Linux平台,我们可以使用于Cjj和Bike Buffer提供的TenzeFullLight API运行推理。",
    "TenzeFullLight和TenzeFullModel Optimization to Kate。",
    "提供了最小优化推理复杂性的工具,可将优化推断的复杂性将至最低。",
    "TenzeFullLight对量化提供了多种极别的量化支持。",
    "模型优化的目标是在给定设备上,实现性能模型大小和整确性的理想平衡。",
    "根据任务的不同,我们会需要在模型复杂度和大小之间做取捨。",
    "如果任务需要高准确率,那么我们可能需要一个大而复杂的模型。",
    "对于精确度不高的任务,就最好使用小一点的模型。",
    "因为小的模型不仅占用更小的磁盘和内层,也一般更快更高效。",
    "教小的存储大小,小模型在用户设备上占用的存储空间更少。",
    "例如,一个使用小模型的安卓应用,在用户的移动设备上会占用更小的存储空间。",
    "教小的下载大小,小模型下载到用户设备所需的时间和带宽教小。",
    "更小的内层用量,小模型在运行时使用的内层更小,",
    "从而释放内层供应用的其他部分使用,并可以转化为更好的性能和稳定性。",
    "Thuntherflow Lite,目前支持通过量化,简直和具类进行优化。",
    "量化的工作原理是降低用于表示模型参数的数字,温任情况为32位幅点数的精度。",
    "这样可以获得教小的模型大小和教快的计算速度。",
    "Thuntherflow Lite提供讯念后flow.16量化,讯念后动态范围量化,讯念后量化,量化感知讯念。",
    "简直的工作原理是移除模型中对其预测影响很小的参数。",
    "简直后的模型在磁盘上的大小相同,并且只有相同的运行时延迟。",
    "但可以更高效地压缩,这时简直成为缩简模型下载大小的使用技术。",
    "具类的工作原理是,将模型中每一层的权重,归入预定数量的具类中,然后共享属于每个单独具类的权重的智新值。",
    "这就减少了模型中唯一权重值的数量,从而降低了起伏砸性。",
    "这个项目我们将会在安卓上使用TenzeFulloLight 时别花朵",
    "基于看花十名APP应用",
    "讲解TenzeFullo模型如何应用于安卓系统",
    "在服务器端讯练TenzeFullo模型",
    "并把模型文件迁移到智能中端",
    "以及TenzeFullo安卓开发环境够简",
    "以及应用开发APP",
    "在安卓设备上运行图像识别模型",
    "MobileNet V2来识别花会",
    "第一步通过天意学习实现花会识别模型",
    "第二步使用TFLight转换器转换模型",
    "第三步在安卓应用中使用TFLight解释器运行它",
    "第四步使用TenzeFulloLight 支持库",
    "预处理模型输入和后处理模型输出",
    "我们选择MobileNet V2进行千亿学习",
    "实现实别花会模型",
    "MobileNet V2是基于一个流线型的价格",
    "它使用深度可分离的卷机",
    "来构建轻量级的深层神经网",
    "我们将使用带有标注的花会数据集",
    "该设法会载入在ImageNet刚1000上的预讯联模型",
    "载花会数据集上做天意学习",
    "使用小型数据集时",
    "通常会利用在同意预中的",
    "较大数据集上训练的模型所学习的特征",
    "预训练的模型被动节",
    "并且仅在训练期间更新分类器的权重",
    "花会数据集可以载TenzeFullo官网下载",
    "每个紫文件夹都存储了一种类别的花的图片",
    "紫文件夹的名称就是花的类别的名称",
    "平均每一种花有734张图片",
    "图片都是RGB色彩模式的",
    "接下来我们将数据集划分为训练集和验证集",
    "训练前需要手动夹载图像数据",
    "完成包括变力数据集的目楼结构",
    "夹载图像数据",
    "以及返回输入和输出",
    "Kirons提供了Image Data Generator类",
    "它是一个图片声成器",
    "负责声成多个批词的图片",
    "以声成器的形式给模型训练",
    "Image Data Generator的构造罕述",
    "包含许多参数",
    "用于指定夹载后如何操作图像数据",
    "包括像素缩放和数据增强",
    "接着需要一个迭代器",
    "来逐步夹载单个数据集的图像",
    "这需要调用",
    "Flow From Directors的含数",
    "并指定该数据集目楼",
    "如Tream Validation目楼",
    "含数还允许配置于夹载图像相关的更多细节",
    "它给的Size参数允许将所有图像",
    "夹载到一个模型需要的特定的大小",
    "数值大小为224、224的正方形图像",
    "BatchSize 默认为32",
    "意思是",
    "许念时从数据集中的不同内中",
    "随机选出的32个图像",
    "该值设置为64",
    "在评估模型时",
    "可能还希望以确定性设许返回P处理",
    "就可以通过将Safe参数设置为FOSS",
    "我们选择MobileNetVR进行千亿学习",
    "首先实力化一个预加载了",
    "EmitNight 信念全中的MobileNetVR模型",
    "MobileNetVR模型",
    "默认是将图片分类到1000类",
    "每一类都有各自的标注",
    "我们项目中花贵分类只有5类",
    "所以购件模型的时候增加",
    "Include, Top等于FOSS参数",
    "表示不需要远有模型中最后的神经网络层",
    "即分类到1000类",
    "由于是通过千亿学习改造模型",
    "所以不改变基础模型的各项参数变量",
    "因为这样才能保留原来大规模训练的优势",
    "使用Model.trinable等于FOSS",
    "设置在训练中基础模型的各项参数变量",
    "不会被新的训练修改数据",
    "专讯通常的做法",
    "在展平操作之前依赖于最后一层",
    "该成称为平景层",
    "与最终或顶层相比",
    "平景层保持了很多通用性",
    "随后在原有模型的后面增加一个实化层",
    "对数据降围",
    "最后是一个五个节点的输出层",
    "因为需要的结果只有五类",
    "模型优化算法使用Odam",
    "损失韩束使用类别交叉商",
    "使用准确率作为判断训练结果的参数",
    "经过10个周期的训练后",
    "我们应该在验证极上看到约94%的准确率",
    "刚才我们紧在MobileNetwork2",
    "基础模型的顶部训练了一些层",
    "预训练网络的权重",
    "在训练过程中并为更新",
    "需要进一步提高性能",
    "就需要在训练",
    "预训练模型顶层的权重的同时",
    "另外训练我们添加的分类器",
    "应该尝试微调式的方式",
    "使用少量顶层而不是整个MobileNet模型",
    "前几层学习非常简单和通用的功能",
    "这些功能可以推广到几乎所有类别的图像",
    "随着层越来越高",
    "这些功能越来越多的针对训练模型的数据级",
    "微调的目的是使这些专用功能",
    "适应新数据级",
    "而不是覆盖通用学习",
    "首先取消洞捷模型的顶层",
    "取消洞捷",
    "被small的",
    "MobileNet V2模型网络",
    "一共155层",
    "前100层任设置为无法训练",
    "然后重新编一模型并恢复训练",
    "经过微调后",
    "模型精度几乎达到了98%",
    "当微调MobileNet V2",
    "基础模型的最后几层",
    "并在习上训练分类气时",
    "验证损失",
    "远远高于训练损失",
    "模型可能有一些过渡你合",
    "我们使用TF.save的model.save模型",
    "我们使用TF.save的model.save",
    "然后将模型保存为",
    "TFlight肩容格式",
    "save的model包含一个完整的",
    "分色flow程序",
    "不仅包含全重纸",
    "还包含计算",
    "它不需要原始模型购件代码",
    "就可以运行",
    "噴射弗洛生态系统有着丰富的工具列",
    "噴射弗洛 serving是使用广泛的高性能的服务器端部署平台",
    "噴射弗洛.js支持使用加拉斯伟传在流览器端部署",
    "噴射弗洛 Light加速了端错机器学习的发展",
    "他支持安卓.ls,签入试设备以及极小的MCU设备",
    "全球超过40亿设备部署了Thnsurvelo Light",
    "谷歌,优伯,网易,爱奇异,腾性等公司的应用",
    "都使用了Thnsurvelo Light",
    "华会识别项目是基于Thnsurvelo Light",
    "使用Mobile Light模型在安卓手机上实现十别四种化的种类",
    "通过这个项目我们将了解Thnsurvelo Light的发展历史与应用",
    "掌握Thnsurvelo Light的整体价格",
    "Thnsurvelo Light转换器作用",
    "Flight Buffers格式",
    "以及Thnsurvelo Light解释执行器的特点以及工作过程",
    "在这个项目中我们将在安卓设备上使用Thnsurvelo Light运行图像实别模型",
    "具体包括使用Thnsurvelo Light Mold-Maker",
    "训练自定义的图像分类器",
    "利用Android Studio导入训练后的模型",
    "并结合CAMERAX使用",
    "利用手机GPU加速模型运行",
    "伴随移动和LT设备的普及",
    "世界以超红想象的方式存在被连接的可能",
    "如今已有超过32亿的手机用户和70亿的连网LT设备",
    "而随着手机成本不断降低",
    "并且随着微控之气和微机电系统的发展",
    "高兴能低功耗的芯片",
    "使得万物智能具有了可能性",
    "Google开始了TF Mobile项目",
    "常试检化Thnsurvelo并在移动设备上运行",
    "它是一个缩减版的Thnsurvelo",
    "简化了算紫级也缩小了运行库",
    "基于TF Mobile的经验",
    "也继承了TF Mini和内部其他类似项目的",
    "很多优秀工作",
    "Google设计了ThnsurveloLight",
    "ThnsurveloLight是Thnsurvelo在移动和LT",
    "等边缘设备端的几节方案",
    "提供了Java,Person和CiJa API库",
    "可以运行在按着OS等设备上",
    "ThnsurveloLight与Thnsurvelo完全独立的两个项目",
    "与Thnsurvelo基本没有代码共享",
    "Thnsurvelo本身是为桌面和服务器端设计开发的",
    "没有为Arm移动停台定制优化",
    "因此如果直接用在移动平台或者签入时段会水土布服",
    "ThnsurveloLight则实现了低能耗",
    "低延迟的移动平台机器学习框架",
    "并且使得编移之后的二进制发布版本更小",
    "ThnsurveloLight的优点如下",
    "1.ThnsurveloLight针对设备端自己学习进行了优化",
    "延迟数据无需往返服务器",
    "隐私没有任何个人数据离开设备",
    "连接性无需连接互联网",
    "大小说减了模型和二进制文件的大小",
    "和功耗高效推理且无需网络连接",
    "第二个优点支持多种平台、涵盖、安卓和LOS设备",
    "陷入是Linux和微控制器",
    "支持多种语言包括加娃、Sweift",
    "Objective C、C加加和Person",
    "第三,高性能支持硬件加速和模型优化",
    "四,提供多种平台上的常见机器学习任务的端道端势力",
    "例如图像分类,对象检测,知识估计",
    "问题回答,文本分类的",
    "全球有超过40亿的设备上部署的TFLight",
    "例如Google Assistant,UBE以及网易、爱奇异和DD等",
    "都在使用TFLight",
    "端则FloLight能解决的问题越来越多元化",
    "就带来了应用的大量繁荣",
    "在移动应用方面",
    "网易使用TFLight做OCR处理",
    "爱奇异使用TFLight来进行视频中的AR效果",
    "而WPR使用它来做一系列文字处理",
    "Google现在更新Google Play服务中的ThinFloLight",
    "作为安卓官方机器学习推理引擎",
    "而从发布到现在Google Play服务中的ThinFloLight",
    "已经通过数万个应用程序",
    "每月对数十一个用户提供服务",
    "TFLight也非常适合工业物廉智能设备的开发",
    "它很好地支持数没派",
    "及其他基于Linux SOC的工业自动化系统",
    "ThinFlo官网有很多ThinFlo.js够建的势力",
    "下面介绍一下Tenzeflow.js的架构",
    "Tenzeflow.js包含Kore API 与Layer API 两部门",
    "可以使用底层Kore API或最高级的Layer API在流览器上开发模型",
    "也能基于流览器运行以讯电的模型",
    "Layer API提供了更高层的API接口",
    "提供了类似于Korealist的余法机构",
    "提供高力度的抽象让开发人员使用加拿斯锤的更变节来开发机器学习模型",
    "Kore API 来处理底层代码",
    "在Kore API 之上编写的Layer API",
    "Kore API 则使用加拿斯锤的提供的Tenzeflow和新功能",
    "比如说Tenzeflow的Tenze的创建数据的运算内存管理等等",
    "此外Kore API 还提供了工具将拍审中的继续学习模型",
    "转换成Tenzeflow 可以或者是流览器可以使用的JSON格式",
    "Tenzeflow.js 支持GPU硬件加速",
    "在Note.js 环境中如果有CUDA 环境支持",
    "或者在流览器环境中有WebGL 环境支持",
    "那么Tenzeflow.js 可以使用硬件进行加速",
    "加拿斯锤的项目中有两种主要的方式来获取Tenzeflow.js",
    "通过脚本标签或从样子安装并使用",
    "Parsel Webpack或Roughup等工具够近工程",
    "如果是Web开发新手或者从未听说过",
    "主要的Webpack或Parsel工具建议使用脚本代",
    "如果已经比较有经验或者想编写更大的程序",
    "那么值得使用够减工具进行探索",
    "在流览器中加载Tenzeflow.js 最方便的办法",
    "是在HTML中直接引用Tenzeflow.js 发布的NPM包中",
    "已经打包安装好的加Warscred的代码",
    "为了能够用加Warscred 够减机器学习模型",
    "需要在Head标签中通过Strept标签",
    "来将Tenzeflow.js 文件从CDN 服务器上下载下来",
    "这个代码中SRC 属性给出了CDN 文件的具体地址",
    "CDN 文件地址是Tenzeflow官网公布的",
    "我们是否正确地引用了正确的库文件地址",
    "如何判断呢",
    "可以在Clown 流览器中按下F12 键",
    "打开开发人员工具可以方便调试自己的代码",
    "可以在控制台中输入Tef.warshen 查看是否正确地输出版本信息",
    "可随时使用Clown 流览器的开发人员工具",
    "从而快速调试加Warscred HTML和极廉样式表",
    "还可以跟踪并查明网页或网络的性能问题",
    "下面我们在Clown 流览器的控制台演示一下",
    "看一下具体操作流程",
    "数据都存放在Tenze 数据结构中",
    "Tenze 是Tenze 幅漏.gs中的中心数据单元",
    "如何理解Tenze呢",
    "Tenze 就是一个一为或多为数损",
    "Tenze 有几个关键的属性",
    "Six 属性定义了其数损形状",
    "Runk 定义张量包含的为数",
    "这里有两个例子",
    "第一个例子通过长量定义了一个22的二为数据",
    "第二个例子输入是一为数据",
    "通过Safe 参数定义张量的形状是22",
    "下面我们在Clown 流览器的控制台演示一下",
    "看一下两个变量的反回值是否相同",
    "Tenze 幅漏.gs 提供了多种诗用于张量的现形代数和机器学习运算的操作",
    "由于Tenze 是不可改变的",
    "这些操作不会改变他们的值",
    "而会返回新的Tenze",
    "这些运算不仅包含F-2的确实",
    "而会运算的确实",
    "而会运算的确实",
    "而会运算的确实",
    "而会运算的确实",
    "而会运算的确实",
    "而会运算的确实",
    "而会运算的确实",
    "而会运算的确实",
    "而会运算的确实",
    "而会运算的确实",
    "这些运算不仅包含F-2的Sab",
    "和M-2的确实",
    "而会运算",
    "同时还包括S-2的依远运算",
    "第一个例子对Tenze中的所有元素",
    "执行X频缝计算",
    "第二个例子对两个Tenze的元素执行",
    "主元素相加",
    "下面我在Crowme榴末机的控制台演示",
    "下面我在Crowme榴末机的控制台演示一下",
    "看一下变量的反回值",
    "ThanThanFlow.gts是一个用于使用加娃Squript进行机器学习开发的库",
    "用于在流览器和Note.gts讯论和部署机器学习模型",
    "ThanThanFlow.gts支持使用加娃Squript在流览器端部署",
    "也与微信小程序有很好的机程",
    "ThanThanFlow.gts支持所有Pyson可以加载的模型",
    "在Note.gts环境中直接通过调言API即可",
    "在流览器环境中需要转换为流览器支持的JSON格式",
    "ThanThanFlow.gts提供了一系列预讯论好的模型",
    "包括图像识别 余音识别 人体姿态识别 物体识别 文字分类等",
    "在这个项目中我们将通过预测汽车油耗效率",
    "首写数字识别 两个实力演示如何使用ThanThanFlow.gts进行ThanThanFlow模型的开发讯认和部署",
    "体验ThanThanFlow.gts直接在流览器加载ThanThanFlow",
    "通过本地CPU或者GPU资源进行所需的机器学习运算",
    "灵活的进行各种AI应用的开发",
    "我们将学习ThanThanFlow.gts的优点",
    "ThanThanFlow.gts的体系价格以及相关概念",
    "学习ThanThanFlow.gts环境配置",
    "在流览器中使用ThanThanFlow.gts",
    "能在Note.gts中使用ThanThanFlow.gts",
    "能通过Layer's API, call API,创建模型",
    "能熟练模型部署开发相应AI应用",
    "ThanThanFlow.gts是一个开源机器学习库",
    "可运行在加娃Scrept",
    "可以运行的任何位置",
    "它基于使用Pyson编写的原始ThanThanFlow.gts",
    "直在为加娃Scrept生态系统",
    "打造这种开发者体验和移系列API",
    "建于加娃Scrept的可移植性",
    "我们可以使用一种语言编写",
    "并在以下所有平台上轻松直行机器学习",
    "使用原版加娃Scrept的网络流览器中的客户端",
    "使用Note.gts进行服务器端",
    "甚至是RESPERBELRY, PII等IOT设备",
    "使用Electron的装面应用",
    "使用React Native的原生移动应用",
    "ThanThanFlow.gts还支持在每个环境中使用多个后端",
    "例如可以在CPU或WebGL中",
    "直行的实际基于硬件的环境",
    "使出的后端并不意味着服务器端环境",
    "以确保肩容性并保持运行速度",
    "在2017年,一个叫Dip Learning.gts的项目诞生了",
    "这是一款基于WebGL加速的开放原带马",
    "加娃Scrept机器学习库",
    "该库可以直接在流览器中运行",
    "而无需进行安装",
    "也无需借助后端运行",
    "在2018年3月,Dip Learning.gts团队与ThanThanFlow团队合并",
    "从命名为ThanThanFlow.gts",
    "ThanThanFlow.gts可以让我们直接在流览器中加载ThanThanFlow",
    "让用户立即通过本地的CPU或GPU资源进行我们所需要的机器学习运算",
    "更灵活的进行AI应用的开发",
    "流览器中进行机器学习",
    "相比于服务计端来讲由以下施打优势",
    "一,不需要安装软件或驱动",
    "打开流览器即可使用",
    "二,可以通过流览器进行更加方便的人机交互",
    "三,可以通过手机流览器",
    "调用手机硬件的各种传感器",
    "例如GPS,身上头等等",
    "似,用户的数据可以无需上传的服务器",
    "在本地即可完成所需操作",
    "官网有很多ThanThanFlow.gts是构建的势力和债线演示",
    "例如在网页端讯练一个模型来识别图片或语音",
    "讯练一个模型以新影的方式玩游戏",
    "我构建一个能创造钢琴音乐的神经网络的",
    "谷歌推出的AI小程序",
    "参画小歌在朋友圈风黄刷屏",
    "现在谷歌AI又有了更有趣的打开方式",
    "WooMeghr可以将你的姿势与同一姿势的其他人的图像相匹配",
    "利用机器来捕捉人类的动作",
    "然后跟8万多幅图像进行比对收索",
    "找出与人类动作一致的图像",
    "在机器学习中,模型是一个带游可学习参数的含书。",
    "可将输入硬设置输出。",
    "通过在数据上训练模型,获得最佳参数。",
    "训练好的模型可以提供从输入到所需输出的准确硬设。",
    "在Tensheveflow.gs中,",
    "我们可以通过两种方式创建机器学习模型。",
    "使用Layer's API使用Core API。",
    "Layer's API有两种方式创建模型,",
    "第一种是创建起困手模型。",
    "第二种是创建Functional模型。",
    "起困手模型将网路的每一层简单的跌在一起。",
    "我们可以将需要的程按讯许起在一个列表中。",
    "然后将列表作为CoreHansu的输入。",
    "也可以通过TF.model来创建Layer's model。",
    "可以用TF.model来创建任何非必还的计算图。",
    "以下是使用TF.model API建立和上文相同模型的例子。",
    "在每一层中,用Apply将上一层的输出作为本层的输入。",
    "不同于CoreHansu model使用InputSafe来定义第一层的输入。",
    "用TF.model的创建的Semmolic Tensheve作为第一层的输入。",
    "Layer's API提供了大量方便的工具,",
    "例如权中出实化,模型续练化,",
    "细练监测可签一性和安全检查。",
    "当遇到如下层矿时,可能会需要使用Core API。",
    "1.需要更多灵火性和控制,",
    "2.不需要系列化,我可以创造自己的系列化方法。",
    "使用WebGL后端时必须显示管理TF.tensheve内存。",
    "在TensheveVLO.gf中可以通过Dispose和TF.tidy这两种方法来管理内存。",
    "要消贵TF.tenshe的内存可以使用Dispose方法或TF.dispose。",
    "进行大量的张量操作时使用Dispose可能会很麻烦。",
    "TensheveVLO.gf提供了另一个韩束TF.tidy。",
    "它对加了Scrape中常规范围起到类似的作用。",
    "不同的是它针对GPU支持的张量。",
    "TF.tidy執行一个韩束并清楚所有创建的中间张量。",
    "释放他们的GPU内存,它不清楚内部韩束的反回纸。",
    "在TensheveVLO.gf中的张量操作时使用Dispose方法或TF.tidy。",
    "它对加了AV的方法,它不需要重新的动作。",
    "TensheveVLO.gf中的张量操作时使用Dispose方法或TF.tidy。",
    "TensheveVLO.gf中的张量操作时使用Dispose方法或TF.tidy。",
    "它对加了AV的方法或TF.tidy。",
    "它对加了AV的方法或TF.tidy。",
    "它对加了AV的方法或TF.tidy。",
    "它对加了AV的方法或TF.tidy。",
    "汽车MPG意味汽车的友号",
    "是每家轮可以跑多少英里的一个数据",
    "每家轮约等于3.785升",
    "而每英里约等于1.61千米",
    "红阳的是一辆汽车在一家轮燃油的情况下能走多远",
    "汽车MPG的数据建模受到汽光数、加速度、马力、排量、重量等影响",
    "在世界各地汽车使用非常普遍的情况下",
    "消费者有时会考虑购买之前想购买汽车的效率和燃油经济型",
    "每个人都想买一辆能行使很远、耗油更少的车",
    "这个项目是简单的现性回归的实验",
    "用来预测汽车的油耗效率MPG",
    "将使用一个小数据级和一个简单的模型",
    "帮助大家熟悉使用Thensaflow.gs进行训练模型的基本流程与概念和语法",
    "我们首先创建一个使用Thensaflow.gs",
    "在流暖器中训练模型的网页",
    "然后给定汽车的功率",
    "使用模型预测汽车油耗具体流程一下",
    "第一步 需要加载数据",
    "并对数据格式化和可式化",
    "要用于训练模型的数据",
    "第二步定义一个现性回归模型",
    "使用其他变量预测输出变量",
    "现性回归是一种广泛用于建模和理解现实世界现象的技术",
    "它一于使用和直观理解",
    "在简单现性回归中模型只是一条直线",
    "而对于多元回归模型可以是多像是或评厌",
    "第三步 训练模型并监视其性能",
    "第四步 评估模型",
    "建立一个HTML文件 文件名为indepth.html",
    "在投信系中通过将NPM模块转换为再线可以引用的免费服务",
    "CDN.js-deliver.night",
    "来加载TFGS和TFGS-WARS两个模块",
    "TFGS-WARS是tensurve-low.js进行牛软器可视化的一组实用工具库",
    "在投信系中通过实用NPM模块转换为再线可以引用的免费服务",
    "CDN.js-deliver.night",
    "来加载TFGS和TFGS-WARS两个模块",
    "TFGS-WARS是tensurve-low.js进行牛软器可视化的一组实用工具库",
    "在于上面的HTML文件相同的文件假中",
    "创建一个名为indepth.js的文件 并将以下代码放入其中",
    "首先 需要加载数据 并对数据格视化和可视化",
    "要用于训练模型的数据",
    "从服务端或取Json文件中加载数据级",
    "数据级中包含了关于每量给定汽车的许多特性",
    "软韩数是项目的主韩数",
    "后面的功能将录序添加在这里",
    "通过MAP来获得将要进行训练的特性",
    "通过TFGS将数据会支撑3.2",
    "为了避免主策整个程序的执行",
    "可能耗试的韩数应当尽量使用 异补方式",
    "也就是FunctionGateData关键字之前的I'mSanite",
    "我们先读书据 其中这里边一个有9列",
    "他们分别都有对应的意义 例如MPG有号",
    "Solenders 器杆数量",
    "Displacement 排气量",
    "Wit 车众",
    "在我们可视化数据的时候",
    "我们会发现",
    "Original和Carding都是离散型的",
    "就没有选择他们进行一个现性活规模型的搭建",
    "除此之外 由于在HousePower中",
    "有一些值是存在问号",
    "我们就要选取那些不是问号的进行操作",
    "从3.2我们可以看出",
    "汽车的燃油效率与排量 重量 马力 反者都存在一定的现性关系",
    "其中汽车重量与燃油效率现性关系作为明显",
    "首先我们就利用HousePower一个单边量",
    "去构建现性回规模型 看看能否预测出来",
    "因為數據比較簡單,所以使用了兩層全連接網絡,只有功耗這一個輸入質,所以輸入的漲量形狀是1,輸出的神經元數量也唯一。",
    "UseBels是神經元全中計算中的偏質量,可以不用顯示,是唯處。",
    "Tancerflow.gf完整模仿了Carrots的模型定義方式,一種是用的TF.sequential,另外一種是TF.model。",
    "兩者的差別是TF.sequential是一個現性堆疊Layer的模型,而TF.model定義的神經網絡層一層之間的關係,較為隨意。",
    "首先實力化一個TF.sequential對象,然後調用APP的方法,為網絡添加一個輸入層。",
    "該輸入層將自動連接到具有隱藏單元的Dance.inputs.swip形狀唯一,因為有一個數字作為輸入,即給定汽車的功率。",
    "最後再添加一個輸出Dance.units,唯一,即輸出為一個數字由後。",
    "模型定義完成後,需要在亂含數中添加調用,並調用可視化工具提供的model Samaray方法,將模型顯示在流暖器中。",
    "在數據載入的時候,需要進行預出裡的工作。需要做數據規範化,並轉換為ThinSurf Low處理起來更高效的張亮類型。",
    "JavaSquarept語言,在大規模數據處理上,不如PASS很高效,其中最突出的問題是內存的回收。",
    "用戶對於流暖器的內存佔用,本身也是非常敏感的。",
    "ThinSurf Low.js為了解決這個問題,專門提供了TF.tid韓數。",
    "使用方法是把大規模的內存操作,放置在這個韓數的回調中執行。",
    "韓數調用完成後,TF.tid得到控制權,進行內存的清理工作,防止內存泄漏。",
    "首先,TF.youtube.shuffle方法,打亂數據集中數據順序。",
    "創建特徵項亮,InputThinSurf,與標籤項亮,LabelThinSurf。",
    "將原始數據轉變為ThinSurf Low可讀的張亮格式。",
    "最後,對輸入和輸出的數據,做規一化操作。保證後期更有效的訓練。",
    "訓練和測試的代碼與ThinSurf Low非常類似,一樣使用Model.fate韓數做訓練。",
    "以及Model.predict韓數做預測。",
    "模型訓練的過程和結果可以使用ThinSurf Low剛VIS圖表工具可視化出來。",
    "顯示在流覽器中,其中,訓練部分是使用毀掉韓數,目的是能夠動態的顯示訓練的過程。",
    "模型優化算法使用AdAM使用軍方差作為判斷訓練結果的參數。",
    "訓練模型採用分批採樣訓練,一次採樣32條訓練數據。",
    "便利所有樣本50次,Surf設置為處表示打亂數據級,最後設置了Coreback。",
    "可以在每一個訓練週期顯示訓練情況。",
    "在亂韓數,添加訓練代碼,可以看到最後的結果的分數,大約是0.69左右還是挺不錯的。",
    "剛剛我們是利用了單辨量的線性回歸模型。",
    "我們猜測,如果用多辨量的線性回歸模型,會不會更好呢?",
    "因為汽車的燃油效率與排量、重量、馬力、三者都存在一定的線性關係。",
    "同時可以考慮使用多個辨量,重新構建模型。",
    "在这个项目中,我们将度件一个Tencerflow.js模型,使用转机神经网络时别手写数字。",
    "首先,我们将通过让分类器观察数千个手写数字图片,机器标签来讯面分类器。",
    "然后,我们会使用模型从未见过的测试数据来评估改分类器的准确性。",
    "我们前面已经了解了手写数字数据级。",
    "这个项目的目标是,讯面一个模型,该模型会获取一张图片,",
    "然后学习预测图片可能所属的十个类中每个类的得分。",
    "十个类几数字零一到九。",
    "每张图片的尺寸为28成28项数,并只有一个颜色通道,因为这是灰度图片。",
    "因此,每张图片的形状为28、28、1。",
    "我们将创建一个使用Tencerflow.js在流暖器中讯面模型的网面。",
    "在我们提供特定尺寸的黑白图片后,该模型将对出现在图片中的数字进行分类。",
    "相关步骤如下,1.加载数据,2.定义模型的价格,3.",
    "讯面模型并监控其讯面时的性能,4.通过进行一些预测来评估经过讯面的模型。",
    "Tencerflow.js在其系列官网已经公开了诸多的例子,",
    "Minister项目是其中一个。",
    "从Github 课龙项目代码,以获取项目所需的HTML,JS文件和Page文件的赴本。",
    "第一是HTML文件。",
    "文件主要包含页面的基本结构,命名为Index.html。",
    "它包含一些DiWay 标签,一些UI元素以及一个原标签。",
    "以Java Scrub 的代码擦入例如Index.js。",
    "DS代码通常分为几个文件,以提高良好的可独信。",
    "用于更新可视化元素的代码,位于UI.js中。",
    "而用于下载数据的代码,位于Data.js中。",
    "第三个重要文件类型是软件包配置文件,Package.json。",
    "就是NPM 软件包管理器。",
    "在Minister 代码幕录中包含以下文件,1,Index.html。",
    "它是HTML 跟文件,提供DiWay跟并调用JS 脚本。",
    "二,Index.js 是跟文件,用于加载数据定义模型,讯战循环并指定UI元素。",
    "三,Data.js 实现下载和访问Minister数据级。",
    "四,UI.js 用于更新可视化元素。",
    "五,Package.json。软件包配置文件,描述了构件和运行此事例所需的依赖项。",
    "创建Index.html 文件,Index.js 文件,考卑TFGS.x3.0,Minister 目录项Data.js 文件。",
    "Index.html 文件中,使用脚本代码在流暖器项目中或许Tensorflow.js 以及TFGS 当VAS。",
    "许多加拿Scrib的开发者,清相于使用NPM安装依赖项。",
    "并使用滚榜器不见项目。",
    "加拿Scrib的开发者,也可以通过NPM安装分色肤楼.js和TFGS.xVAS。",
    "在上述HTML文件所在的文件加州,创建一个名为Data.js 的文件。",
    "实现了预处理数据,其中包含了Minister Data Lay。",
    "从Minister数据集中,随机批量提取Minister图像。",
    "Minister Data将整个数据集分为训练数据和测试数据。",
    "当训练模型时,分类器将使用训练集进行训练。",
    "在评估模型时,使用测试集中的数据,以检查模型对新数据的犯化情况。",
    "Minister Data有两个Public方法。",
    "Next to green batch方法,从训练集中,反回一批随机图像,机器标签。",
    "Next to test batch方法,从测试集中,反回一批图像机器标签。",
    "在训练Minister分类器时,为了模型的预测将不受图像的市论区的影响,随机打乱数据集是非常重要的。",
    "例如,如果首先将所有1位数字提供给模型,那么在此阶段的训练中,模型可能会学会简单的预测1。",
    "如果我们只给模型提供2,它可能会简单的转换到紧预测2,并且从不运测1。",
    "3.0",
    "同學們好",
    "上集課我們介紹了QT的基本情況",
    "QT最突出的特點就是其強大的跨平台功能",
    "我們只需要開發一次運用程序",
    "就可以在不同系統上進行部署",
    "QT API在所支持的平台上使用都是相同的",
    "QT工具在這些平台上使用方法也是一致的",
    "因此QT應用開發與平台沒有關係",
    "但是到我們部署的時候",
    "我們需要為QT應用來準備它的相應的開運行環境",
    "Mini24.0默認安裝了一個可托培系統",
    "可托培最初是Source4G上面的一個開源的項目",
    "它是構建於QTInbadi的職商的一個類似",
    "揪面系統的應用環境",
    "可托培有幾個版本",
    "一個是應用與技能手機的手機版本",
    "另外一個是PDA的版本",
    "第三個就是消費電子類版本",
    "可托培包含了完整的應用程",
    "靈活的用戶介面",
    "創起操作系統",
    "應用程序啟動程序以及開發框架",
    "我們需要在Cellos的主板上運行QT程序",
    "就需要QT的運行環境",
    "因此我們來交叉編譯QT",
    "交叉編譯QT首先需要交叉編譯器",
    "即使是4.3.2",
    "另外還需要QT的圓碼",
    "QT的圓碼我們可以在QT官方網證上面下載",
    "還有一個是TSLiber",
    "這個是充模頻的程序",
    "下面分三個步驟",
    "第一步是交叉編譯QT4",
    "然後調步我們需要把QT4",
    "考配到2040的文件系統當中",
    "第三步就是在2040上面運行",
    "我們QT4編譯的勢力程序",
    "在編譯QT4.7之前",
    "我們先會編譯TSLiber",
    "TSLiber是一個充模頻驅動",
    "我們可以通過GETMING 直接下載下來",
    "把TSLiber的圓碼",
    "然後在TSLiber 墓入下面有一個配置腳本",
    "下去是MACMAC install",
    "這個還是比較方便的",
    "下面我們來試一下",
    "我們通過GETMING 直接把TSLiber 圓碼下載下來",
    "現在我已經下載好了",
    "在TSLiber下面有一個配置的腳本",
    "就是這個腳本",
    "首先我們運行這個腳本",
    "現在出錯了是手裝人件了",
    "我們用FTG去裝一下",
    "總是用翅膀的記憶上",
    "還有這一張小布",
    "所以車程改煞到",
    "說起將會易用",
    "另一娛樂車的篩子",
    "即即HAPPY",
    "召唤以后我们再运行",
    "再去我们再运行考庇一个命令",
    "召唤以后我们再运行",
    "然后是Mac and Mac and Store",
    "下去我们就可以兵议QT4.7了",
    "在兵议之前我们首先也需要配置一下",
    "第一个我们配置的是这一句",
    "这个是配置安装目录的在opt下QT4.7",
    "这个我们可以自己改一下",
    "这就是指名我们的交叉兵器",
    "是Linux ARM刚即加加",
    "然后还有一些是有一些模块",
    "我们可以选择一下",
    "有些模块我们是需要的",
    "我们就把它选上",
    "这样就是把这个Liber就选上了",
    "然后我们如果前面加上node的话",
    "就是把这个模块给取消掉了",
    "就不需要它",
    "QT的下载我们可以在QT的官方网站上面下载",
    "上面有所有的版本都有",
    "从1到最新的是5.9的QT的版本",
    "然后我们是下载QT4.7",
    "因为现在名里24.0它整个文件系统里边",
    "所有使用的都是QT4.7的",
    "当然我们也可以下载一个其他版本",
    "试一下就下这个QT4.7就可以了",
    "下载好以后我们把它解压出来",
    "我已经把它靠在OPTWOKEMULU下面了",
    "然后我们用TA把它解压出来",
    "QT的圆码包还是很大的",
    "我们下面也是要config",
    "首先提示你是否接受协议",
    "我们说Yes",
    "下面进行配置了",
    "下面进行配置了",
    "现在我们要做的就是Mac跟Mac Insta",
    "整个QT便宜一下估计要一个小时左右",
    "所以我们现在在9不演示了",
    "如果Mac的话",
    "然后它还提示QT将安装到OPTQT4.7这个目录底下",
    "就是Mac Insta的时候我们把安装的内容就安装到这个目录底下了",
    "Mac时间会非常长",
    "便宜好以后我们需要把QT这个目录烤背到线路是主板上面",
    "也就是烤背到它跟文件系统下面去",
    "这个文件还是比较大的",
    "在有三支笔其固的跟文件系统里面已经有一个QT4.7",
    "这个运行环境已经有了在里边",
    "我们可以先把它压缩打包一下",
    "然后我们把它烤背到跟文件系统里边",
    "我们可以用FTP下载下去或者用SD卡烤在先烤在SD卡然后再烤进去",
    "在有三支笔其固的跟文件系统里面它原来是把QT放在OPT目录底下的",
    "我们看就是这个目录QT4.7",
    "然后可托配是放在OPT底下的",
    "这是可托配的文件的内容",
    "这是QT整个运行环境都是放在这个里边的",
    "现在我们已经有了",
    "所以我们没有必要在往里边烤了",
    "如果没有的话就是把刚才我们编一好的OPT底下的那个QT4",
    "其实那个目录我们要把它烤到这个跟文件系统下面去",
    "如果我们要把它烤到OPT底下的安排组织里边的话",
    "我们就需要用FTP把它下载",
    "因为这个文件比较大",
    "所以烤下去还是满花时间了",
    "整个文件大概由40 到50 左右的空间",
    "最后一步我们就可以在",
    "签论是主板上运行我们的QT程序了",
    "我们是用QT它编移的势力程序来运行一下",
    "然后运行程序的话关键我们是要设置一下环境变量",
    "通常我们会编写一个角本",
    "主要是设置环境变量的",
    "系统首先运行起来的是QTPR的介面",
    "然后我们可以看一下并一目录底下它有一个QTPR的配置文件",
    "就是这一个啟动配置文件QTPR的",
    "在我们运行客T程序之前我们所谓的一个机器",
    "是我们的机器",
    "我们可以把这个机器的机器放在这个机器上",
    "然后我们可以把这个机器放在这个机器上",
    "所以我们可以把这个机器放在这个机器上",
    "然后我们可以把这个机器放在这个机器上",
    "在我们运行客T程序之前我们首先要设置一下环境变量",
    "其中最主要的就是设置寸模屏驱动的",
    "另外还有就是QT目录",
    "在这里边是我们是可托片",
    "我们要把这个把它改掉",
    "因此我们自己修改一下",
    "我们修改一个角本就是四个角本",
    "在这里边我们指定QT是OPT的QT4",
    "这是QT的",
    "我们换到还是换到原来迅你机的中端",
    "首先我们看不设置角本我们看",
    "这是一个QT的一个是里程序",
    "刚刚QWS",
    "这个时候就提示我们库刷了",
    "就是有个切试",
    "这是一个充平的库刷它找不到",
    "我们这个",
    "路径没有告诉它",
    "所以我们要把这些配置文件考复一下",
    "这是最简单的方法",
    "你也可以做个角本自己运行一下",
    "这样也可以",
    "然后我们再来运行",
    "看好这个位置",
    "看好这个位置",
    "这是一个中的程序",
    "东学们回去可以试一下",
    "第一步我们可以先使用",
    "有三支比取攻的QT4.7这个墨路",
    "然后用它墨路底下的测试程序",
    "我们试一下",
    "先把这个程序能够运行起来",
    "然后我们再重新编移QT",
    "把编移好的我们在器坏原来的QT4.7那个墨路",
    "然后再测试一下",
    "如果你一开始就器坏了的话",
    "你可能不知道是哪里出了问题了",
    "因此我们先能把程序运行起来",
    "然后我们再次换了再试一下",
    "看能不能运行起来",
    "测试一下这个过程",
    "今天我们的课就上到这边",
    "同学们再见",
    "中學猛好,上結課我們為QT準備了運行環境,這結課我們將學習怎樣來兵以一個QT程序",
    "QT有一個非常重要的項目管理工具,就是QMAC,QMAC是用來為不同的平台和便宜器,輸血MAC file工具",
    "我們手寫MAC file是比較困難,而且非常容易出錯的,尤其是需要給不同的平台和便宜器組合寫幾個MAC file的時候",
    "QMAC可以利用原文件,生成各種不同類型的工程以及工程所需要的MAC file文件",
    "使用QMAC我們首先可以創建Dempro項目文件,把項目所需要的原文件添加到工程裡面",
    "而且我們還可以設定平台相關的不同原文件設置各種規則",
    "然後由Dempro項目文件生成MAC file文件,MAC file文件保存了便宜器和連機器的參數選項,還表述了所有原文件之間的關係",
    "下面我們將學習如何使用QMAC來便宜我們的QT程序,然後我們在學習配置QT Criter",
    "下面我們首先來學習QMAC的使用",
    "現在我們有兩個QMAC,第一個是插865平台的,它的路徑是在QSDK裡面,我們先看一下",
    "這個非常關鍵,我們不同的平台使用的是不同的QMAC,現在我們先看插865平台的,在OPTQTSTK",
    "剛2010.05QT,然後在這個目錄底下我們有一個QMAC,這個大家記住是插865平台的",
    "然後是切錄是平台的,是在QT4.7,就是我們便宜出來的那個目錄裡面,在也是在便宜裡面",
    "這邊的這個QMAC,這個是我們慶祝式的QMAC",
    "我們首先使用插865平台的來便宜一個程序",
    "在QT4.7目錄裡面有一個彰姆斯,在這裡邊有很多的例子,我們可以從這個裡邊先考一個例子出來",
    "我現在已經把它考過來了,首先我們先MACCLEAN一下",
    "然後把這個硬程序也刪掉它",
    "File文件我們也把它刪掉了",
    "這樣看得清楚一點,首先我們先看一下QTMAX版本",
    "QTMAX剛V,我們看一下,現在我們看是OPTSTK",
    "說明我們現在使用的是插865平台的,下面我們來運行QMAC",
    "直接QMAC就可以了",
    "這個時候我們看又生成了一個MACFile文件",
    "接下來就要去我們MACCLEAN型",
    "便宜",
    "然後我們運行一下這個程序",
    "這就是我們一個程序,因為現在我們是插865平台便宜的,所以我們是可以運行的",
    "下面我們再來改把它交叉便宜",
    "交叉便宜我們先要改一下環境變量,剛才我們設置的環境變量是SDK目錄下面的",
    "我們改LUT下面的",
    "BSHRC",
    "好看這幾句,剛才我們指定的是OPTSTK",
    "QTB並這個目錄底下的,現在我們要把這個要租掉它",
    "我們現在要指名的路徑是OPTSTK",
    "並而也就說使用這個清律師",
    "清律師的QMAC",
    "還是先檢查一下",
    "QMAC剛V先檢查一下",
    "你確認你要便宜是什麼版本的,你就要確定你使用的QMAC是否正確",
    "現在我們使用了OPTSTK",
    "QT407的,所以是沒有問題",
    "然後我們再來便宜還是先MAC clean",
    "然後把MAC file我們也清,3了它",
    "不3,問題有不帶,會覆蓋的",
    "MAC",
    "然後我們再來便宜",
    "我們看現在用的便宜器,便宜器已經是Online X加加了",
    "所以現在這個可信程序在W平台下面已經不能用了",
    "顯示無效的二進指紋件",
    "我們可以把它考到訊息機裡面",
    "讓它運行一下",
    "下面我們再來看一下在QT Criter裡面的設置",
    "我們打開一個工程",
    "我們可以看一下這個工程文件",
    "工程文件裡面主要第一個是指定我們的頭文件",
    "就是我們原程序的頭文件",
    "然後是原程序的原文件",
    "在項目裡面我們會有對它進行配置",
    "我們看現在我們有兩個",
    "第一個是桌面系統的",
    "桌面系統的有構建和運行構建",
    "構建就是我們常說的便宜",
    "這是桌面環境,或者我們也叫X86環境的",
    "另外就是MBA的Linux",
    "乾淨是Linux的環境",
    "我們選這個的話就切換到乾淨是Linux",
    "最主要的我們看還是這個QT的版本",
    "在這裡邊我們看兩個QT版本是不一樣的",
    "一個是QT4.7的另外一個是QT",
    "這個在哪設置呢",
    "是在工具裡面進行設置的",
    "工具QT版本在這個位置",
    "先把它刪掉",
    "刪掉",
    "這邊也刪掉",
    "我們可以手工設置",
    "首先我們就是選",
    "就是剛才",
    "已經給大家看過了在OPT下面",
    "我們先是插8.6環境的",
    "在這個QTSDK裡面",
    "然後是QT",
    "然後是BINQMAC",
    "我們選中這個QMAC把它打開",
    "這是第一個插8.6環境的",
    "然後叫一個我們添加",
    "也是在OPT",
    "是在QT4.7",
    "BINQMAC打開",
    "這個是QT4.7的",
    "然後應用確定",
    "另外還有一個是工具鏈",
    "工具鏈就是邊壹氣",
    "我們所使用的邊壹氣",
    "如果沒有自動檢測的話",
    "我們同樣也可以手工添加",
    "就是添這個愛的手工添加",
    "確定",
    "這要我們就有兩個平台",
    "一個是插8.6平台",
    "另外一個是QT4.6平台",
    "我們先來邊壹插8.6平台",
    "現在插8.6平台顯示",
    "無效的QT版本",
    "我們要把它選上QT4.7",
    "把它選上",
    "好 選上了以後",
    "我們在這邊",
    "這個是構建",
    "這個是運型",
    "構建就相當於邊壹",
    "我們先來",
    "邊壹 然後運型",
    "邊壹 然後定運型",
    "就要我們就顯示出這個",
    "程序就運型起來了",
    "這是一個模擬始終的",
    "這是周面環境的",
    "如果我們選擇",
    "簽入式的話",
    "在這邊就只能編裔了",
    "因為沒有辦法運型",
    "我們要把它考到",
    "訓練機裏面才能夠運型",
    "邊壹 好以後",
    "我們把這個運用程序刪掉它",
    "重新編裔的話",
    "我們把它刪掉",
    "最好是",
    "MACCLEAN一下",
    "清空",
    "也沒有供具鏈",
    "我們把供具鏈先選上",
    "現在我們加它編裔的話",
    "是使用這個",
    "CLEAN STAIN 7",
    "先清空",
    "然後我們再重新過見",
    "這個時候運型就運型不起來了",
    "因為這個是",
    "簽入式版本的",
    "這邊是沒有辦法運型",
    "我們可以把它考到",
    "訓練機裏面去運型",
    "這幾顆我們學習了",
    "CLEAN MACCLE的使用",
    "以及CULT CREATE的配置",
    "我們編裔了壹個勢力程序",
    "同學們回去以後",
    "也可以試一下",
    "從CULT CREATE的目錄底下",
    "把勢力程序把它",
    "考背幾個出來",
    "把它壹個的編裔一下",
    "然後編裔好了",
    "再把它考到",
    "簽入式版本的上面",
    "再把它運型壹下",
    "一定要測試壹下",
    "是否編裔成功了",
    "學會這個過程以後",
    "我們以後不管",
    "怎樣複雜的程序",
    "我們也可以",
    "自己來編裔",
    "然後把它",
    "壹直到",
    "簽入式版本的上面",
    "好",
    "同學們",
    "今天的課我們就上了這邊",
    "同學們再見",
    "从这节课开始,我们给大家介绍一下签论式的 GUI冰程,就是图形用户界面的冰程。",
    "在签论式系统中, GUI的地位也越来越重要,但是不同于桌面系统。",
    "签论式系统的硬件资源是有效,因此签论式的用户界面要求简单直观,可靠,再用资源小冰淇淋反映迅速。",
    "感谢齐聚公司为我们提供了QT,无论是专业的程序开发人员,还是编程爱号者,他们都希望自己编写的程序可以流畅的运行与各种平坦。",
    "QT在这一方面出种的表现,令我们印象深刻。",
    "利用QT提供的西加加英雄程序开发框架,可以轻松的实现,一次编写随处编绎的跨平台解决方案。",
    "使得我们的英雄程序能够完美的运行与各种平台之上。",
    "下面我们看一下QT的发展历史。",
    "在1991年的时候,Howver的开始开发QT,他提出了信号跟朝的概念并且开发出了第一个图形的核心。",
    "在94年的时候,成立了齐聚公司。",
    "2008年,齐聚公司被诺家公司收购,QT因此成为诺家旗下的冰层员工具。",
    "在2009年12月1日,诺家发布了QT4.6。",
    "2012年,QT又被迪迪来收购。",
    "2014年,跨平台去升开发环境QT Create 3.1证实发布,并且实现了对IOA4的完全支持。",
    "2014年,5月20日,QT开发团队宣布QT5.3证实发布。",
    "QT现在有四种版本。",
    "第一个就是文山奥的,它是用于文路士平台。",
    "另外是X11版,它是用于X系统的各种Linux和Unix平台。",
    "第三个是Mac板,它是用于苹果的IOA4系统。",
    "最后一个就是X版本,Inbadi的版,它是用于X系统。",
    "QT是一个庞大的跨平台开发框架,它提供了非常丰富的习家家力。",
    "我们看一下这个框架图,最底下是QT Core,它提供了核心的飞机外功能,所有模块都需要它。",
    "这个模块它提供了动画框架,定是器,各种容器类,时间日期类,事件,参见机制,图形,线程,XMNL等。",
    "在左边两个,第一个是QT Test,它提供了QT程序的单元测试功能。",
    "另外一个是QT Circle,它提供了使用社口访问数据库。",
    "在右边最上面QT WebCate,这个是Web流冷器引擎,它提供了显示和编辑Web内容。",
    "这就是QT Multimedia,这个是对Dormity的支持。",
    "QT QML提供了公QML使用的C家家Appi,QML是一种脚本语言。",
    "QT Quick是一种基于QT的高度动画的用户界面。",
    "适合与移动平台开发。",
    "QT Network它提供了跨平台的网络功能。",
    "QT Great,这个是其公Gi程序的基本功能,包括与窗口系统的集成,事件处理等等,就是跟窗体相关的。",
    "QT还提供了QT Great,QT Great是一个跨平台的完整的QT级程开发环境。",
    "包括了私家家的代码冰机器,项目和生成管理工具,集成了像下文相关的帮助系统,图形化的调试器,代码管理和流冷工具等。",
    "QT Great的主界面,下面我们简单的介绍一下QT Great的界面,还有它的一些功能,给大家做一下简单的介绍。",
    "QT打开以后主界面就是这样的,在上面是菜单,菜单项。",
    "在它左边,这个位置是一个叫模式选择器,在这里我们看有几种模式,这个是我们可以选的。",
    "这边是固件套件的选择器。",
    "这个我们叫定力器。另外还有输出窗口,这边是用于输出的各种输出信息的。",
    "首先看一下模式选择器,第一个是欢迎介面。",
    "在这边我们看有几个,第一个是入门。",
    "这里面主要是一些文档,我们可以打开看一下,因为这里面文档都是英文的,QT文档很全,全都是英文的。",
    "这个主要是第一个创建宵母,这个是打开宵母,打开右的宵母,这边是我们已经打开过了的宵母。",
    "第三个是例子,这里边的例子大家可以看一下很多。",
    "第四个是教程,有一些简单的教程,大家也可以看一下。",
    "第四个是我们最主要的一个工作区,就是编写代码的地方,这边是我们的项目,我们同时可以打开几个项目,可以打开多个项目,每一个项目我们看都有投文件,原文件,其他文件。",
    "如果有界面的话,我们就还会有一个界面文件。这是我们最主要的一个工作区,就是编写代码的地方。",
    "第三个设计,这个是用于设计我们界面文件的。",
    "第1个项目因为我们没有界面文件,所以这边是灰的,有的同学怎么觉得我的实际界面没有不能用,不是不能用,是因为你没有界面。",
    "如果我有界面文件的话,我们打开界面文件,这个时候就转到我们是实际界面了。",
    "实际界面是用于我们界面设计的。在这里边我们可以进行部件属性的设置,比如我放了一个按钮罢屏,在这边是我的属性,属性窗口。",
    "另外我们还可以进行信号跟草的设置,还可以进行布局设置等等。",
    "加去一个调试窗口,当我们调试的时候,我们可以用到。",
    "还有是项目,这个是进行项目配置的。",
    "项目配置的,我们要进行构建的设置,运行的设置,并计器的设置,代码风格的设置等等。",
    "并计器代码风格依赖关系。",
    "还有一个是分析模式,分析模式在这里边我们看有一个是QML的分析器,另外还有内存分析器。",
    "最后一个是帮助,帮助。",
    "大家也应该习惯看这些帮助,因为QT的类优很多,我们不可能每个类都非常熟悉。",
    "如果有不会的,我们就可以在这里边查一下。",
    "在固件套件选择器里边有4个按钮,第1个按钮是误标选择器,第2个按钮是运行按钮,第3个是调试按钮。",
    "最后一个是固件按钮,固件按钮我们就可以把它理解为是编移按钮。",
    "按了以后它就开始编移了。",
    "运行按钮就是运行程序的,我们运行点了运行以后我们的程序就开始运行了。",
    "第1个目标选择器,目标选择器里边我们可以选择第8个还是Release,就是调试版本还是发布版本。",
    "如果我们多个QT项目的话在这边我们还可以选择多个项目,我们要调试哪一个项目。",
    "并且我们每一个项目都会有两个版本第1个发布的第2个是调试的。",
    "如果我们有多个QT版本的话我们还可以选择QT的版本。",
    "这集课我们简单介绍了一下QT的情况,同学们回去以后可以打安装QTCREATE,",
    "安装了试一下,我们可以下载里边的例子,QTC它自带了很多的例子,这些例子也非常的有用。",
    "我们把它下载下载然后便宜运行一下,主要是要熟悉一下QTCREATE的机程开发环境,以后我们会一直会使用到它。",
    "这集课我们就上到这边,同学们再见。",
    "【鋼琴音】",
    "大家好",
    "上集课我们学习了CleMAC",
    "以及对CleMAC的配置",
    "我们学会了如何编译CleMAC程序",
    "这集课我们将来编写一个最简单的程序",
    "HelloQT",
    "如果你已经学会了Java或者CiSharp编程的话",
    "那你会很容易的掌握QT的编程",
    "C家家语法从表面上看",
    "与Java或者CiSharp的语法是非常相似的",
    "他们有相似的数据类型",
    "同样的运算符以及同样的基本控制流程语言",
    "但是从深层语上来讲",
    "这些概念又稍微有些不同",
    "比如如何定义类",
    "如何使用紫针和引用",
    "如何从载运算符",
    "如何使用预处理器等等",
    "如果你对C家家语法不熟的话",
    "你应该先学习一下C家家的语法",
    "QT它使用的是标准的C家家语法",
    "下面我们来冰淇一个最简单的QT程序",
    "HelloQT",
    "首先我们要使用两个头文件",
    "第一个是QApplication",
    "第二个是QLib-O",
    "这个是 QLib-O",
    "这个不是QAppLib-O",
    "处理器的通它的外",
    "确实是告诉7 mercy",
    "它有两个概念",
    "1万才孙",
    "左韓速路第一件是要创建一个application",
    "用来管理整个应用程序所用到的所有的资源",
    "application製造韓速需要两个参数",
    "就是没韩素传辑进来的两个参数",
    "我们创建了一个qlivo的标签",
    "在qt里边我们把这个叫Weget 窗口部件",
    "这个数与跟cchap里面的空间是类似的",
    "在文多式里面通常会把它叫做空间",
    "或者叫做容器",
    "像按钮菜单滚动条框架",
    "这个都把它叫做窗口部件",
    "就是Weget",
    "Weget在qt里边它是一个非常重要的概念",
    "我们现在先看第一个就是一个qlivo标签",
    "它就是一个窗口部件",
    "同样我们是窗见",
    "然后在它的够赞韩素里边输入了要显示的内容",
    "Helloqt",
    "绝大部分的应用程序",
    "我们会使用QMando 或者QDialog来作为窗体",
    "但是Qt它是非常的灵火",
    "任意的窗口部件我们都可以把它作为一个窗体",
    "现在我们只是一个标签",
    "我们同样也可以把它作为一个窗体",
    "然后我们需要显示",
    "在窗见窗口部件的时候通常都是隐藏的",
    "我们必须要让它显示才会显示到屏幕上面",
    "就是用Dialog 它的一个方法秀",
    "最后我们要用一个窗口的方法称",
    "然后我们要用一个窗口的方法称",
    "最后我们要将应用程序的控制权传给Qt",
    "这样我们一个程序一个最简单的程序就完成了",
    "完成了以后我们用QMAC来生成工程文件",
    "现在我们只是点CPP文件",
    "我们需要生成一个工程文件",
    "带上参数",
    "生成一个点CPRO的工程文件",
    "然后我们再进行QMAC来生成MAC 5文件",
    "然后我们有点CPRO文件然后MAC 5文件",
    "我们可以先MAC clean清楚一下",
    "这样我们就可以打开工程文件",
    "一般我们都会使用工程文件",
    "现在我们看这些变量都没有变颜色",
    "没有变颜色",
    "当我们使用工程文件打开以后",
    "它会变颜色",
    "我们在边域以后",
    "所有的类它都会显示颜色",
    "然后支援的颜色",
    "重新过进",
    "再去运行",
    "这个创题非常小",
    "我们看这边一点点",
    "一个HelloQT",
    "下面我们再介绍另外一个",
    "就是使用它的向导来创建",
    "同样还是一个HelloQT",
    "我们把关掉",
    "我们把这里边",
    "创建它有模板Application",
    "然后是Gray運用",
    "图形界面的应用QT",
    "Gray運用选择",
    "选择一个工程的名字",
    "下一步",
    "这个是目标设置",
    "同样是桌面还是千论是NX",
    "我们现在还是选桌面",
    "这个是我们会选择一个类名",
    "机类QT",
    "向导里面提供了三个",
    "第一个是QManWindow",
    "然后是QTQ widget",
    "QDialog",
    "QDialog跟QManWindow",
    "都是继承与这个VGT",
    "都是继承与这个VGT",
    "QManWindow就是我们一个组的",
    "然后下面我们看这个QT",
    "整个后面的这个框架",
    "它有菜单",
    "有状态条",
    "然后有主要的",
    "工作区域部分",
    "这个我们把它叫做ManWindow",
    "主创体",
    "Dialog就是现在我们这个显示的",
    "就像当一个Dialog对话框",
    "然后我们现在选Q widget",
    "W widget",
    "完成",
    "MainWindow",
    "我们看就是一个MainHan数",
    "跟我们刚才还是类似的",
    "这个依据是类似的创建了一个Precation",
    "然后Return",
    "当中就是创建了一个VGT",
    "然后VGT的点秀",
    "我们刚才是创建了一个标签",
    "然后把标签写出来",
    "在",
    "W widget点CPP里边",
    "就是购赏韩数跟CKK韩数",
    "这里边没有什么内容",
    "然后还有一个界面文件",
    "这个时候我们就可以直接拖一个",
    "创建部件上去",
    "还是用这个LiveWord不要签",
    "然后我们在",
    "这边是我们创口部件的一个",
    "修改修行的地方",
    "找到它的修行Atext",
    "在这边我们修改",
    "这样",
    "等于我们把边一下包成",
    "现在我们看这个LiveWord这个标签",
    "它是放在我们这个创建部件上面了",
    "所以这个是后面它有一个整个的一个创建部件",
    "就是这个区域",
    "就在这里边这个区域",
    "然后在这个上面我们放了一个LiveWord不要签",
    "跟我们刚第一次那个程序有点不一样",
    "这解课我们学习了一个最简单的QT程序",
    "HelloQT",
    "同学们回去以后可以自己试一下",
    "我们也采用两种方法",
    "一种就是使用存代码的方法",
    "另外一种就是我们使用图形界面",
    "通过工程相达来生成一个QT的程序",
    "QT可以完全不使用图形界面",
    "我们就通过存代码也可以编达一个非常复杂的一个",
    "就是图形界面的程序",
    "这个也是QT的一个特点",
    "这解课我们就上了这边同学们再见",
    "词曲",
    "同学们好",
    "今天我们学习QT里边的一个非常重要的概念",
    "信号预朝",
    "信号预朝是QT不同于其他开发框架",
    "最突出的一个特征",
    "它主要是用于两个对象之间进行通讯的",
    "我们希望任何对象都可以和其他对象进行通讯",
    "比如当用户单击了关闭按钮",
    "只希望可以执行窗口的口子韩素来关闭窗口",
    "为了实现对象间的通讯",
    "一些工具它使用了回掉机制",
    "但是QT它使用了信号和朝来进行对象间的通讯",
    "当一个特殊的事情发生的时候",
    "并发射一个信号",
    "比如现在我们是单击了",
    "如果手标单击了这个PosaryBoton",
    "就是我们要退出应用程序了",
    "当我单击它以后",
    "这个PosaryBoton它就会发射一个Click信号",
    "单击这个信号",
    "把它这个信号发射出去",
    "朝就是一个韩素",
    "它在信号发射后被调用来想硬这个信号的",
    "信号的发送者不知道",
    "它也没有必要知道接收信息的视随",
    "在信号跟朝之间",
    "他们之间的参数必须要匹配",
    "就是一一要对应起来",
    "信号和朝可以使用任意类型",
    "任意数量的参数",
    "通常我们一个信号对应一个朝",
    "但实际上一个信号",
    "它可以关联到多个朝上",
    "多个信号我们也可以关联到同一个朝上",
    "甚至一个信号",
    "我们还可以关联到另一个信号上面去",
    "如果存在多个朝和多个信号相互关联的话",
    "那么当这个信号被发射时",
    "这些朝将会一个一个的被执行",
    "但是这个执行它是随机的",
    "没有办法去指定他们的执行的顺序",
    "Qt本身已经定义了大部分",
    "我们朝用的信号跟朝",
    "但是我们自己也可以定义信号跟朝",
    "在定义信号的时候",
    "我们必须要使用新狗关键字",
    "因为只有定义该信号的类",
    "还有它的指类才能够发射这个信号",
    "信号只需要声明",
    "我们不需要也不能对它进行定义和实现",
    "另外信号它也没有返回值",
    "发射信号的时候",
    "我们需要使用Emit关键字",
    "它的格式就是Emit",
    "后面就是信号的名字",
    "跨号里边是信号的参数列表",
    "只有QtOp2的类集籍指类",
    "派生的类才能够使用信号和朝机字",
    "使用信号和朝还必须在类声明的开始",
    "处天家QtOp2的红",
    "声明一个朝韩素",
    "我们是使用slot关键字",
    "一个朝韩素可以是Private",
    "或者Public类型的",
    "朝也可以声明为虚韩素",
    "至于普通的成员韩素是一样的",
    "也可以像调用一个普通韩素一样来调用朝韩素",
    "朝的最大特点就是可以和信号来进行关联",
    "信号和朝使用connected以具来进行关联",
    "connected",
    "以具它包含了四个参数",
    "第1个参数是send发送者",
    "是指发出信号的对象的指针",
    "这2个参数是single",
    "就是它发哪个信号出去",
    "然后是receiver接收者",
    "两个对象一个是发送的",
    "一个是接收的",
    "这个信号发给谁",
    "就是这个receiver",
    "是指接触信号的对象的指针",
    "然后是slot",
    "对应的朝就是这个对象接收到这个信号以后",
    "它就会调用这个朝韩素",
    "这个朝韩素就开始工作了",
    "信号和朝我们必须要通过connected",
    "这个语句来进行关联",
    "四个参数第1个参数就是发送信号的对象",
    "第2个参数是要发送信号",
    "就是这个对象我要发出什么信号",
    "第3个参数是接收信号的对象",
    "最后一个参数就是指信的朝",
    "当我这个对象接收到信号以后",
    "我要去指行什么事情",
    "就是在朝韩素里面定义",
    "下面我们通过一个简单的例子来收明信号跟朝",
    "我们先建一个工程",
    "听家两个空间",
    "一个是华条",
    "另外一个我们在听家的进度条",
    "pogless",
    "现在有两个窗体空间",
    "窗体部件",
    "QT叫窗体部件",
    "一个是华条",
    "现在这两个我们现在运行一下",
    "运行起来了",
    "这个华条华了以后",
    "我们看跟底下是没有关系的对吧",
    "我们现在要建立信号跟朝",
    "这个是华条它是发送信号的",
    "当它移动的时候",
    "移动的时候就是这个直发生变化了",
    "然后它会发出这个信号",
    "告诉底下的进度条",
    "我们进度条跟上面的这个直一起变化",
    "就是它是发送者",
    "它是接收者",
    "它发一个信号是直变化了",
    "这个我们就是CatValue相当于设置直",
    "根据它的直设置我们进度条的这个直",
    "下面我们就是要建立关系",
    "下面我们通过ConnectHansu来连接",
    "第一个是华条",
    "这个是对象发送者",
    "然后我们是发送的信号",
    "在这里边我们没有定信号",
    "这个是系统定义的",
    "信号是发流倩具的",
    "再吃点东西",
    "接收者是我们的Progress",
    "它对应的槽",
    "这个槽我们也没有定义,也是系统定义的",
    "是CATV6",
    "好,这样我们建立起来联系了",
    "就是划条发出一个信号",
    "当它直发生改变的时候",
    "它会发出一个信号",
    "然后我们的进度条就会根据它",
    "根据它发出的整形数据",
    "我们按照它的整形数据",
    "来CATV6",
    "就是说重新设置我们的直",
    "好,下面再来边形一下",
    "えっ,岛楼侧发了",
    "多了夸好了",
    "找了个夸",
    "好 再来",
    "现在我们看 刚刚才情况不一样",
    "它发出信号",
    "当上面我拉动这个华条的时候 直就变了",
    "然后我们的进度条就根据它一起变化了",
    "这是有信号 一个草",
    "我们再来添加一个 添加一个进度条",
    "相当于一个信号两个场",
    "再来添加一个 这个是",
    "好",
    "我们还要来",
    "连接一下",
    "其他都有变 就是这个位置我们要变一下",
    "现在发送信号的还是这个华条 实在是来的",
    "但是朝我们会有两个 有两个processor",
    "Progress 办",
    "现在我们看两个同时一起动了",
    "这里信号和草还有一个简单的方法",
    "我们可以使用这个编辑信号跟草",
    "我们把这个语句三调谈",
    "我们把这个三调租调谈",
    "使用这个",
    "先把它选上",
    "然后我们往下拖",
    "这个时候就调出一个配置的窗口",
    "在这里边我们选 这个是Wire Change",
    "这边是SetWire 确定",
    "把这两个就建立起了",
    "信号跟草就建立 连接好了",
    "另外我们再可以试一下下面",
    "明到下面这个同样一次 信号",
    "草 确定",
    "然后我们再运行一下",
    "跟刚才效果是一样",
    "效果是一样",
    "这个是我们使用这个快捷方式",
    "然后还有一个我们有连接",
    "也有取消连接",
    "取消连接就是Disconnect",
    "后面参数是一样",
    "扶着一个",
    "Connect是连接",
    "Disconnect是取消连接",
    "我们来看一下刚才两个是一起变化的",
    "我们现在是在见面里面已经把它连接好了",
    "然后又Disconnect",
    "把All给Disconnect取消连接",
    "我们看只有一个动了",
    "只要它没有变化",
    "因为我这边已经Disconnect取消连接了",
    "刚才我们通过一个例子学习了信号",
    "通讯们回去以后可以自己定义信号跟草",
    "再测试一下",
    "我们使用的是系统已经定义好的信号跟草",
    "因为没有自己定义",
    "通讯们可以自己定义一下",
    "今天我们的课就上了这边",
    "同学们再见",
    "ThanThanFlow.gts是一个用于使用加娃Squript进行机器学习开发的库",
    "用于在流览器和Note.gts讯论和部署机器学习模型",
    "ThanThanFlow.gts支持使用加娃Squript在流览器端部署",
    "也与微信小程序有很好的机程",
    "ThanThanFlow.gts支持所有Pyson可以加载的模型",
    "在Note.gts环境中直接通过调言API即可",
    "在流览器环境中需要转换为流览器支持的JSON格式",
    "ThanThanFlow.gts提供了一系列预讯论好的模型",
    "包括图像识别 余音识别 人体姿态识别 物体识别 文字分类等",
    "在这个项目中我们将通过预测汽车油耗效率",
    "首写数字识别 两个实力演示如何使用ThanThanFlow.gts进行ThanThanFlow模型的开发讯认和部署",
    "体验ThanThanFlow.gts直接在流览器加载ThanThanFlow",
    "通过本地CPU或者GPU资源进行所需的机器学习运算",
    "灵活的进行各种AI应用的开发",
    "我们将学习ThanThanFlow.gts的优点",
    "ThanThanFlow.gts的体系价格以及相关概念",
    "学习ThanThanFlow.gts环境配置",
    "在流览器中使用ThanThanFlow.gts",
    "能在Note.gts中使用ThanThanFlow.gts",
    "能通过Layer's API, call API,创建模型",
    "能熟练模型部署开发相应AI应用",
    "ThanThanFlow.gts是一个开源机器学习库",
    "可运行在加娃Scrept",
    "可以运行的任何位置",
    "它基于使用Pyson编写的原始ThanThanFlow.gts",
    "直在为加娃Scrept生态系统",
    "打造这种开发者体验和移系列API",
    "建于加娃Scrept的可移植性",
    "我们可以使用一种语言编写",
    "并在以下所有平台上轻松直行机器学习",
    "使用原版加娃Scrept的网络流览器中的客户端",
    "使用Note.gts进行服务器端",
    "甚至是RESPERBELRY, PII等IOT设备",
    "使用Electron的装面应用",
    "使用React Native的原生移动应用",
    "ThanThanFlow.gts还支持在每个环境中使用多个后端",
    "例如可以在CPU或WebGL中",
    "直行的实际基于硬件的环境",
    "使出的后端并不意味着服务器端环境",
    "以确保肩容性并保持运行速度",
    "在2017年,一个叫Dip Learning.gts的项目诞生了",
    "这是一款基于WebGL加速的开放原带马",
    "加娃Scrept机器学习库",
    "该库可以直接在流览器中运行",
    "而无需进行安装",
    "也无需借助后端运行",
    "在2018年3月,Dip Learning.gts团队与ThanThanFlow团队合并",
    "从命名为ThanThanFlow.gts",
    "ThanThanFlow.gts可以让我们直接在流览器中加载ThanThanFlow",
    "让用户立即通过本地的CPU或GPU资源进行我们所需要的机器学习运算",
    "更灵活的进行AI应用的开发",
    "流览器中进行机器学习",
    "相比于服务计端来讲由以下施打优势",
    "一,不需要安装软件或驱动",
    "打开流览器即可使用",
    "二,可以通过流览器进行更加方便的人机交互",
    "三,可以通过手机流览器",
    "调用手机硬件的各种传感器",
    "例如GPS,身上头等等",
    "似,用户的数据可以无需上传的服务器",
    "在本地即可完成所需操作",
    "官网有很多ThanThanFlow.gts是构建的势力和债线演示",
    "例如在网页端讯练一个模型来识别图片或语音",
    "讯练一个模型以新影的方式玩游戏",
    "我构建一个能创造钢琴音乐的神经网络的",
    "谷歌推出的AI小程序",
    "参画小歌在朋友圈风黄刷屏",
    "现在谷歌AI又有了更有趣的打开方式",
    "WooMeghr可以将你的姿势与同一姿势的其他人的图像相匹配",
    "利用机器来捕捉人类的动作",
    "然后跟8万多幅图像进行比对收索",
    "找出与人类动作一致的图像",
    "“社会实践”",
    "课程实践报告",
    "姓名：彭思奇",
    "学号：23371112",
    "学院：软件学院",
    "班级：232112",
    "任课教师：\t徐冶琼",
    "报告题目：相约同行，赴梦蓝天",
    "2025年 10月 2日",
    "相约同行，赴梦蓝天",
    "本实践的核心议题或计划回答的问题",
    "本实践旨在通过开展特色支教活动、实地田野调查等方式增强大学生的责任意识，并带给乡村学生独特体验。",
    "本实践采取的主要形式",
    "本次“赴梦蓝天”寒假社会实践是一次集线下支教、实地调研、文化交流于一体的综合性志愿服务活动。在北京航空航天大学蓝天志愿者协会长期线上支教的基础上，我们实践队于2024年1月15日至2月5日期间，组织队员前往云南省保山市隆阳区，与之前线上结对的乡村中小学生进行为期数天的面对面深度交流与教学互动。",
    "实践团队由来自北航各学院（书院）的十五名同学组成，我们怀揣着对乡村教育事业的热忱，希望将知识、视野与温暖带给当地的孩子们。实践地点主要包括保山市汉庄中学、瓦渡中学、芒宽中学、荷花中学等多所乡村学校。",
    "实践过程主要围绕两个方向展开：",
    "寓教于乐，创新教学形式，设计特色团体活动。 我们精心策划并组织了“开年大戏”戏剧排演、“天南地北茶话会”以及“辞旧迎新联欢会”等一系列文娱活动，大学生和中学生共同参与、共同完成。",
    "在汉庄中学我们开展的“开年大戏”活动中，我们在上海戏剧学院麦老师的帮助下，将经典文学作品《老人与海》改编为剧本，并指导当地学生分幕进行排练和汇报演出。从围读到创排，制作海报、门票，共同完成沉浸式剧本朗读会，线下邀请小同伴家人前来观看，线上同步围读录制视频，与更多共享一出好戏。",
    "在瓦渡中学开展的“天南地北茶话会”活动中，我们邀请所有参与者登上“同行专列”，由来自祖国各地的实践队员以多媒体、短视频、实物等方式，展现“各美其美、美美与共”的家乡风采，并结伴分小组深入了解小同伴的家乡—云南保山，制作创意手绘单页和短视频，经过排版设计和剪辑创作，完成“青春同行版”保山宣传册和视频。",
    "我们最后在荷花民族中学开展“辞旧迎新联欢会”。队员们邀请中学生现场组队，随心排演联欢节目，土味高雅，温情搞笑，唱跳说演，样样皆可，共同迎接新的一年的到来。",
    "实地调研，聚焦现实问题。我们提前设计田野调查方案，准备相关访谈主题、问卷。在保山、芒宽、荷花等地进行实地采访调研。每个调研主题以1-3人为一组分批调研情况并撰写调研报告。主题包括但不限于：",
    "“线上支教”对于连线双方的利弊，我们该如何改进线上教育的形式？",
    "多角度探究，信息化时代快速传播的网络流行文化会给乡村孩子带来什么样的影响？",
    "资源链接，乡村留守儿童和青少年在成长中遇到的心理问题，我们能提供哪些帮助？",
    "关于课外阅览，怎样提供具体行动帮助缺少时间和接触渠道的乡村学生的增加阅读量?",
    "走进乡村，体会云南保山的乡土人情，我们如何看待城乡差距？",
    "拓宽视野，面对乡村学生无法提供足够的物质帮助，那如何给予合适的情绪价值？",
    "产生好奇，乡镇中小学生的课余生活是什么样？",
    "基于现实考虑，当地是如何解决乡村孩子的交通方式、通勤时间、安全问题等？",
    "算本经济账，寒门学子去一线城市读大学，究竟值不值？",
    "本实践的理论意义、应用价值",
    "本次实践通过实地调查产生了一系列具有价值的实践报告。比如我调研的主题为《线上支教的赋能原理探析与经验总结》（相关材料见附件），探索线上支教是否有用、有什么用，为乡村教育研究提供了宝贵的一线案例与数据。我们对“线上+线下”混合式支教模式的探索，验证了其在弥补城乡教育资源不均、激发学生学习兴趣方面的可行性。我们发现，线上的长期陪伴能建立情感基础，而线下的深度互动则能有效激发这种情感积淀，形成“身份感”认同，从而侧面赋能学生的学习动力。此外，我们对乡村留守儿童心理状态的初步调研，也为相关社会学、教育学研究积累了鲜活的质性材料，为后续的理论构建提供了实证支持。",
    "我们实践不同于死板的课堂教学，而是通过设计特色活动达到共同参与，具有显著的可推广性。我们成功探索并实践了一套行之有效的乡村支教活动方案，如“戏剧工作坊”等形式，证明了艺术教育在建立学生自信、培养协作能力上的独特价值，可供其他公益组织借鉴。本次实践也为我们当代大学生提供了一个了解国情、服务社会、锤炼品格的平台，深化了我们对自身时代责任与历史使命的认知，实现大学生和中学生的共同成长。",
    "基本成果介绍",
    "第一，成功构建并深化了“线上长期陪伴+线下深度赋能”的混合式支教模式。 本次实践并非空中楼阁，而是建立在团队长期线上辅导所积累的情感与信任基础上。实践证明，线上建立的稳定联系能有效转化为线下活动的参与热情与深度互信。我们将抽象的帮扶具体化为可感知的陪伴，形成了集文化熏陶、能力培养、情感支持于一体的立体化教育成果，验证了该模式在促进城乡教育交流中的“1+1>2”效应，为乡村支教提供了可持续、可复制的创新思路。",
    "第二，策划并实施了三大主题校园活动，形成了系列可推广的典型教育案例。 我们将教育理念融入精心设计的活动中，取得了显著成效：",
    "“开年大戏”沉浸式戏剧工作坊： 我们选取《老人与海》改编剧本，引导学生从围读、创排到制作海报门票，最终完成了一场邀请家人观看、并同步线上录制的沉浸式剧本朗读会。该活动不仅锻炼了学生的语言表达与团队协作能力，更通过完整的项目制学习，极大地提升了他们的自信心与艺术表现力。",
    "“天南地北茶话会”文化交流项目： 队员们以视频、实物等形式生动展示了各自的家乡风采，并与当地学生分组合作，共同为保山制作创意手绘单页和短视频。最终产出的“青春同行版”保山宣传册与视频，不仅是学生们创意与实践能力的结晶，更是城乡青年文化交融、彼此认同的生动体现。",
    "“辞旧迎新联欢会”民俗体验活动： 通过剪窗花、写对联、挂灯笼等传统活动，我们与孩子们共同营造了浓厚的年味。联欢会上的即兴组队与多元化节目表演，打破了师生界限，在欢声笑语中深化了情感连接，成为一份珍贵的集体记忆。",
    "第三，开展了体系化的乡村教育调研，形成了具有现实关怀的一手资料库。 为保证调研的专业性，我们特别邀请了中央民族大学博士后郭少妮老师提供学术支持。调研不再是浅尝辄止的问答，而是聚焦于一系列深刻议题，如“线上教育的利弊与改进”、“网络流行文化对乡村孩子的影响”、“留守儿童的心理支持体系”、“城乡差距下的教育选择”等。我们通过家访等形式，深入孩子们的生活，收集了大量关于学生学习困境、家庭状况、内心愿望的真实信息。这些兼具学术严谨性与人文关怀的原始资料，为深刻揭示乡村教育的薄弱环节、探索解决方案提供了坚实基础。",
    "第四，产出了丰富的实践宣传产品与可复用的经验材料库。 实践的全程记录与精心制作，转化为图文推送与视频Vlog，在多个新媒体平台传播，有效扩大了社会影响力，并在“北京航空航天大学蓝天志愿者协会”公众号上的“赴梦行记”专栏播报。同时，我们将活动的完整策划方案、组织流程进行整理归档，形成了一套可供后续团队直接借鉴使用的实践工具包，真正实现了经验的沉淀与传承。",
    "团队情况",
    "线上：王立旻（线上队长）徐聆雯 宋乐轩 罗雪睿",
    "线下：\t彭思奇（线下队长，本人） 苏俊杰 史忠明 徐文浩 王子赫 叶思羽 许燕 陈硕 吕洪福 荆韵",
    "个人在团队中的贡献",
    "作为本次线下实践的队长，我深度参与了从策划到执行的全过程，致力于将团队的设想转化为富有成效的行动。",
    "在活动组织与执行上，我勇于承担核心任务。 在“开年大戏”这一重点项目中，我主动请缨担任第一幕的导演。面对时间紧、任务重的挑战，我带领组员和孩子们从早到晚进行排练，没有丝毫懈怠。我不仅要设计表演环节，更要关注每个孩子的情绪和进步。通过一遍遍的示范、鼓励和心理疏导，帮助孩子们克服胆怯，最终在舞台上完成了令人惊喜的蜕变。这个过程让我深刻体会到作为一名组织者和教育者的责任与喜悦。",
    "在实践调研上，我坚持问题导向，持续深化认知。 我抱着验证线上支教有效性的初衷参与实践，并在调研中始终围绕这一核心议题展开。通过与孩子们的深入访谈，我逐渐理解了线上支教在建立“身份感”、提供情感支持方面的独特价值。同时，在实践中敏锐地捕捉到“留守儿童”这一关键问题，并迅速将其调整为我的调研重点。在与孩子们交流时，我会有意识地加入相关问题，努力从他们的视角去理解他们的困境与渴望，力求让我们的调研更具深度与温度。",
    "在团队协作与成员激励上，我尽力发挥队长的凝聚作用与组织协调能力。在每位成员到达/离开实践地点时，我都会实时跟踪成员安全情况，主动组织顺路的同学同行。在实践进行中，我每一天都会根据实际情况为每位同学分配相应任务，并完成实践材料（照片、感想、物料等）的收集，并掌握整体的宣传工作。在蓝天志愿者协会编辑多条“赴梦行记”的推送。面临着作息紧张、条件艰苦等挑战。我以饱满的热情投入工作，并时刻关注团队成员的状态，努力营造积极向上、互帮互助的团队氛围。",
    "个人实践感悟",
    "这次云南保山之行，它颠覆了我对志愿服务的固有看法，让我真正思考：志愿的意义究竟是什么？",
    "出发前，我满怀疑虑。作为长期线上支教的参与者，我反复追问自己：每周两小时的线上陪伴，究竟是孩子们的切实所需，还是我们志愿者的“自我感动”？这种“帮助”会否反而成为一种打扰？为了解答这个困惑，我主动报名并担任了线下实践队长，决心到实地去寻找答案。",
    "实践初期，我通过调研访谈，似乎印证了我的猜想——不少孩子直言线上支教作用不大。然而，随着走访的深入，我发现了理论与现实的悖论：线上支教对成绩的提升或许并非直接的因果关系，但其侧面赋能的心理效应却不容忽视。有孩子因为参与了我们的项目而产生了一种荣誉感和“身份感”，认为“不能让别人笑话”，从而在课堂上变得更为积极主动。这个发现让我第一次意识到，支教的价值远比我想象的要复杂和深刻。",
    "然而，真正让我对志愿服务产生颠覆性思考的，是实践中无意间触碰到的“留守儿童”这一沉重议题。在汉庄，一位心理老师告诉我，一个年级几百人中，就有七八十位孩子因留守问题前来咨询；在我们走访的多个学校，双亲都在家的孩子是极少数。在瓦渡中学，最后我们有一个活动是写下自己的新年愿望，然后有同学向群里发了一张图片，是他们组里面一个小女孩写的愿望，我一张小卡片上用稚嫩的却工整的笔迹写着“希望再梦到爸爸一次”，那一刻，我们全体队员都沉默了，鼻子突然好酸好酸。",
    "我经过调研看到了更多了留守现象，也在和家长孩子的沟通中变得更加沉默。\t有个孩子想要辍学去江苏打工，我们问他问什么，他说“我学习压力好大，我也学不会什么，不如早早的打工，至少那里有妈妈”。",
    "有家长两人在广东打工，一个月吃住不到2000元，其余都汇到家里，但是还是一直亏欠——“我孩子生重病我都没办法，还要麻烦班主任，在这边瞎着急”",
    "有单亲妈妈坚强出走，一个人撑起一个家，有奶奶开小卖部养活父母双亡的女儿，有父亲只是因为“您很伟大坚强”的肯定就夺泪而出。",
    "我发现，这群人，太需要被看见，也太需要认可了。",
    "可是如果不是这次志愿，我可能永远无法真正“看见”这个群体的痛苦。即便新闻报道中常有提及，但远不及亲身走进他们中间，感受那种无声的渴望来得震撼。我开始理解，志愿服务对我最大的意义，或许并非是去验证“我对别人有无用处”，而在于它让我“对自己大有裨益”。它强迫我走出被保护的舒适圈，让我看到了一个更真实、更复杂的社会；它让我关注到那些我原本可能一生都不会留意的群体，让我对他们的困境感同身受。",
    "于是，我不再纠结于“我的付出有没有得到回报”这种难以量化的焦虑。我开始明白，志愿的意义，不一定是说在别人心中种下什么，因为我不是他人，我永远无法知晓、永远无法确定我所做之于他人。但是我能够在自己心中种下一颗种子——一颗关注社会、关怀他人的种子。我们无法确保每一次行动都能在别人心中开花结果，但可以确定的是，每一次的走访、每一次的倾听，都在拓宽我们自身的视野，都在重塑我们的世界观。我们能做的，就是为孩子们带去一段有趣的体验，比如一场戏剧排演，一次联欢会，这本身就是一种宝贵的价值。",
    "我不再预设宏大的意义，不会在开始前就把意义、价值规定死板，不再为所谓的“被帮助者”代言。而是更多地去思考“我看见了什么”、“我收获了什么”，因为，当我“看见”，我则有了意识；当我“看见”，我则有了信念；当我“看见”，我则有了力量。",
    "志愿或许对我而言，是“自私”的，因为我过于贪婪，贪婪地想要“看见”。",
    "实践照片、参考文献及其他附件材料",
    "实践照片2张，其中至少1张有本人出镜（若是多人合照请标出本人所在位置）：",
    "照片1说明（23371112-彭思奇，2024年1月24日、云南保山，“开年大戏”第一幕小组合影，最前方男生为本人）：",
    "照片2说明（23371112-彭思奇，2024年1月27日、云南保山在学校采访老师）：",
    "下面附件页包含：",
    "附件1——问卷",
    "附件2——访谈提纲",
    "附件3——本人田野调查报告论文",
    "附件一——学生问卷设计",
    "1.您使用过那些线上教育软件？使用体验如何？",
    "2.线上教育与教师授课相比，您更喜欢哪种方式？父母能否给与你一定的支持？",
    "3.家里可以提供网络、电子设备等条件吗？",
    "4.寻找教育资源过程会有什么困难吗？或者说自己未主动寻找过，都是由教师提供的。",
    "5.自己能否坚持运用电子设备学习，而不沉迷于其中的短视频和手游等，能够控制自己，拥有一定的自控力？",
    "6.您还有什么想要和我们分享的吗？",
    "附件二——访谈设计",
    "访谈对象：",
    "中考考试科目(语数英物化政史等)老师中的几位，与非中考考试科目(美术音乐体育等)老师中的几位，同时希望这些老师能够同时拥有资历老的教师和年轻教师（如90后、00后）。还希望能够访谈校长（副校长之类）和负责对接线上教学，对活动有所了解的老师。",
    "访谈大纲：",
    "一、自我介绍",
    "老师（校长）您好，我是北京航空航天大学的学生，我们正在对保山市的线上教育进行一项访谈研究。",
    "二、访谈人信息",
    "1.请介绍一下您所在的学校和工作职务。",
    "2.您认为目前乡镇中学面临的主要挑战是什么。",
    "三、线上教育现状",
    "1. 您学校目前使用线上教育的程度如何？",
    "2. 您认为线上教育在乡镇中学中的角色是什么？",
    "3. 您觉得线上教育有哪些优势和劣势？",
    "四、需求与期望",
    "1. 您认为乡镇中学对于线上教育有哪些具体需求？",
    "2.您觉得什么样的线上教育资源和服务是必要的？",
    "3.您希望线上教育在哪些方面对学校有所帮助？",
    "五、看法与态度",
    "1. 您对于线上教育的长期发展有何看法？",
    "2. 您认为目前影响乡镇中学线上教育发展的主要因素是什么？",
    "3. 您对于线上教育和传统教育的结合有何看法？",
    "六、实施与建议",
    "1. 如果要进一步推广线上教育，您认为应该采取哪些措施？",
    "2. 您对于如何提高乡镇中学老师在线上教育的技能有何建议？",
    "3. 您认为政府或相关机构应该如何支持乡镇中学的线上教育发展？",
    "附件三——田野调查报告论文",
    "线上支教的赋能原理探析与经验总结",
    "——以同行公益助学项目为例",
    "2024年3月",
    "摘要",
    "线上支教以其便捷、低成本等独特优势成为不少支教团体的选择，但同时它又存在学生自制力弱、挤占学生时间、实际效果不明显以及支教沦为单向交流的“网课”等问题。为了真正利用好互联网带来的优势促进支教事业的发展，本篇论文以同行公益助学项目为例，探究线上支教该如何做才能避免沦为支教者一厢情愿的打扰、真正的产生实际的促学效能，旨在为各线上支教项目的发展提供经验与思路。为了探究这一主题，笔者前往同行公益助学项目的帮扶学生所在地——云南保山，采用访谈、问卷的调研方式，针对线上支教问题开展实地调研。",
    "通过调研，笔者创造性总结线上支教项目的两个供需矛盾，并提出通过激发学生的“身份感”和榜样作用来借此赋能线下课堂学习的运行机理。同时，笔者总结同行公益助学项目的成功原因，并针对其存在的问题提出解决方案。",
    "与许多针对线上支教优劣分析的研究不同，本文将主题聚焦于找寻线上支教项目真正切实有效的运行方式。通过对学生心理的分析探究，找寻线上支教项目在间接的心理方面影响。同时，笔者创造性结合调研结果、心理学以及经济学的边际收益，为回答“线上支教该如何走”这一问题提供思路。",
    "关键词：支教，线上教育，心理健康，教育公平",
    "Abstract",
    "Online volunteer teaching has become a popular choice for many volunteer teaching groups due to its unique advantages such as convenience and low cost. However, it also faces problems such as weak student self-control, occupying student time, unclear actual effects, and the fact that volunteer teaching has become an \"online course\" for one-way communication. In order to really make good use of the advantages brought by the Internet to promote the development of volunteer education, this paper takes the peer charity education program as an example to explore how online volunteer education can be done to avoid becoming a wishful interference of volunteer education and truly produce actual learning promotion efficiency, aiming to provide experience and ideas for the development of various online volunteer education programs. In order to explore this topic, the author went to Baoshan, Yunnan, which is the location of the student assistance program for peer public welfare education. Through interviews and questionnaires, the author conducted on-site research on online teaching assistance issues.",
    "Through research, the author creatively summarizes the two supply-demand contradictions of online teaching projects and proposes to empower the operation mechanism of offline classroom learning by stimulating students' sense of identity and role model. At the same time, the author summarizes the reasons for the success of peer public welfare education programs and proposes solutions to their existing problems.",
    "Unlike many studies that analyze the advantages and disadvantages of online teaching support, this article focuses on finding the truly practical and effective operation mode of online teaching support projects. By analyzing and exploring the psychology of students, we aim to identify the indirect psychological effects of online teaching programs. At the same time, the author creatively combines research results, psychology, and the marginal benefits of economics to provide ideas for answering the question of \"how to go about online teaching support\".",
    "Key words:support education, online education, mental health, education equity",
    "目录",
    "图目录",
    "图 1  参加线上助学项目学生动机调查\t3",
    "图2  赋能机制思维导图\t5",
    "表目录",
    "表 1  互联网使用对低龄留守儿童自我管理能力影响的门槛效应研究表格（G1为3小时）\t7",
    "引言",
    "研究背景",
    "1.线上支教的必要性",
    "习近平总书记到河北阜平县考察扶贫开发工作时讲到：“要把下一代的教育工作做好，特别是要注重山区贫困地区下一代的成长。”[1]。但由于时间、空间、成本、信息等限制，传统支教在服务的稳定性、规模性、可持续性等方面都面临着挑战[2]。而随着科技发展，线上支教逐步走入大众视野。它不仅节约了由于距离限制而产生的交通成本，而且以其便捷性、广泛性一定程度上弥补了传统线下支教的不足。2021 年 7 月，《中共中央国务院关于深化教育教学改革全面提高义务教育质量的意见》提到“整合建设国家中小学生网络学习平台，免费为农村和边远贫困地区学校提供优质学习资源，加快缩小城乡教育差距”，强调了利用好互联网资源促进教育公平的必然性[3]。同样《2023 年数字乡村发展工作要点》也强调了推进“互联网+教育”促进乡村振兴的必要性[4]。由此可见如果能够将互联网带来的便利利用得当，不仅能够让优质教育资源走入乡村，而且能够为促进教育公平与乡村振兴提供磅礴力量。",
    "2.线上支教的困境",
    "然而，线上支教并不完美，在实际运行过程中，也会出现各种各样的问题。如出现授课质量不稳定、师生缺乏互动、课后师生难以交流以及设备缺位等问题[5]。由此产生了一个值得深度探究的问题，线上支教该如何做才能避免沦为支教者一厢情愿的打扰、真正的产生实际的促学效能，这也是本篇文章的研究重心。",
    "3.同行公益助学项目",
    "同行公益助学项目致力于以“看电影学英语”为途径，通过每周末两小时一对一的线上网课连接大学生志愿者与英语资源匮乏的乡村地区的初中学生，实现“让城市与乡村孩子共同成长”的目标。并不长的支教时间、较脱离教材的知识内容、打破常规的教学方式令人不难质疑该项目的实际效果。但与预期大大相反的是，该项目在促进学生成绩上取得了斐然的成就。为了探究其发挥作用的运转原理，笔者走入受支教的云南保山地区。通过问卷调查与采访的方式，总结出通过线上项目的身份感与榜样作用赋能线下学习的机理与其成功经验，并针对目前项目中存在的问题，提出合理的解决方案。",
    "一、线上支教的矛盾性",
    "笔者结合亲身实践经历与其他研究者的报告，提出线上支教常见的“两个供需矛盾”。",
    "（一）人员供需矛盾",
    "这种人员矛盾具体体现在志愿者的筛选上。一方面，乡村学生的巨大人口基数与相对偏弱的教育水平产生对教师志愿者更高的数量需求。另一方面，大学生是志愿活动的主力军，由于大学生本身教学能力有限且需要完成学业等日常任务，备课时长与授课质量难以保证。同时，部分大学生虽然有充足知识上的储备，但在授课经验、课堂管理、教学技能等方面相对较弱，可能造成课堂混乱、教学质量无法保证的现象[6]。",
    "如果将志愿者单独限于师范院校，不仅限制了志愿者的数量，致使其难以满足项目需求，还会使线上支教志愿者群体趋于单一，限制了项目的长远发展。有的项目通过一对多的模式，把老师课堂的学生数量扩大来缓解这种矛盾，但这种形式不仅进一步强化了线上支教的单向交流、互动缺乏问题，更不断将支教活动推向了另一种形式的“网课”，削弱了支教活动的独特色彩。面对这一矛盾，有学者提出健全志愿者选拔的各项机制，加强志愿者考核来打造高质量的志愿者团队[7]。但在具体实施出于时间、精力、项目吸引力等各种考虑，建立起一套既考核严密又运转高效的机制需要不断地实践与考量，一时难以解决该人员矛盾。",
    "（二）意愿供需矛盾",
    "由于授课时间短暂，课程间隔时间长，以及为了保证课程趣味性与师生的沟通交流，同行公益线上助学等线上支教项目将目标放在点燃学习兴趣、丰富综合素质上，因此采用“看电影学习英语”的方式组织线上的一对一辅导。但在问卷的调研中，91%的同学表示更渴望从中得到成绩上的提升，约1/5的同学表示项目的学习效果一般、可有可无。由此产生了一个供给方与需求方意愿不对等的矛盾。不少学生乃至老师表示所谓综合素质的提升过于长远或者飘渺，对于学习压力巨大、成绩水平较落后的乡村孩子来说，远不如直接可见的成绩提升更另他们信服。",
    "图1  参加线上助学项目学生动机调查",
    "二、赋能机理解释",
    "上面已经提到，线上支教本身能传授的应试知识较少，对学生成绩很难产生较显著的直接影响。但是，在上一个期的线上支教项目中，一所学校29位中26位同学成绩进步，另一所学校33位同学中有24位成绩进步。且笔者本次的问卷调研中，约80%同学表示“项目很有帮助，效果很好”。为了探究其成功的内在机理，笔者与老师、同学进行访谈与交流，发现项目所产生的间接影响在一定程度上超过了它的直接影响。",
    "（一）身份感",
    "线上教育带来的“身份感”与“荣誉感”将提高线下学习的积极性。由于一对一模式限制了参与项目的学生名额，在这种“名额竞争”下，申请通过的学生们将产生一种被肯定与认同的感觉。当参与项目的同学向其他同学“炫耀”所学到的课外知识时，也会产生愉悦的心情。参加项目这件事本身让他们相比于其他同学来说拥有了一个项目参与者的“新身份”。这种身份感给了他们一种优越感，并在课堂上表现为一种责任感。“明显能感觉到参与项目的那些同学他们上课时更加积极，举手的次数也更多。”汉庄中学的一位英语老师说。腾冲荷花中学的一位班主任也表示“我们班参与同行公益的几位学生英语学习根本就不用我操心，他们自己学习英语都很热情”。",
    "由此可见，线上支教的第二个意愿供需矛盾其实可以通过身份感来巧妙的化解。线上助学通过其心理的影响激发学生学习热情与兴趣，通过提高学习热情、上课积极性等将促学效果延伸至线下的课堂，做到以学促学。",
    "（二）榜样作用",
    "线上教育促进的综合素质在潜移默化地改变他们的学习态度与能力。首先，大学生拥有较为的丰富的学习经验与成长经历，却又不失开放包容的态度与对孩子的亲和力。在与老师一对一的每周交流中，小同伴收获的更多是一个可以指导生活与学习的朋友、榜样而非一味传授知识的老师。“学校为青少年选树的榜样并不一定能获得学生的真心认可，青少年是依据其自身成长背景和心理需求来认同榜样的”，而通过每周的交流指导，大学生榜样更容易获得学生的心理认同[8]。参与项目的一位同学说：“参加项目后我知道了很多大学的事情，特别是师范大学。我的理想信念更加强大，更想当一名老师。”就如苏霍姆林斯基所说：“我总是努力给少年们描绘出活生生的人的鲜明形象，这样的形象成了人类道德美的永久体现，我要让这个形象照亮少年的心，深入他的思想深处，使少年的心更快地跳动……”老师的学习态度、学习方法、生活态度都可能对学生的三观塑造、目标梦想的确立产生影响[9]。他们的鼓励、宽慰、劝导也可以转化为学生奋进的动力。",
    "图2  赋能机制思维导图",
    "三、成功经验总结",
    "（一）项目的趣味性",
    "正如爱尔兰诗人叶芝所说“教育不是将水灌满，而是把火点燃”。项目以“看电影学英语”的趣味性吸引了乡村孩子的广泛参与与热情投入。项目通过看电影的方式点燃、维持学生参与热情、通过“身份感”与“榜样效用”来提供学习动力与热情，课堂本身的师生互动交流又能潜移默化地提高口语与听力能力，课上的知识点与随堂测试可以提高英语知识水平与应试能力。在项目的趣味性的点燃下，线上支教的各个作用环节才能得以发挥效能并构成完整的统一体，使得项目有充足的吸引力与持续的实际效能。",
    "（二）一对一的教学模式",
    "一对一的教学模式是项目的一大亮点。这种模式并不回避前文中提到的线上支教人员方面的供需矛盾。相反，一对一模式巧妙地利用了该矛盾，将志愿者人数的缺乏演变为一种巧妙的无声竞争。根据心理学的“稀缺效应”（scarcity effect），学生对来之不易的线上助学项目名额将更加珍惜，由此将会产生更强的身份感，进而使得上文所提到的运行机制有效发挥了作用。",
    "首先，一对一的教学模式使得师生之间交流具有唯一性，在被提问者唯一的情况下，小同伴会更加专注于课堂，更加保证了课堂的有效交流。同时，一对一的教学模式能有效拉近学生与老师之间的距离，提高学生上课的积极性，而且在一对一交流中形成的亲密关系能有效填补乡村孩子特别是留守儿童内心的情感需求空缺。笔者走访的汉庄中学、瓦渡中学、芒宽中学、荷花中学均为寄宿制，且留守儿童问题突出。据荷花镇书记介绍，在一个荷花镇上留守儿童(父母均常年不在家)的数目就高达461名。由于缺乏父母的关心和陪伴，教育资源的限制以及社会环境和个体因素的影响，农村留守儿童普遍存在着各种心理健康问题，如自卑心理、逆反心理、性格与行为偏差等[10]。但由于大学生既不会有太多老师的威严，又有超过同学、朋友的成熟与温柔，他们能在一定程度上缓解小朋友的心理问题。荷花中学一位教师在访谈时说：“他（参加的项目学生）跟同行公益的老师聊天时很响亮，说个不停，但之前跟我们都是低着头不怎么说话的。”一对一模式不仅促进了学生的专心学习，更在解决心理问题上贡献了一份独特力量。",
    "（三）每周授课时长",
    "与一对一模式异曲同工的是项目的授课时长安排。同行公益助学项目每周设置一个半小时到两个小时的授课时长。这样的课程安排不仅保证了充足的备课时间，一定程度上保证了整体的教学质量，更维持了同学上课的新鲜感、期待值，进一步强化了教学效果。",
    "经济学中有一个经常被用于社会心理学分析的边际效应（Marginal utility)，即重复投入的增加在超过某一水平后会带来收益的降低。如果占用学生过多的周末时间，不仅更容易引起学生的反感或厌倦，更有可能带来最终收益的减少。有研究者对农村低龄留守儿童的接受线上教育的时长与自控力之间的门槛效应进行分析，得出了每周三小时的阈值[11]。即将上网学习时间控制在3小时以内，不仅有助于学生热情参与，还能一定程度帮助学生提升自我管理能力。",
    "表1  互联网使用对低龄留守儿童自我管理能力影响的门槛效应研究表格（G1为3小时）",
    "四、问题反思与可行方案",
    "虽然项目通过其独特的运转原理取得了不错的成效，但这套运转机制同样存在一些问题，笔者对其进行反思并尝试提出可能的解决方案。",
    "（一）课件问题",
    "1.问题阐述",
    "由于看电影学英语的限制，课件上的内容难以避免的出现脱离课本的现象。很多单词、俗语超纲或者学生在考试、生活中并不常用。一方面，这减弱了线上支教的直接知识性效果。由于平时难以遇到这些单词，同学们在综合时间成本与实际收益后往往不会花大量时间去复习巩固这些陌生单词，导致出现了虽然在课上学会但很快便遗忘这些单词的现象。另一方面，这为一些同学带来了压力与焦虑。在访谈中有同学反映课件难、陌生单词多、学到的一些单词没有用。他们在参加项目后不仅没有看到成效，反而加剧了自己的紧张与焦虑。",
    "笔者访谈发现，这些同学参加项目往往都是渴望快速提升英语，有较强的目的性。但英语这门科目是一门需要日积月累的学科，而同学们倾向以卷面成绩来评判进步而忽略积极性等方面的提升。在难以看到成效时，一些同学难免对项目的实际效果产生质疑甚至焦虑。而如果没有了参与项目的激情与动力，反而会阻拦我们上方所提到的运转机制发挥作用，进一步阻拦了学生成绩的提升。当同一批学生大部分表现为进步时，没有明显进步的学生心里难免产生落差感。在落差感与这些学生对英语成绩的焦虑心情的压迫下，学生对项目的质疑甚至会发展为对自己能力的质疑。甚至在访谈时有同学出现放弃英语学习，试图通过其他学科的高分“弥补”英语成绩的想法。",
    "2.解决方案",
    "既然看电影的趣味性作为关键一环不能舍弃，那笔者认为不如从加深与课程的关联入手来强化课堂的知识性教学效果。具体表现为以下两个方面：",
    "课件与课后测验应适当减少对生僻单词的讲解与考察。以同行公益助学项目第五期中的《美丽中国》为例，其课件中出现较多动植物的英文名，这些单词甚至超出四六级的范围，对这些单词的记忆笔者认为并没有太大意义。",
    "课件的选题可以尝试参考英语课本甚至语文等课本教材。如仁爱版八年级上册教材第三单元有个小主题为“音乐爱好”，项目者可以找寻与音乐相关的电影题材，通过电影提供有关音乐的知识与单词等，为线下学生学习这一单元时提供背景知识、提高上课积极性，同时又是为学生上的一场独特的美育课。",
    "（二）自制力问题",
    "1.问题阐述",
    "问卷调查中，近97%的学生认为学生缺乏自制力是线上学习效果不好的原因。当然，项目组通过将学生学习的地点安排在学校机房、设置老师看管、进行课后测验等措施与校方合力，构建了一个有效的“防沉迷系统”。但是仍有出现同学不听课反而做其它事情的情况。同行公益助学项目设置电影鉴赏课，电影的时长使得交谈的时间变得短暂，这会为学生提供“空白期”，如果电影情节不够吸引学生，也有可能出现走神甚至打开其它网页的现象。而且当出于一些原因，学生需要在家中拿着父母手机“补课”时，也可能出现类似现象。",
    "2.解决方案",
    "鼓励学生打开摄像头。一些学生在线上学习时不愿意打开摄像头。一方面会增加不认真对待课堂的风险，另一方面阻碍了师生关系的拉近。打开摄像头不仅能让老师掌握学生实时的状态，及时调整授课内容，更能使师生双方的距离拉近，有助于所提到的赋能机制的运行。",
    "加强与学校的合作。设备的更新与老师在机房的监管都需要项目负责人与校方的密切合作。在访谈时，腾冲荷花中学的一位班主任提到，为了防止部分学生抱着放松娱乐的心态参加项目而不认真对待课堂，每次课后她都会检查学生的笔记，而她们班级这几位同学英语成绩也都得到了更明显的提升。老师的真正认可与学校的积极配合能更好帮助学生认真听讲，提高课堂效果。",
    "总结",
    "毋庸置疑，线上支教是实现教育脱贫、促进教育公平的一条路。这条路该怎么走、如何走，还需要不断的探索与实践。本文笔者打开思路，研究线上支教过程中，学生们从支教课堂以外的事物里所能获得的提升。并以同行公益项目为例，提成出以线上课堂赋能线下课堂的运行机制。将研究重心放于项目的侧面影响上，从项目所带来的身份感与一对一教学中形成的榜样作用两方面，系统解释了线上助学项目对线下的学习产生帮助的赋能机理。同时，作者针对具体的助学项目，总结其成功的独到之处，并对其存在的问题提出可能的解决方案，希望为同行公益助学项目的发展与其他线上助学项目提供经验与思路。笔者期待，更多研究者能投入到线上支教的研究之中，让互联网为教育公平与乡村振兴贡献更大的力量。",
    "参考文献",
    "《求是》杂志发表习近平总书记重要文章《在河北省阜平县考察扶贫开发工作时的讲话》[J].小康,2021,(07):20.",
    "林春霞. 以数字化赋能破解乡村教育难题[N]. 中国经济时报,2024-01-15(001).",
    "中共中央  国务院关于深化教育教学改革全面提高义务教育质量的意见[J].河南教育(基教版),2019(09):4-8.",
    "中央网信办等五部门印发《2023年数字乡村发展工作要点》[J].农业工程技术,2023,43(12):6.",
    "罗欣,李婷婷,连雨欣等.“互联网+支教”教育帮扶模式研究——以河南省汝南县南余店乡为例[J].农村.农业.农民(B版),2021,(08):45-48.",
    "王严.“互联网+”视域下大学生支教志愿活动途径拓展探索[J].中国轻工教育,2020(01):25-29.",
    "陈雨凡,张晶.大学生志愿服务“互联网+支教”模式构建路径探析[J].宁波工程学院学报,2023,35(04):89-96.",
    "王再新,冼欣宜.新时代青少年榜样教育的向度与路径[J].人民教育,2022(20):30-32.",
    "[苏]瓦·阿·苏霍姆林斯基.让少年一代健康成长[M].黄之瑞,张佩珍等译.北京:教育科学出版社,1984.",
    "刘娟.农村留守儿童心理健康问题及对策研究——以湘西地区为例[J].农村经济与科技,2023,34(20):268-271.",
    "雷万鹏,尹珺瑶.互联网使用对低龄留守儿童自我管理能力影响的门槛效应研究[J].华中师范大学学报(人文社会科学版),2024,63(01):156-164.",
    "上网学习时长<G1 | 上网学习时长≥G1",
    "互联网使用条件 | 0.586 | 0.811",
    "-0.392 | -0.568",
    "互联网使用偏好(以娱乐偏好为参照)",
    "信息获取偏好 | 6.100*** | 4.319**",
    "-1.12 | -1.832",
    "社交偏好 | 3.738 | -1.65",
    "-2.215 | -3.407",
    "控制变量 | √ | √",
    "N | 851 | 103",
    "R2 | 0.179 | 0.285",
    "22:22 自 国 囚 息 REO 22 Okun 佩 2% CO\nx 2023 级 学 生 成 绩 和 排 名 - 正 考 2.。 …",
    "jsj.top\nQ #5: 23371112 #8: 彭 思 奇",
    "学 号",
    "23371112",
    "姓 名",
    "〇 “ 吉 * 志\nao wu",
    "GPA 排 名 得 分",
    "3.87",
    "GPA 专 业 排 名",
    "园 6",
    "算 术 平 均 成 绩 得 分",
    "90.1",
    "算 术 平 均 成 绩 专 业 排 名",
    "16",
    "加 权 平 均 成 绩 得 分",
    "91.821",
    "加 权 平 均 成 绩 专 业 排 名",
    "固 10",
    "年 级",
    "2023 级",
    "学 院",
    "软 件 学 院",
    "专 业",
    "软 件 工 程",
    "班 级\n保 存 整 页 为 图 片 >",
    "|",
    "232112"
  ],
  "sources": [
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第1段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第2段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第3段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第4段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第6段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第7段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第8段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第9段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第10段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第11段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第12段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第13段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第14段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第15段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第16段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第17段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第18段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第19段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第21段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第22段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第23段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第24段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第25段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第26段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第27段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第28段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第29段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第30段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第31段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第32段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第33段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第34段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第35段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第36段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第38段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第39段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第40段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第41段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第42段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第43段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第44段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第45段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第46段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第47段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第48段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第49段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第50段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第52段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第53段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第54段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第55段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第56段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第57段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第58段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第59段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第60段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第61段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第62段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第63段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第64段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第65段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第66段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第67段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第68段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第69段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第72段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第73段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第74段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第75段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第76段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第77段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第78段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第79段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第80段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第81段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第82段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第83段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第84段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第85段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第86段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第87段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第88段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第89段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第90段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第92段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第93段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第94段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第95段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第96段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第97段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第98段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第99段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第100段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第101段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第103段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第104段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第105段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第106段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第107段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第110段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第111段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第112段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第113段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第114段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第115段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第116段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第117段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第118段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第120段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第122段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第123段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第124段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第125段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第126段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第127段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第128段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第129段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第130段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第131段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第133段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第134段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第135段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第136段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第137段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第138段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第139段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第140段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第141段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第142段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第143段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第144段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第145段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第146段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第147段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第148段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第149段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第150段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第151段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第152段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第153段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第155段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第156段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第157段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第159段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第160段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第161段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第162段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第163段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第165段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第166段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第167段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第168段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第169段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第170段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第171段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第172段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第173段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第175段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第176段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第177段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第179段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第180段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第181段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第182段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第183段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第184段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第185段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第186段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第187段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第188段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第189段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第190段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第191段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第192段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第193段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第194段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第195段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第196段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第197段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第198段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第199段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第200段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第201段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第202段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第203段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第204段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第205段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第206段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第207段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第208段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第209段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第210段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第211段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第212段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第213段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第214段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第215段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第216段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第217段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第218段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第219段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第220段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第221段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第223段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第224段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第225段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第226段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第227段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第229段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第230段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第231段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第232段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第233段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第234段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第235段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第236段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第237段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第238段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第239段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第240段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第241段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第242段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第243段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第245段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第246段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第247段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第248段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第249段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第250段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第251段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第253段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第254段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第255段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第256段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第257段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第258段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第259段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第261段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第262段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第263段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第265段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第266段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第267段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第268段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第269段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第271段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第272段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第273段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第274段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第275段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第276段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第277段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第278段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第280段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第281段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第282段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第283段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第284段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第285段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第286段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第287段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第288段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第289段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第290段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第291段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第292段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第293段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第294段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第295段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第297段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第298段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第299段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第300段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第301段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第302段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第303段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第304段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第305段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第306段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第307段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第309段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第310段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第311段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第312段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第313段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第314段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第315段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第316段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第317段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第319段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第320段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第321段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第322段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第323段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第324段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第325段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第326段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第327段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第328段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第329段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第330段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第331段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第332段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第333段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第334段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第335段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第336段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第337段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第338段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第339段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第340段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第341段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第342段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第343段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第344段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第345段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第346段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第347段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第348段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第350段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第351段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第352段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第353段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第354段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第355段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第356段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第357段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第358段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第359段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第361段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第362段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第364段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第365段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第366段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第367段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第368段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第369段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第370段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第371段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第372段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第373段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第374段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第376段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第377段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第378段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第379段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第380段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第381段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第382段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第384段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第385段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第386段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第388段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第389段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第391段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第392段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第394段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第395段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第396段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第397段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第398段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第399段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第400段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第401段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第402段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第403段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第405段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第406段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第408段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第409段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第410段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第411段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第412段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第413段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第414段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第415段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第416段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第417段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第418段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第419段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第420段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第421段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第422段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第424段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第425段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第426段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第427段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第428段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第429段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第430段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第431段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第432段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第433段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第434段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第435段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第436段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第437段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第438段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第439段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第440段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第442段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第443段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第444段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第445段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第446段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第447段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第448段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第449段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第450段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第451段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第453段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第454段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第455段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第456段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第457段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第458段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第459段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第461段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第462段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第463段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第464段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第466段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第467段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第468段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第469段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第470段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第472段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第473段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第474段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第475段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第476段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第477段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第478段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第479段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第480段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第481段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第482段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第483段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第484段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第485段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第486段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第487段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第488段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第489段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第490段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第491段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第492段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第493段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第494段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第496段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第497段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第498段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第499段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第500段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第501段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第502段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第503段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第504段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第505段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第506段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第507段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第508段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第510段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第512段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第513段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第514段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第515段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第516段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第517段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第518段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第519段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第520段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第521段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第522段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第523段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第524段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第525段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第526段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第528段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第529段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第531段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第532段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第533段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第535段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第536段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第538段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第540段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第541段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第543段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第544段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第546段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第548段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第549段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第550段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第551段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第552段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第553段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第555段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第556段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第557段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第558段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第559段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第560段",
    "upload-6617113664522196356-cp08-样章示例-TensorFlow Lite_154550.docx 第561段",
    "03 TensorFlow Lite开发工作流程_221403.mp4 0.0-18.4s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 18.4-35.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 36.8-49.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 50.8-57.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 58.8-71.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 73.8-81.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 82.8-85.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 86.8-92.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 93.8-98.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 99.8-101.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 102.8-108.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 112.8-124.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 125.8-131.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 132.8-136.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 137.8-141.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 142.8-147.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 151.8-157.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 158.8-164.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 166.8-177.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 179.8-184.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 185.8-189.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 190.8-193.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 194.8-206.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 207.8-216.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 217.8-228.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 229.8-236.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 237.8-244.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 245.8-250.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 252.8-258.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 259.8-267.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 268.8-277.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 278.8-285.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 287.8-289.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 290.8-294.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 295.8-303.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 304.8-306.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 307.8-315.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 316.8-323.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 324.8-327.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 329.8-339.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 340.8-346.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 347.8-355.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 356.8-364.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 365.8-373.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 374.8-387.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 390.8-400.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 400.8-404.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 405.8-411.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 413.8-422.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 423.8-429.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 431.8-441.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 444.8-450.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 451.8-458.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 458.8-463.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 464.8-472.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 473.8-479.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 480.8-486.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 486.8-491.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 492.8-498.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 500.8-507.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 508.8-515.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 517.8-524.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 525.8-531.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 532.8-540.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 541.8-548.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 549.8-558.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 559.8-564.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 565.8-575.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 578.8-584.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 585.8-591.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 592.8-600.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 601.8-614.8s",
    "03 TensorFlow Lite开发工作流程_221403.mp4 614.8-621.8s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 0.0-11.8s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 11.8-15.4s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 15.4-20.4s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 20.4-24.6s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 24.6-28.6s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 28.8-32.4s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 32.4-34.6s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 36.8-40.2s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 40.2-43.8s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 45.0-49.8s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 50.6-55.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 56.0-61.6s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 62.6-66.5s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 66.5-71.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 72.0-76.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 76.0-78.4s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 79.4-83.6s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 84.2-87.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 87.0-90.4s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 91.6-94.8s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 95.4-101.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 102.0-105.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 107.0-109.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 109.2-112.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 112.0-115.8s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 117.0-119.2s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 119.2-123.4s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 125.6-129.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 130.0-134.2s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 135.2-138.6s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 139.8-143.2s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 143.6-146.6s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 150.6-155.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 156.0-159.2s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 159.8-163.2s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 163.6-165.2s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 165.6-167.8s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 169.6-173.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 174.0-176.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 177.0-179.4s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 180.8-183.6s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 186.4-189.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 189.4-190.8s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 191.4-194.8s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 195.6-198.4s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 200.0-202.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 202.0-205.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 205.8-207.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 207.4-209.6s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 210.0-212.2s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 212.6-215.4s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 216.6-221.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 221.2-226.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 226.2-229.2s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 230.0-235.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 237.0-239.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 240.0-241.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 241.0-243.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 243.0-246.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 247.0-249.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 249.0-251.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 252.0-255.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 256.0-260.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 265.0-269.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 270.0-273.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 273.0-277.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 278.0-280.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 283.0-286.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 287.0-290.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 291.0-293.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 294.0-296.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 297.0-300.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 301.0-305.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 305.0-307.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 309.0-312.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 313.0-316.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 317.0-320.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 321.0-324.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 325.0-329.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 330.0-332.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 333.0-335.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 336.0-339.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 340.0-342.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 343.0-345.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 346.0-348.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 349.0-353.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 354.0-355.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 356.0-359.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 359.0-362.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 366.0-369.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 369.0-372.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 373.0-376.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 377.0-379.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 380.0-384.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 385.0-389.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 389.0-392.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 393.0-395.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 395.0-398.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 399.0-401.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 402.0-403.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 404.0-406.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 407.0-410.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 411.0-413.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 414.0-417.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 418.0-422.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 423.0-426.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 427.0-429.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 430.0-433.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 435.0-438.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 439.0-440.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 441.0-443.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 444.0-447.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 448.0-449.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 450.0-451.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 452.0-454.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 455.0-456.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 457.0-459.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 460.0-463.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 465.0-466.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 467.0-470.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 471.0-473.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 474.0-475.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 476.0-478.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 479.0-480.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 481.0-482.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 483.0-485.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 489.0-492.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 495.0-498.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 498.0-501.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 503.0-505.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 507.0-510.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 511.0-512.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 513.0-514.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 515.0-516.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 517.0-519.0s",
    "04 TensorFlow Lite实现花卉识别-1_222124.mp4 520.0-521.0s",
    "1112_222613.mp4 0.0-10.0s",
    "1112_222613.mp4 10.0-16.3s",
    "1112_222613.mp4 16.3-23.0s",
    "1112_222613.mp4 23.0-27.8s",
    "1112_222613.mp4 28.0-35.3s",
    "1112_222613.mp4 35.3-40.1s",
    "1112_222613.mp4 40.1-45.9s",
    "1112_222613.mp4 45.9-49.6s",
    "1112_222613.mp4 49.6-53.4s",
    "1112_222613.mp4 53.4-60.5s",
    "1112_222613.mp4 63.6-69.6s",
    "1112_222613.mp4 69.6-72.8s",
    "1112_222613.mp4 72.8-75.7s",
    "1112_222613.mp4 75.7-78.1s",
    "1112_222613.mp4 78.1-84.4s",
    "1112_222613.mp4 84.4-92.7s",
    "1112_222613.mp4 92.7-98.1s",
    "1112_222613.mp4 98.1-101.6s",
    "1112_222613.mp4 101.6-105.7s",
    "1112_222613.mp4 105.7-109.5s",
    "1112_222613.mp4 109.5-115.2s",
    "1112_222613.mp4 115.2-118.7s",
    "1112_222613.mp4 118.7-123.6s",
    "1112_222613.mp4 123.6-130.7s",
    "1112_222613.mp4 130.7-133.6s",
    "1112_222613.mp4 133.6-138.6s",
    "1112_222613.mp4 138.6-141.3s",
    "1112_222613.mp4 141.3-145.9s",
    "1112_222613.mp4 145.9-149.4s",
    "1112_222613.mp4 149.4-154.6s",
    "1112_222613.mp4 154.6-157.8s",
    "1112_222613.mp4 157.8-163.4s",
    "1112_222613.mp4 163.4-166.4s",
    "1112_222613.mp4 166.4-170.9s",
    "1112_222613.mp4 170.9-172.8s",
    "1112_222613.mp4 172.8-178.0s",
    "1112_222613.mp4 178.0-182.6s",
    "1112_222613.mp4 182.6-185.7s",
    "1112_222613.mp4 185.7-190.7s",
    "1112_222613.mp4 190.7-195.8s",
    "1112_222613.mp4 195.8-201.0s",
    "1112_222613.mp4 201.0-204.9s",
    "1112_222613.mp4 204.9-209.8s",
    "1112_222613.mp4 209.8-214.0s",
    "1112_222613.mp4 214.0-220.7s",
    "1112_222613.mp4 220.7-224.3s",
    "1112_222613.mp4 224.3-227.9s",
    "1112_222613.mp4 227.9-234.8s",
    "1112_222613.mp4 234.8-237.7s",
    "1112_222613.mp4 237.7-244.0s",
    "1112_222613.mp4 244.0-248.2s",
    "1112_222613.mp4 248.2-252.6s",
    "1112_222613.mp4 252.6-256.2s",
    "1112_222613.mp4 256.2-261.0s",
    "1112_222613.mp4 261.0-267.0s",
    "1112_222613.mp4 267.0-273.2s",
    "1112_222613.mp4 273.2-277.4s",
    "1112_222613.mp4 277.4-282.2s",
    "1112_222613.mp4 282.2-287.4s",
    "1112_222613.mp4 287.4-293.1s",
    "1112_222613.mp4 293.1-299.4s",
    "1112_222613.mp4 299.4-303.8s",
    "1112_222613.mp4 303.8-306.6s",
    "1112_222613.mp4 309.8-314.6s",
    "1112_222613.mp4 314.6-322.4s",
    "1112_222613.mp4 322.4-325.1s",
    "1112_222613.mp4 325.1-329.4s",
    "1112_222613.mp4 329.4-332.7s",
    "1112_222613.mp4 332.7-334.6s",
    "1112_222613.mp4 334.6-338.9s",
    "1112_222613.mp4 338.9-344.8s",
    "1112_222613.mp4 344.8-349.8s",
    "1112_222613.mp4 349.8-355.2s",
    "1112_222613.mp4 355.2-359.9s",
    "1112_222613.mp4 359.9-365.1s",
    "1112_222613.mp4 365.1-368.6s",
    "1112_222613.mp4 368.6-373.4s",
    "1112_222613.mp4 373.4-379.1s",
    "1112_222613.mp4 379.1-381.6s",
    "1112_222613.mp4 381.6-387.4s",
    "1112_222613.mp4 387.4-392.9s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 0.0-10.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 10.0-17.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 17.0-25.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 25.0-29.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 30.0-34.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 35.0-38.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 39.0-47.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 49.0-52.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 52.0-56.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 57.0-63.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 63.0-70.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 71.0-76.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 76.0-83.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 84.0-88.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 89.0-94.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 95.0-99.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 99.0-103.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 105.0-111.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 112.0-116.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 116.0-121.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 122.0-126.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 126.0-132.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 132.0-137.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 138.0-142.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 144.0-149.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 149.0-155.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 155.0-159.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 160.0-164.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 164.0-168.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 168.0-174.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 174.0-180.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 180.0-184.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 184.0-188.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 188.0-190.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 190.0-194.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 194.0-198.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 198.0-205.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 205.0-211.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 211.0-217.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 217.0-222.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 222.0-226.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 226.0-228.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 242.0-245.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 246.0-251.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 251.0-253.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 253.0-257.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 257.0-260.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 260.0-263.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 263.0-267.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 268.0-270.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 270.0-275.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 276.0-279.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 279.0-283.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 284.0-288.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 288.0-291.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 390.0-393.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 393.0-395.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 395.0-397.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 397.0-400.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 400.0-403.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 403.0-404.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 404.0-406.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 406.0-409.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 409.0-410.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 410.0-411.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 411.0-412.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 412.0-413.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 413.0-415.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 415.0-417.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 417.0-418.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 418.0-421.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 421.0-423.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 423.0-424.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 424.0-427.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 430.0-434.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 434.0-436.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 436.0-440.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 440.0-442.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 442.0-446.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 449.0-453.0s",
    "upload-1262541090359221833-02 TensorFlow.js框架_170151.mp4 453.0-455.0s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 0.0-13.8s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 13.8-20.4s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 20.4-26.8s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 26.8-30.4s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 30.4-36.0s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 36.0-42.0s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 42.0-48.0s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 48.0-53.3s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 53.3-62.9s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 62.9-67.7s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 67.7-78.8s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 78.8-84.9s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 84.9-91.8s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 91.8-96.6s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 96.6-100.3s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 100.3-105.3s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 105.3-108.7s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 108.7-112.4s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 112.4-117.8s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 117.8-123.4s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 123.4-130.3s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 130.3-134.7s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 134.7-137.2s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 137.2-140.0s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 140.0-144.6s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 144.6-147.4s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 147.4-154.0s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 154.0-157.2s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 157.2-160.3s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 160.3-164.6s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 166.4-170.4s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 171.5-174.7s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 174.7-179.4s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 181.2-184.2s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 184.6-188.6s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 189.4-194.7s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 195.1-199.0s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 199.0-201.8s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 203.0-206.2s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 206.2-209.8s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 211.5-216.8s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 217.2-221.8s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 221.8-224.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 225.6-228.6s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 228.6-230.4s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 231.1-233.4s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 234.4-240.4s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 240.4-243.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 244.5-250.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 251.5-259.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 260.5-263.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 264.5-267.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 267.5-271.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 272.5-276.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 276.5-278.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 279.5-284.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 285.5-288.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 288.5-291.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 291.5-295.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 296.5-300.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 300.5-303.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 307.5-313.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 313.5-319.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 319.5-323.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 323.5-327.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 328.5-330.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 330.5-334.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 335.5-339.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 340.5-346.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 346.5-349.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 349.5-354.5s",
    "upload-5827127634749586247-01 认识TensorFlow.js-1_170810.mp4 354.5-357.5s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 0.0-12.1s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 12.1-14.9s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 14.9-19.4s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 19.4-25.4s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 25.4-29.0s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 29.0-34.0s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 34.0-38.5s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 38.5-42.5s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 42.5-45.8s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 45.8-49.4s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 49.4-54.6s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 54.7-59.3s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 59.3-63.5s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 63.5-68.6s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 68.6-74.2s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 74.2-81.7s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 81.8-89.0s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 89.0-95.1s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 95.1-103.0s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 103.0-106.9s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 106.9-110.3s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 110.4-115.0s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 115.0-120.4s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 120.4-123.6s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 123.6-129.3s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 133.0-139.3s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 139.3-148.7s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 148.7-156.2s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 156.2-161.7s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 161.7-167.8s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 167.8-173.4s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 173.4-177.4s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 177.4-183.9s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 183.9-189.6s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 197.8-205.9s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 205.9-213.1s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 213.1-220.4s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 221.1-227.4s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 227.4-233.7s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 233.7-239.0s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 239.0-244.6s",
    "upload-1017771394655554015-03 TensorFlow.js框架(模型与内存管理）_171842.mp4 244.6-250.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 0.0-9.5s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 9.5-13.8s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 13.8-17.4s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 17.4-21.4s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 21.4-27.0s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 27.5-36.6s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 36.6-40.6s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 40.6-48.0s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 48.0-53.5s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 53.5-57.0s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 57.0-62.4s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 62.4-66.1s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 66.1-78.7s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 78.7-82.4s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 82.4-85.4s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 85.4-88.1s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 88.1-93.6s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 93.6-95.9s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 95.9-99.8s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 99.8-103.4s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 103.4-106.6s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 106.6-110.1s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 110.1-116.8s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 116.8-119.5s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 119.5-124.0s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 124.0-130.1s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 130.1-134.5s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 134.5-137.0s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 141.1-147.3s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 147.3-155.7s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 155.7-160.7s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 160.7-168.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 169.2-178.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 180.2-187.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 187.2-190.6s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 190.6-196.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 197.2-205.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 210.2-214.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 214.2-220.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 220.2-225.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 225.2-227.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 228.2-232.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 233.2-237.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 239.2-241.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 241.2-245.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 245.2-249.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 249.2-254.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 256.2-259.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 259.2-263.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 263.2-269.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 274.2-278.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 278.2-283.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 284.2-286.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 287.2-289.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 290.2-292.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 293.2-295.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 295.2-296.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 296.2-299.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 300.2-304.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 307.2-310.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 310.2-313.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 314.2-318.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 319.2-321.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 321.2-329.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 330.2-335.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 336.2-339.2s",
    "upload-17896897878885126814-04 预测汽车油耗效率-1_173153.mp4 339.2-344.2s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 0.0-21.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 22.4-29.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 30.4-41.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 42.4-54.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 55.4-64.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 64.4-79.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 80.4-88.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 89.4-102.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 103.4-118.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 119.4-129.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 129.4-134.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 134.4-142.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 142.4-149.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 149.4-158.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 159.4-165.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 165.4-171.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 172.4-177.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 178.4-186.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 190.4-198.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 199.4-202.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 203.4-210.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 211.4-220.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 221.4-228.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 229.4-235.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 236.4-245.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 246.4-250.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 253.4-262.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 263.4-267.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 268.4-273.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 273.4-281.4s",
    "upload-2977973880960911101-05 预测汽车油耗效率-2_173944.mp4 282.4-286.4s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 0.0-15.6s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 15.6-25.1s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 25.7-32.7s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 32.7-36.5s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 36.5-42.9s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 42.9-48.7s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 48.7-52.5s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 53.3-62.7s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 62.7-68.7s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 68.7-76.2s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 76.2-84.4s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 84.4-91.5s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 91.5-101.4s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 101.4-107.5s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 107.5-110.4s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 110.4-119.6s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 119.6-122.7s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 122.7-129.0s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 130.0-135.6s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 135.6-140.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 140.8-147.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 147.8-153.4s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 153.4-158.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 159.8-166.2s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 166.2-170.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 171.8-178.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 178.8-185.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 186.8-197.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 197.8-203.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 203.8-208.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 209.8-218.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 221.8-234.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 234.8-245.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 245.8-252.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 252.8-255.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 255.8-265.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 266.8-274.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 274.8-279.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 279.8-284.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 285.8-290.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 291.8-296.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 296.8-304.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 305.8-308.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 309.8-318.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 318.8-325.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 326.8-337.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 338.8-348.8s",
    "upload-17308567376682724494-06 手写数字识别-1_174128.mp4 349.8-357.8s",
    "10.2 qtopia_180857.mp4 0.0-2.0s",
    "10.2 qtopia_180857.mp4 16.0-17.0s",
    "10.2 qtopia_180857.mp4 17.0-20.0s",
    "10.2 qtopia_180857.mp4 20.0-25.0s",
    "10.2 qtopia_180857.mp4 25.0-29.0s",
    "10.2 qtopia_180857.mp4 29.0-32.0s",
    "10.2 qtopia_180857.mp4 32.0-38.0s",
    "10.2 qtopia_180857.mp4 38.0-42.0s",
    "10.2 qtopia_180857.mp4 42.0-47.0s",
    "10.2 qtopia_180857.mp4 47.0-49.0s",
    "10.2 qtopia_180857.mp4 49.0-56.0s",
    "10.2 qtopia_180857.mp4 56.0-60.0s",
    "10.2 qtopia_180857.mp4 60.0-65.0s",
    "10.2 qtopia_180857.mp4 65.0-71.0s",
    "10.2 qtopia_180857.mp4 71.0-73.0s",
    "10.2 qtopia_180857.mp4 73.0-76.0s",
    "10.2 qtopia_180857.mp4 76.0-80.0s",
    "10.2 qtopia_180857.mp4 80.0-83.0s",
    "10.2 qtopia_180857.mp4 83.0-87.0s",
    "10.2 qtopia_180857.mp4 87.0-92.0s",
    "10.2 qtopia_180857.mp4 92.0-94.0s",
    "10.2 qtopia_180857.mp4 94.0-96.0s",
    "10.2 qtopia_180857.mp4 96.0-100.0s",
    "10.2 qtopia_180857.mp4 103.0-108.0s",
    "10.2 qtopia_180857.mp4 108.0-112.0s",
    "10.2 qtopia_180857.mp4 113.0-117.0s",
    "10.2 qtopia_180857.mp4 117.0-120.0s",
    "10.2 qtopia_180857.mp4 120.0-123.0s",
    "10.2 qtopia_180857.mp4 123.0-126.0s",
    "10.2 qtopia_180857.mp4 126.0-130.0s",
    "10.2 qtopia_180857.mp4 130.0-133.0s",
    "10.2 qtopia_180857.mp4 133.0-135.0s",
    "10.2 qtopia_180857.mp4 135.0-138.0s",
    "10.2 qtopia_180857.mp4 138.0-141.0s",
    "10.2 qtopia_180857.mp4 141.0-144.0s",
    "10.2 qtopia_180857.mp4 144.0-149.0s",
    "10.2 qtopia_180857.mp4 149.0-152.0s",
    "10.2 qtopia_180857.mp4 152.0-156.0s",
    "10.2 qtopia_180857.mp4 156.0-160.0s",
    "10.2 qtopia_180857.mp4 160.0-163.0s",
    "10.2 qtopia_180857.mp4 163.0-167.0s",
    "10.2 qtopia_180857.mp4 168.0-172.0s",
    "10.2 qtopia_180857.mp4 172.0-174.0s",
    "10.2 qtopia_180857.mp4 174.0-179.0s",
    "10.2 qtopia_180857.mp4 181.0-183.0s",
    "10.2 qtopia_180857.mp4 183.0-185.0s",
    "10.2 qtopia_180857.mp4 185.0-187.0s",
    "10.2 qtopia_180857.mp4 187.0-192.0s",
    "10.2 qtopia_180857.mp4 193.0-197.0s",
    "10.2 qtopia_180857.mp4 199.0-203.0s",
    "10.2 qtopia_180857.mp4 203.0-205.0s",
    "10.2 qtopia_180857.mp4 205.0-207.0s",
    "10.2 qtopia_180857.mp4 212.0-216.0s",
    "10.2 qtopia_180857.mp4 216.0-220.0s",
    "10.2 qtopia_180857.mp4 222.0-226.0s",
    "10.2 qtopia_180857.mp4 226.0-230.0s",
    "10.2 qtopia_180857.mp4 233.0-234.5s",
    "10.2 qtopia_180857.mp4 239.0-242.0s",
    "10.2 qtopia_180857.mp4 243.0-246.0s",
    "10.2 qtopia_180857.mp4 246.0-249.0s",
    "10.2 qtopia_180857.mp4 249.0-254.0s",
    "10.2 qtopia_180857.mp4 263.0-266.0s",
    "10.2 qtopia_180857.mp4 266.0-271.0s",
    "10.2 qtopia_180857.mp4 296.0-299.0s",
    "10.2 qtopia_180857.mp4 301.0-304.0s",
    "10.2 qtopia_180857.mp4 304.0-308.0s",
    "10.2 qtopia_180857.mp4 308.0-311.0s",
    "10.2 qtopia_180857.mp4 311.0-315.0s",
    "10.2 qtopia_180857.mp4 315.0-318.0s",
    "10.2 qtopia_180857.mp4 319.0-324.0s",
    "10.2 qtopia_180857.mp4 324.0-327.0s",
    "10.2 qtopia_180857.mp4 329.0-335.0s",
    "10.2 qtopia_180857.mp4 335.0-337.0s",
    "10.2 qtopia_180857.mp4 337.0-339.0s",
    "10.2 qtopia_180857.mp4 339.0-341.0s",
    "10.2 qtopia_180857.mp4 341.0-345.0s",
    "10.2 qtopia_180857.mp4 346.0-348.0s",
    "10.2 qtopia_180857.mp4 348.0-350.0s",
    "10.2 qtopia_180857.mp4 350.0-352.0s",
    "10.2 qtopia_180857.mp4 353.0-358.0s",
    "10.2 qtopia_180857.mp4 358.0-362.0s",
    "10.2 qtopia_180857.mp4 362.0-368.0s",
    "10.2 qtopia_180857.mp4 368.0-371.0s",
    "10.2 qtopia_180857.mp4 371.0-376.0s",
    "10.2 qtopia_180857.mp4 376.0-380.0s",
    "10.2 qtopia_180857.mp4 380.0-384.0s",
    "10.2 qtopia_180857.mp4 384.0-389.0s",
    "10.2 qtopia_180857.mp4 393.0-397.0s",
    "10.2 qtopia_180857.mp4 398.0-403.0s",
    "10.2 qtopia_180857.mp4 403.0-406.0s",
    "10.2 qtopia_180857.mp4 428.0-430.0s",
    "10.2 qtopia_180857.mp4 430.0-439.0s",
    "10.2 qtopia_180857.mp4 439.0-445.0s",
    "10.2 qtopia_180857.mp4 445.0-448.0s",
    "10.2 qtopia_180857.mp4 451.0-454.0s",
    "10.2 qtopia_180857.mp4 454.0-457.0s",
    "10.2 qtopia_180857.mp4 473.0-476.0s",
    "10.2 qtopia_180857.mp4 476.0-481.0s",
    "10.2 qtopia_180857.mp4 482.0-486.0s",
    "10.2 qtopia_180857.mp4 486.0-488.0s",
    "10.2 qtopia_180857.mp4 488.0-494.0s",
    "10.2 qtopia_180857.mp4 494.0-500.0s",
    "10.2 qtopia_180857.mp4 501.0-503.0s",
    "10.2 qtopia_180857.mp4 504.0-513.0s",
    "10.2 qtopia_180857.mp4 513.0-517.0s",
    "10.2 qtopia_180857.mp4 517.0-520.0s",
    "10.2 qtopia_180857.mp4 520.0-526.0s",
    "10.2 qtopia_180857.mp4 526.0-530.0s",
    "10.2 qtopia_180857.mp4 531.0-535.0s",
    "10.2 qtopia_180857.mp4 535.0-541.0s",
    "10.2 qtopia_180857.mp4 541.0-549.0s",
    "10.2 qtopia_180857.mp4 549.0-558.0s",
    "10.2 qtopia_180857.mp4 559.0-563.0s",
    "10.2 qtopia_180857.mp4 563.0-567.0s",
    "10.2 qtopia_180857.mp4 568.0-570.0s",
    "10.2 qtopia_180857.mp4 570.0-574.0s",
    "10.2 qtopia_180857.mp4 577.0-579.0s",
    "10.2 qtopia_180857.mp4 579.0-581.0s",
    "10.2 qtopia_180857.mp4 581.0-587.0s",
    "10.2 qtopia_180857.mp4 588.0-593.0s",
    "10.2 qtopia_180857.mp4 593.0-598.0s",
    "10.2 qtopia_180857.mp4 598.0-602.0s",
    "10.2 qtopia_180857.mp4 602.0-604.0s",
    "10.2 qtopia_180857.mp4 604.0-609.0s",
    "10.2 qtopia_180857.mp4 609.0-616.0s",
    "10.2 qtopia_180857.mp4 617.0-621.0s",
    "10.2 qtopia_180857.mp4 621.0-627.0s",
    "10.2 qtopia_180857.mp4 627.0-633.0s",
    "10.2 qtopia_180857.mp4 633.0-639.0s",
    "10.2 qtopia_180857.mp4 639.0-643.0s",
    "10.2 qtopia_180857.mp4 644.0-648.0s",
    "10.2 qtopia_180857.mp4 648.0-653.0s",
    "10.2 qtopia_180857.mp4 653.0-658.0s",
    "10.2 qtopia_180857.mp4 658.0-667.0s",
    "10.2 qtopia_180857.mp4 673.0-680.0s",
    "10.2 qtopia_180857.mp4 680.0-682.0s",
    "10.2 qtopia_180857.mp4 682.0-686.0s",
    "10.2 qtopia_180857.mp4 686.0-690.0s",
    "10.2 qtopia_180857.mp4 690.0-694.0s",
    "10.2 qtopia_180857.mp4 694.0-698.0s",
    "10.2 qtopia_180857.mp4 699.0-705.0s",
    "10.2 qtopia_180857.mp4 705.0-710.0s",
    "10.2 qtopia_180857.mp4 710.0-715.0s",
    "10.2 qtopia_180857.mp4 715.0-718.0s",
    "10.2 qtopia_180857.mp4 718.0-720.0s",
    "10.2 qtopia_180857.mp4 720.0-723.0s",
    "10.2 qtopia_180857.mp4 729.0-735.0s",
    "10.2 qtopia_180857.mp4 744.0-749.0s",
    "10.2 qtopia_180857.mp4 749.0-752.0s",
    "10.2 qtopia_180857.mp4 752.0-757.0s",
    "10.2 qtopia_180857.mp4 758.0-762.0s",
    "10.2 qtopia_180857.mp4 762.0-766.0s",
    "10.2 qtopia_180857.mp4 766.0-770.0s",
    "10.2 qtopia_180857.mp4 770.0-774.0s",
    "10.2 qtopia_180857.mp4 774.0-778.0s",
    "10.2 qtopia_180857.mp4 778.0-782.0s",
    "10.2 qtopia_180857.mp4 782.0-783.0s",
    "10.2 qtopia_180857.mp4 783.0-785.0s",
    "10.2 qtopia_180857.mp4 785.0-790.0s",
    "10.2 qtopia_180857.mp4 790.0-792.0s",
    "10.2 qtopia_180857.mp4 792.0-796.0s",
    "10.2 qtopia_180857.mp4 796.0-798.0s",
    "10.2 qtopia_180857.mp4 798.0-801.0s",
    "10.2 qtopia_180857.mp4 805.0-808.0s",
    "10.2 qtopia_180857.mp4 809.0-812.0s",
    "10.2 qtopia_180857.mp4 826.0-828.0s",
    "10.2 qtopia_180857.mp4 828.0-831.0s",
    "10.2 qtopia_180857.mp4 831.0-835.0s",
    "10.2 qtopia_180857.mp4 835.0-839.0s",
    "10.2 qtopia_180857.mp4 839.0-842.0s",
    "10.2 qtopia_180857.mp4 842.0-843.0s",
    "10.2 qtopia_180857.mp4 843.0-846.0s",
    "10.2 qtopia_180857.mp4 846.0-849.0s",
    "10.2 qtopia_180857.mp4 849.0-855.0s",
    "10.2 qtopia_180857.mp4 855.0-857.0s",
    "10.2 qtopia_180857.mp4 857.0-860.0s",
    "10.2 qtopia_180857.mp4 860.0-863.0s",
    "10.2 qtopia_180857.mp4 863.0-866.0s",
    "10.2 qtopia_180857.mp4 866.0-868.0s",
    "10.2 qtopia_180857.mp4 868.0-870.0s",
    "10.2 qtopia_180857.mp4 870.0-873.0s",
    "10.2 qtopia_180857.mp4 875.0-877.0s",
    "10.2 qtopia_180857.mp4 877.0-879.0s",
    "10.3 qmake_181344.mp4 0.0-26.0s",
    "10.3 qmake_181344.mp4 27.0-39.0s",
    "10.3 qmake_181344.mp4 40.0-52.0s",
    "10.3 qmake_181344.mp4 53.0-60.0s",
    "10.3 qmake_181344.mp4 61.0-72.0s",
    "10.3 qmake_181344.mp4 73.0-79.0s",
    "10.3 qmake_181344.mp4 80.0-95.0s",
    "10.3 qmake_181344.mp4 96.0-108.0s",
    "10.3 qmake_181344.mp4 110.0-114.0s",
    "10.3 qmake_181344.mp4 115.0-125.0s",
    "10.3 qmake_181344.mp4 126.0-146.0s",
    "10.3 qmake_181344.mp4 147.0-158.0s",
    "10.3 qmake_181344.mp4 160.0-173.0s",
    "10.3 qmake_181344.mp4 174.0-180.0s",
    "10.3 qmake_181344.mp4 187.0-191.0s",
    "10.3 qmake_181344.mp4 192.0-203.0s",
    "10.3 qmake_181344.mp4 208.0-213.0s",
    "10.3 qmake_181344.mp4 216.0-219.0s",
    "10.3 qmake_181344.mp4 221.0-224.0s",
    "10.3 qmake_181344.mp4 225.0-231.0s",
    "10.3 qmake_181344.mp4 231.0-238.0s",
    "10.3 qmake_181344.mp4 238.0-245.0s",
    "10.3 qmake_181344.mp4 246.0-249.0s",
    "10.3 qmake_181344.mp4 250.0-254.0s",
    "10.3 qmake_181344.mp4 255.0-258.0s",
    "10.3 qmake_181344.mp4 258.0-260.0s",
    "10.3 qmake_181344.mp4 264.0-269.0s",
    "10.3 qmake_181344.mp4 280.0-292.0s",
    "10.3 qmake_181344.mp4 293.0-298.0s",
    "10.3 qmake_181344.mp4 298.0-308.0s",
    "10.3 qmake_181344.mp4 310.0-313.0s",
    "10.3 qmake_181344.mp4 315.0-318.0s",
    "10.3 qmake_181344.mp4 324.0-330.0s",
    "10.3 qmake_181344.mp4 330.0-336.0s",
    "10.3 qmake_181344.mp4 340.0-347.0s",
    "10.3 qmake_181344.mp4 347.0-351.0s",
    "10.3 qmake_181344.mp4 355.0-359.0s",
    "10.3 qmake_181344.mp4 360.0-364.0s",
    "10.3 qmake_181344.mp4 364.0-368.0s",
    "10.3 qmake_181344.mp4 368.0-374.0s",
    "10.3 qmake_181344.mp4 374.0-385.1s",
    "10.3 qmake_181344.mp4 385.1-390.1s",
    "10.3 qmake_181344.mp4 390.1-397.1s",
    "10.3 qmake_181344.mp4 397.1-404.1s",
    "10.3 qmake_181344.mp4 405.1-410.1s",
    "10.3 qmake_181344.mp4 411.1-415.1s",
    "10.3 qmake_181344.mp4 417.1-421.1s",
    "10.3 qmake_181344.mp4 424.1-430.1s",
    "10.3 qmake_181344.mp4 430.1-437.1s",
    "10.3 qmake_181344.mp4 440.1-444.1s",
    "10.3 qmake_181344.mp4 444.1-447.1s",
    "10.3 qmake_181344.mp4 447.1-452.1s",
    "10.3 qmake_181344.mp4 454.1-460.1s",
    "10.3 qmake_181344.mp4 460.1-465.1s",
    "10.3 qmake_181344.mp4 465.1-467.1s",
    "10.3 qmake_181344.mp4 467.1-474.1s",
    "10.3 qmake_181344.mp4 474.1-478.1s",
    "10.3 qmake_181344.mp4 478.1-482.1s",
    "10.3 qmake_181344.mp4 484.1-489.1s",
    "10.3 qmake_181344.mp4 489.1-492.1s",
    "10.3 qmake_181344.mp4 492.1-496.1s",
    "10.3 qmake_181344.mp4 496.1-500.1s",
    "10.3 qmake_181344.mp4 500.1-503.1s",
    "10.3 qmake_181344.mp4 505.1-509.1s",
    "10.3 qmake_181344.mp4 511.1-514.1s",
    "10.3 qmake_181344.mp4 514.1-517.1s",
    "10.3 qmake_181344.mp4 517.1-520.1s",
    "10.3 qmake_181344.mp4 521.1-524.1s",
    "10.3 qmake_181344.mp4 524.1-529.1s",
    "10.3 qmake_181344.mp4 529.1-533.1s",
    "10.3 qmake_181344.mp4 533.1-536.1s",
    "10.3 qmake_181344.mp4 536.1-539.1s",
    "10.3 qmake_181344.mp4 541.1-546.1s",
    "10.3 qmake_181344.mp4 547.1-550.1s",
    "10.3 qmake_181344.mp4 550.1-551.1s",
    "10.3 qmake_181344.mp4 551.1-553.1s",
    "10.3 qmake_181344.mp4 555.1-559.1s",
    "10.3 qmake_181344.mp4 559.1-561.1s",
    "10.3 qmake_181344.mp4 561.1-562.1s",
    "10.3 qmake_181344.mp4 563.1-566.1s",
    "10.3 qmake_181344.mp4 566.1-569.1s",
    "10.3 qmake_181344.mp4 569.1-572.1s",
    "10.3 qmake_181344.mp4 572.1-574.1s",
    "10.3 qmake_181344.mp4 575.1-577.1s",
    "10.3 qmake_181344.mp4 577.1-580.1s",
    "10.3 qmake_181344.mp4 582.1-585.1s",
    "10.3 qmake_181344.mp4 585.1-588.1s",
    "10.3 qmake_181344.mp4 589.1-591.1s",
    "10.3 qmake_181344.mp4 591.1-593.1s",
    "10.3 qmake_181344.mp4 593.1-596.1s",
    "10.3 qmake_181344.mp4 597.1-599.1s",
    "10.3 qmake_181344.mp4 600.1-602.1s",
    "10.3 qmake_181344.mp4 605.1-608.1s",
    "10.3 qmake_181344.mp4 608.1-610.1s",
    "10.3 qmake_181344.mp4 610.1-612.1s",
    "10.3 qmake_181344.mp4 612.1-614.1s",
    "10.3 qmake_181344.mp4 614.1-616.1s",
    "10.3 qmake_181344.mp4 616.1-620.1s",
    "10.3 qmake_181344.mp4 621.1-623.1s",
    "10.3 qmake_181344.mp4 623.1-626.1s",
    "10.3 qmake_181344.mp4 626.1-628.1s",
    "10.3 qmake_181344.mp4 628.1-630.1s",
    "10.3 qmake_181344.mp4 630.1-633.1s",
    "10.3 qmake_181344.mp4 633.1-635.1s",
    "10.3 qmake_181344.mp4 635.1-637.1s",
    "10.3 qmake_181344.mp4 637.1-640.1s",
    "10.3 qmake_181344.mp4 640.1-642.1s",
    "10.3 qmake_181344.mp4 642.1-643.1s",
    "10.3 qmake_181344.mp4 643.1-644.1s",
    "10.3 qmake_181344.mp4 644.1-646.1s",
    "10.3 qmake_181344.mp4 646.1-648.1s",
    "10.3 qmake_181344.mp4 648.1-650.1s",
    "10.3 qmake_181344.mp4 651.1-653.1s",
    "10.3 qmake_181344.mp4 654.1-657.1s",
    "10.3 qmake_181344.mp4 664.1-669.1s",
    "10.3 qmake_181344.mp4 671.1-674.1s",
    "10.3 qmake_181344.mp4 674.1-676.1s",
    "10.3 qmake_181344.mp4 676.1-679.1s",
    "10.3 qmake_181344.mp4 683.1-686.1s",
    "10.3 qmake_181344.mp4 686.1-688.1s",
    "10.3 qmake_181344.mp4 688.1-690.1s",
    "10.3 qmake_181344.mp4 690.1-692.1s",
    "10.3 qmake_181344.mp4 692.1-694.1s",
    "10.3 qmake_181344.mp4 694.1-695.1s",
    "10.3 qmake_181344.mp4 695.1-697.1s",
    "10.3 qmake_181344.mp4 700.1-702.1s",
    "10.3 qmake_181344.mp4 702.1-704.1s",
    "10.3 qmake_181344.mp4 704.1-706.1s",
    "10.3 qmake_181344.mp4 706.1-708.1s",
    "10.3 qmake_181344.mp4 708.1-709.1s",
    "10.3 qmake_181344.mp4 709.1-711.1s",
    "10.3 qmake_181344.mp4 714.1-715.1s",
    "10.3 qmake_181344.mp4 718.1-720.1s",
    "10.3 qmake_181344.mp4 720.1-722.1s",
    "10.3 qmake_181344.mp4 722.1-724.1s",
    "10.3 qmake_181344.mp4 724.1-726.1s",
    "10.3 qmake_181344.mp4 726.1-727.1s",
    "10.3 qmake_181344.mp4 739.1-741.1s",
    "10.3 qmake_181344.mp4 742.1-745.1s",
    "10.3 qmake_181344.mp4 751.1-755.1s",
    "10.3 qmake_181344.mp4 755.1-757.1s",
    "10.3 qmake_181344.mp4 760.1-762.1s",
    "10.3 qmake_181344.mp4 762.1-764.1s",
    "10.3 qmake_181344.mp4 764.1-766.1s",
    "10.3 qmake_181344.mp4 766.1-768.1s",
    "10.3 qmake_181344.mp4 772.1-774.1s",
    "10.3 qmake_181344.mp4 774.1-776.1s",
    "10.3 qmake_181344.mp4 776.1-779.1s",
    "10.3 qmake_181344.mp4 781.1-783.1s",
    "10.3 qmake_181344.mp4 783.1-785.1s",
    "10.3 qmake_181344.mp4 785.1-786.1s",
    "10.3 qmake_181344.mp4 786.1-789.1s",
    "10.3 qmake_181344.mp4 789.1-790.1s",
    "10.3 qmake_181344.mp4 790.1-792.1s",
    "10.3 qmake_181344.mp4 792.1-795.1s",
    "10.3 qmake_181344.mp4 795.1-797.1s",
    "10.3 qmake_181344.mp4 797.1-799.1s",
    "10.3 qmake_181344.mp4 799.1-800.1s",
    "10.3 qmake_181344.mp4 800.1-802.1s",
    "10.3 qmake_181344.mp4 802.1-804.1s",
    "10.3 qmake_181344.mp4 804.1-806.1s",
    "10.3 qmake_181344.mp4 808.1-809.1s",
    "10.3 qmake_181344.mp4 809.1-811.1s",
    "10.3 qmake_181344.mp4 811.1-813.1s",
    "10.3 qmake_181344.mp4 813.1-815.1s",
    "10.3 qmake_181344.mp4 815.1-817.1s",
    "10.3 qmake_181344.mp4 817.1-818.1s",
    "10.3 qmake_181344.mp4 818.1-819.1s",
    "10.3 qmake_181344.mp4 819.1-821.1s",
    "10.3 qmake_181344.mp4 823.1-824.1s",
    "10.3 qmake_181344.mp4 824.1-825.1s",
    "10.3 qmake_181344.mp4 825.1-826.1s",
    "10.3 qmake_181344.mp4 826.1-827.1s",
    "10.1 qt_181927.mp4 0.0-25.7s",
    "10.1 qt_181927.mp4 26.4-33.8s",
    "10.1 qt_181927.mp4 34.9-49.9s",
    "10.1 qt_181927.mp4 50.9-66.6s",
    "10.1 qt_181927.mp4 66.6-71.9s",
    "10.1 qt_181927.mp4 72.9-83.3s",
    "10.1 qt_181927.mp4 83.3-88.7s",
    "10.1 qt_181927.mp4 88.7-93.1s",
    "10.1 qt_181927.mp4 94.1-106.5s",
    "10.1 qt_181927.mp4 106.5-111.3s",
    "10.1 qt_181927.mp4 111.3-122.3s",
    "10.1 qt_181927.mp4 123.3-128.7s",
    "10.1 qt_181927.mp4 130.7-134.3s",
    "10.1 qt_181927.mp4 135.3-145.9s",
    "10.1 qt_181927.mp4 146.9-156.3s",
    "10.1 qt_181927.mp4 156.3-161.3s",
    "10.1 qt_181927.mp4 161.3-165.9s",
    "10.1 qt_181927.mp4 165.9-173.3s",
    "10.1 qt_181927.mp4 174.3-179.3s",
    "10.1 qt_181927.mp4 180.3-187.7s",
    "10.1 qt_181927.mp4 189.9-197.1s",
    "10.1 qt_181927.mp4 198.1-208.5s",
    "10.1 qt_181927.mp4 209.1-223.5s",
    "10.1 qt_181927.mp4 224.5-232.5s",
    "10.1 qt_181927.mp4 233.5-239.5s",
    "10.1 qt_181927.mp4 242.5-252.9s",
    "10.1 qt_181927.mp4 254.5-259.5s",
    "10.1 qt_181927.mp4 261.5-273.5s",
    "10.1 qt_181927.mp4 274.5-280.5s",
    "10.1 qt_181927.mp4 280.5-283.5s",
    "10.1 qt_181927.mp4 285.5-289.5s",
    "10.1 qt_181927.mp4 290.5-304.5s",
    "10.1 qt_181927.mp4 305.5-314.5s",
    "10.1 qt_181927.mp4 315.5-329.5s",
    "10.1 qt_181927.mp4 330.5-344.5s",
    "10.1 qt_181927.mp4 345.5-354.5s",
    "10.1 qt_181927.mp4 355.5-369.5s",
    "10.1 qt_181927.mp4 370.5-376.5s",
    "10.1 qt_181927.mp4 376.5-391.5s",
    "10.1 qt_181927.mp4 392.5-403.5s",
    "10.1 qt_181927.mp4 403.5-408.5s",
    "10.1 qt_181927.mp4 408.5-423.5s",
    "10.1 qt_181927.mp4 424.5-434.5s",
    "10.1 qt_181927.mp4 434.5-442.5s",
    "10.1 qt_181927.mp4 442.5-449.5s",
    "10.1 qt_181927.mp4 450.5-470.5s",
    "10.1 qt_181927.mp4 470.5-480.5s",
    "10.1 qt_181927.mp4 480.5-486.5s",
    "10.1 qt_181927.mp4 486.5-499.5s",
    "10.1 qt_181927.mp4 499.5-509.5s",
    "10.1 qt_181927.mp4 510.5-528.5s",
    "10.1 qt_181927.mp4 528.5-535.5s",
    "10.1 qt_181927.mp4 536.5-544.5s",
    "10.1 qt_181927.mp4 544.5-549.5s",
    "10.1 qt_181927.mp4 549.5-560.5s",
    "10.1 qt_181927.mp4 561.5-563.5s",
    "10.1 qt_181927.mp4 566.5-577.5s",
    "10.1 qt_181927.mp4 578.5-583.5s",
    "10.1 qt_181927.mp4 584.5-594.5s",
    "10.1 qt_181927.mp4 596.5-600.5s",
    "10.1 qt_181927.mp4 601.5-617.5s",
    "10.1 qt_181927.mp4 617.5-625.5s",
    "10.1 qt_181927.mp4 626.5-630.5s",
    "10.1 qt_181927.mp4 635.5-643.5s",
    "10.1 qt_181927.mp4 644.5-658.5s",
    "10.1 qt_181927.mp4 658.5-667.5s",
    "10.1 qt_181927.mp4 667.5-674.5s",
    "10.1 qt_181927.mp4 674.5-680.5s",
    "10.1 qt_181927.mp4 686.5-695.5s",
    "10.1 qt_181927.mp4 695.5-705.5s",
    "10.1 qt_181927.mp4 705.5-719.5s",
    "10.1 qt_181927.mp4 719.5-723.5s",
    "10.4 hello_182349.mp4 0.0-15.5s",
    "10.4 hello_182349.mp4 15.5-16.5s",
    "10.4 hello_182349.mp4 16.5-19.0s",
    "10.4 hello_182349.mp4 19.0-22.0s",
    "10.4 hello_182349.mp4 22.0-25.5s",
    "10.4 hello_182349.mp4 25.5-29.3s",
    "10.4 hello_182349.mp4 29.3-31.3s",
    "10.4 hello_182349.mp4 31.3-35.8s",
    "10.4 hello_182349.mp4 35.8-39.8s",
    "10.4 hello_182349.mp4 39.8-42.3s",
    "10.4 hello_182349.mp4 42.3-46.3s",
    "10.4 hello_182349.mp4 46.3-49.6s",
    "10.4 hello_182349.mp4 49.6-56.1s",
    "10.4 hello_182349.mp4 56.1-59.1s",
    "10.4 hello_182349.mp4 59.1-62.1s",
    "10.4 hello_182349.mp4 62.1-64.1s",
    "10.4 hello_182349.mp4 64.1-66.1s",
    "10.4 hello_182349.mp4 66.1-68.1s",
    "10.4 hello_182349.mp4 68.1-71.1s",
    "10.4 hello_182349.mp4 71.1-74.1s",
    "10.4 hello_182349.mp4 74.1-77.1s",
    "10.4 hello_182349.mp4 77.1-81.1s",
    "10.4 hello_182349.mp4 81.1-85.1s",
    "10.4 hello_182349.mp4 85.1-87.1s",
    "10.4 hello_182349.mp4 89.1-93.1s",
    "10.4 hello_182349.mp4 93.1-99.1s",
    "10.4 hello_182349.mp4 108.1-113.1s",
    "10.4 hello_182349.mp4 115.1-119.1s",
    "10.4 hello_182349.mp4 119.1-123.1s",
    "10.4 hello_182349.mp4 131.1-131.5s",
    "10.4 hello_182349.mp4 132.5-135.5s",
    "10.4 hello_182349.mp4 137.5-139.5s",
    "10.4 hello_182349.mp4 140.5-144.0s",
    "10.4 hello_182349.mp4 144.0-173.9s",
    "10.4 hello_182349.mp4 173.9-180.9s",
    "10.4 hello_182349.mp4 181.5-185.3s",
    "10.4 hello_182349.mp4 185.3-190.4s",
    "10.4 hello_182349.mp4 270.9-282.5s",
    "10.4 hello_182349.mp4 282.5-288.9s",
    "10.4 hello_182349.mp4 288.9-294.5s",
    "10.4 hello_182349.mp4 294.5-298.8s",
    "10.4 hello_182349.mp4 298.8-300.8s",
    "10.4 hello_182349.mp4 300.8-304.8s",
    "10.4 hello_182349.mp4 304.8-308.3s",
    "10.4 hello_182349.mp4 308.3-309.8s",
    "10.4 hello_182349.mp4 309.8-315.3s",
    "10.4 hello_182349.mp4 315.3-320.3s",
    "10.4 hello_182349.mp4 320.3-322.5s",
    "10.4 hello_182349.mp4 322.5-325.3s",
    "10.4 hello_182349.mp4 325.5-330.3s",
    "10.4 hello_182349.mp4 330.3-331.3s",
    "10.4 hello_182349.mp4 337.0-339.0s",
    "10.4 hello_182349.mp4 339.0-345.1s",
    "10.4 hello_182349.mp4 345.1-349.9s",
    "10.4 hello_182349.mp4 350.9-355.9s",
    "10.4 hello_182349.mp4 355.9-359.9s",
    "10.4 hello_182349.mp4 359.9-362.9s",
    "10.4 hello_182349.mp4 368.9-371.9s",
    "10.4 hello_182349.mp4 380.9-384.9s",
    "10.4 hello_182349.mp4 384.9-389.9s",
    "10.4 hello_182349.mp4 389.9-393.9s",
    "10.4 hello_182349.mp4 399.9-403.9s",
    "10.4 hello_182349.mp4 403.9-407.9s",
    "10.4 hello_182349.mp4 408.9-413.9s",
    "10.4 hello_182349.mp4 413.9-441.9s",
    "10.4 hello_182349.mp4 442.9-447.9s",
    "10.4 hello_182349.mp4 447.9-450.9s",
    "10.4 hello_182349.mp4 450.9-453.9s",
    "10.4 hello_182349.mp4 465.9-467.9s",
    "10.4 hello_182349.mp4 468.9-473.9s",
    "10.4 hello_182349.mp4 473.9-481.9s",
    "10.4 hello_182349.mp4 484.9-489.9s",
    "10.4 hello_182349.mp4 489.9-493.9s",
    "10.4 hello_182349.mp4 498.9-503.9s",
    "10.4 hello_182349.mp4 503.9-506.9s",
    "10.4 hello_182349.mp4 506.9-511.9s",
    "10.4 hello_182349.mp4 511.9-512.9s",
    "10.4 hello_182349.mp4 512.9-517.9s",
    "10.4 hello_182349.mp4 517.9-523.9s",
    "10.4 hello_182349.mp4 523.9-526.9s",
    "10.4 hello_182349.mp4 532.9-538.9s",
    "10.4 hello_182349.mp4 538.9-540.9s",
    "10.4 hello_182349.mp4 545.9-547.9s",
    "10.4 hello_182349.mp4 548.9-551.9s",
    "10.4 hello_182349.mp4 552.9-554.9s",
    "10.4 hello_182349.mp4 554.9-556.9s",
    "10.4 hello_182349.mp4 557.9-561.9s",
    "10.4 hello_182349.mp4 572.9-575.9s",
    "10.4 hello_182349.mp4 576.9-579.9s",
    "10.4 hello_182349.mp4 579.9-581.9s",
    "10.4 hello_182349.mp4 583.9-585.9s",
    "10.4 hello_182349.mp4 585.9-587.9s",
    "10.4 hello_182349.mp4 599.9-603.9s",
    "10.4 hello_182349.mp4 603.9-606.9s",
    "10.4 hello_182349.mp4 606.9-608.9s",
    "10.4 hello_182349.mp4 608.9-610.9s",
    "10.4 hello_182349.mp4 612.9-614.9s",
    "10.4 hello_182349.mp4 617.9-619.9s",
    "10.4 hello_182349.mp4 619.9-621.9s",
    "10.4 hello_182349.mp4 621.9-625.9s",
    "10.4 hello_182349.mp4 625.9-627.9s",
    "10.4 hello_182349.mp4 629.9-631.9s",
    "10.4 hello_182349.mp4 631.9-634.9s",
    "10.4 hello_182349.mp4 634.9-636.9s",
    "10.4 hello_182349.mp4 636.9-638.9s",
    "10.4 hello_182349.mp4 638.9-641.9s",
    "10.4 hello_182349.mp4 641.9-643.9s",
    "10.4 hello_182349.mp4 643.9-645.9s",
    "10.4 hello_182349.mp4 645.9-649.9s",
    "10.4 hello_182349.mp4 649.9-652.9s",
    "10.4 hello_182349.mp4 652.9-656.9s",
    "10.4 hello_182349.mp4 656.9-658.9s",
    "10.4 hello_182349.mp4 658.9-660.9s",
    "10.4 hello_182349.mp4 660.9-662.9s",
    "10.4 hello_182349.mp4 662.9-663.9s",
    "10.4 hello_182349.mp4 663.9-665.9s",
    "10.4 hello_182349.mp4 665.9-668.9s",
    "10.4 hello_182349.mp4 668.9-671.9s",
    "10.4 hello_182349.mp4 671.9-673.9s",
    "10.4 hello_182349.mp4 673.9-676.9s",
    "10.4 hello_182349.mp4 676.9-680.9s",
    "10.4 hello_182349.mp4 680.9-684.9s",
    "10.4 hello_182349.mp4 684.9-686.9s",
    "10.4 hello_182349.mp4 688.9-689.9s",
    "10.4 hello_182349.mp4 690.9-698.9s",
    "10.4 hello_182349.mp4 698.9-701.9s",
    "10.4 hello_182349.mp4 701.9-704.9s",
    "10.4 hello_182349.mp4 704.9-708.9s",
    "10.4 hello_182349.mp4 708.9-710.9s",
    "10.4 hello_182349.mp4 710.9-713.9s",
    "10.4 hello_182349.mp4 713.9-715.9s",
    "10.4 hello_182349.mp4 715.9-718.9s",
    "10.4 hello_182349.mp4 718.9-721.9s",
    "10.4 hello_182349.mp4 721.9-723.9s",
    "10.4 hello_182349.mp4 727.9-729.9s",
    "10.4 hello_182349.mp4 729.9-732.9s",
    "10.4 hello_182349.mp4 732.9-735.9s",
    "10.4 hello_182349.mp4 735.9-738.9s",
    "10.4 hello_182349.mp4 738.9-743.9s",
    "10.4 hello_182349.mp4 745.9-747.9s",
    "10.4 hello_182349.mp4 747.9-750.9s",
    "10.4 hello_182349.mp4 752.9-753.9s",
    "10.4 hello_182349.mp4 756.9-760.9s",
    "10.4 hello_182349.mp4 760.9-762.9s",
    "10.4 hello_182349.mp4 765.9-768.9s",
    "10.4 hello_182349.mp4 769.9-771.9s",
    "10.4 hello_182349.mp4 778.9-780.9s",
    "10.4 hello_182349.mp4 780.9-783.9s",
    "10.4 hello_182349.mp4 787.9-792.9s",
    "10.4 hello_182349.mp4 792.9-797.9s",
    "10.4 hello_182349.mp4 797.9-802.9s",
    "10.4 hello_182349.mp4 802.9-804.9s",
    "10.4 hello_182349.mp4 805.9-807.9s",
    "10.4 hello_182349.mp4 807.9-812.9s",
    "10.4 hello_182349.mp4 812.9-816.9s",
    "10.4 hello_182349.mp4 819.9-823.9s",
    "10.4 hello_182349.mp4 823.9-824.9s",
    "10.4 hello_182349.mp4 824.9-828.9s",
    "10.4 hello_182349.mp4 831.9-833.9s",
    "10.4 hello_182349.mp4 833.9-836.9s",
    "10.4 hello_182349.mp4 836.9-840.9s",
    "10.4 hello_182349.mp4 840.9-848.9s",
    "10.4 hello_182349.mp4 850.9-855.9s",
    "10.4 hello_182349.mp4 855.9-860.9s",
    "10.4 hello_182349.mp4 860.9-863.9s",
    "10.4 hello_182349.mp4 863.9-866.9s",
    "10.4 hello_182349.mp4 868.9-871.9s",
    "10.5 singal_182823.mp4 0.0-16.0s",
    "10.5 singal_182823.mp4 16.0-17.3s",
    "10.5 singal_182823.mp4 17.3-21.6s",
    "10.5 singal_182823.mp4 21.6-23.7s",
    "10.5 singal_182823.mp4 23.7-27.8s",
    "10.5 singal_182823.mp4 27.8-30.8s",
    "10.5 singal_182823.mp4 30.8-36.1s",
    "10.5 singal_182823.mp4 36.1-41.3s",
    "10.5 singal_182823.mp4 41.3-44.4s",
    "10.5 singal_182823.mp4 44.4-51.4s",
    "10.5 singal_182823.mp4 51.4-54.1s",
    "10.5 singal_182823.mp4 54.1-57.2s",
    "10.5 singal_182823.mp4 57.2-63.1s",
    "10.5 singal_182823.mp4 63.1-65.9s",
    "10.5 singal_182823.mp4 65.9-68.7s",
    "10.5 singal_182823.mp4 68.7-71.2s",
    "10.5 singal_182823.mp4 71.2-75.5s",
    "10.5 singal_182823.mp4 75.5-77.9s",
    "10.5 singal_182823.mp4 77.9-79.8s",
    "10.5 singal_182823.mp4 79.8-85.3s",
    "10.5 singal_182823.mp4 85.3-86.6s",
    "10.5 singal_182823.mp4 86.6-91.4s",
    "10.5 singal_182823.mp4 91.4-94.0s",
    "10.5 singal_182823.mp4 94.0-103.3s",
    "10.5 singal_182823.mp4 103.3-105.9s",
    "10.5 singal_182823.mp4 105.9-112.8s",
    "10.5 singal_182823.mp4 112.9-115.6s",
    "10.5 singal_182823.mp4 115.6-118.3s",
    "10.5 singal_182823.mp4 118.3-120.6s",
    "10.5 singal_182823.mp4 120.6-123.6s",
    "10.5 singal_182823.mp4 123.6-128.1s",
    "10.5 singal_182823.mp4 128.1-131.7s",
    "10.5 singal_182823.mp4 131.7-134.1s",
    "10.5 singal_182823.mp4 134.1-136.9s",
    "10.5 singal_182823.mp4 136.9-141.2s",
    "10.5 singal_182823.mp4 141.3-142.4s",
    "10.5 singal_182823.mp4 142.4-146.1s",
    "10.5 singal_182823.mp4 146.1-150.8s",
    "10.5 singal_182823.mp4 150.8-153.6s",
    "10.5 singal_182823.mp4 153.6-157.1s",
    "10.5 singal_182823.mp4 157.1-159.6s",
    "10.5 singal_182823.mp4 159.6-165.4s",
    "10.5 singal_182823.mp4 165.4-168.4s",
    "10.5 singal_182823.mp4 168.4-171.7s",
    "10.5 singal_182823.mp4 171.7-176.0s",
    "10.5 singal_182823.mp4 176.0-177.5s",
    "10.5 singal_182823.mp4 177.5-181.7s",
    "10.5 singal_182823.mp4 181.7-185.0s",
    "10.5 singal_182823.mp4 185.0-189.6s",
    "10.5 singal_182823.mp4 189.6-192.2s",
    "10.5 singal_182823.mp4 192.2-197.8s",
    "10.5 singal_182823.mp4 197.9-200.7s",
    "10.5 singal_182823.mp4 207.9-209.2s",
    "10.5 singal_182823.mp4 209.2-211.4s",
    "10.5 singal_182823.mp4 212.6-214.2s",
    "10.5 singal_182823.mp4 214.2-216.0s",
    "10.5 singal_182823.mp4 216.7-219.5s",
    "10.5 singal_182823.mp4 223.8-226.8s",
    "10.5 singal_182823.mp4 226.9-230.2s",
    "10.5 singal_182823.mp4 231.2-235.5s",
    "10.5 singal_182823.mp4 235.5-238.0s",
    "10.5 singal_182823.mp4 239.6-241.2s",
    "10.5 singal_182823.mp4 241.2-243.4s",
    "10.5 singal_182823.mp4 245.7-248.2s",
    "10.5 singal_182823.mp4 248.2-250.0s",
    "10.5 singal_182823.mp4 250.5-252.9s",
    "10.5 singal_182823.mp4 253.4-256.0s",
    "10.5 singal_182823.mp4 256.2-261.7s",
    "10.5 singal_182823.mp4 262.2-266.5s",
    "10.5 singal_182823.mp4 267.9-271.6s",
    "10.5 singal_182823.mp4 271.8-272.9s",
    "10.5 singal_182823.mp4 273.3-275.6s",
    "10.5 singal_182823.mp4 275.8-278.6s",
    "10.5 singal_182823.mp4 278.8-282.6s",
    "10.5 singal_182823.mp4 283.6-286.1s",
    "10.5 singal_182823.mp4 286.6-289.1s",
    "10.5 singal_182823.mp4 289.6-293.3s",
    "10.5 singal_182823.mp4 295.3-297.3s",
    "10.5 singal_182823.mp4 297.3-298.4s",
    "10.5 singal_182823.mp4 298.9-300.7s",
    "10.5 singal_182823.mp4 300.9-303.0s",
    "10.5 singal_182823.mp4 303.0-306.3s",
    "10.5 singal_182823.mp4 308.9-311.2s",
    "10.5 singal_182823.mp4 311.6-315.6s",
    "10.5 singal_182823.mp4 315.8-319.2s",
    "10.5 singal_182823.mp4 319.6-321.6s",
    "10.5 singal_182823.mp4 328.0-331.2s",
    "10.5 singal_182823.mp4 331.9-333.7s",
    "10.5 singal_182823.mp4 334.2-338.4s",
    "10.5 singal_182823.mp4 338.8-343.2s",
    "10.5 singal_182823.mp4 343.4-346.8s",
    "10.5 singal_182823.mp4 347.2-350.6s",
    "10.5 singal_182823.mp4 352.8-355.2s",
    "10.5 singal_182823.mp4 355.4-359.0s",
    "10.5 singal_182823.mp4 359.0-361.8s",
    "10.5 singal_182823.mp4 361.8-364.0s",
    "10.5 singal_182823.mp4 365.0-370.0s",
    "10.5 singal_182823.mp4 371.0-373.0s",
    "10.5 singal_182823.mp4 395.0-399.0s",
    "10.5 singal_182823.mp4 402.0-404.0s",
    "10.5 singal_182823.mp4 410.0-414.0s",
    "10.5 singal_182823.mp4 415.0-417.0s",
    "10.5 singal_182823.mp4 424.0-429.0s",
    "10.5 singal_182823.mp4 429.0-431.0s",
    "10.5 singal_182823.mp4 431.0-433.0s",
    "10.5 singal_182823.mp4 433.0-435.0s",
    "10.5 singal_182823.mp4 435.0-439.0s",
    "10.5 singal_182823.mp4 450.0-452.0s",
    "10.5 singal_182823.mp4 452.0-454.0s",
    "10.5 singal_182823.mp4 454.0-457.0s",
    "10.5 singal_182823.mp4 457.0-460.0s",
    "10.5 singal_182823.mp4 461.0-465.0s",
    "10.5 singal_182823.mp4 466.0-468.0s",
    "10.5 singal_182823.mp4 468.0-472.0s",
    "10.5 singal_182823.mp4 472.0-476.0s",
    "10.5 singal_182823.mp4 476.0-480.0s",
    "10.5 singal_182823.mp4 480.0-485.0s",
    "10.5 singal_182823.mp4 485.0-487.0s",
    "10.5 singal_182823.mp4 487.0-489.0s",
    "10.5 singal_182823.mp4 489.0-494.0s",
    "10.5 singal_182823.mp4 494.0-497.0s",
    "10.5 singal_182823.mp4 497.0-501.0s",
    "10.5 singal_182823.mp4 502.0-507.0s",
    "10.5 singal_182823.mp4 510.0-513.0s",
    "10.5 singal_182823.mp4 517.0-520.0s",
    "10.5 singal_182823.mp4 522.0-526.0s",
    "10.5 singal_182823.mp4 526.0-529.0s",
    "10.5 singal_182823.mp4 532.0-535.0s",
    "10.5 singal_182823.mp4 535.0-536.0s",
    "10.5 singal_182823.mp4 536.0-544.0s",
    "10.5 singal_182823.mp4 544.0-546.0s",
    "10.5 singal_182823.mp4 564.0-568.0s",
    "10.5 singal_182823.mp4 568.0-573.0s",
    "10.5 singal_182823.mp4 573.0-578.0s",
    "10.5 singal_182823.mp4 578.0-584.0s",
    "10.5 singal_182823.mp4 584.0-594.0s",
    "10.5 singal_182823.mp4 594.0-598.0s",
    "10.5 singal_182823.mp4 598.0-600.0s",
    "10.5 singal_182823.mp4 600.0-602.0s",
    "10.5 singal_182823.mp4 602.0-607.0s",
    "10.5 singal_182823.mp4 607.0-611.0s",
    "10.5 singal_182823.mp4 611.0-613.0s",
    "10.5 singal_182823.mp4 613.0-614.0s",
    "10.5 singal_182823.mp4 614.0-616.0s",
    "10.5 singal_182823.mp4 618.0-621.0s",
    "10.5 singal_182823.mp4 624.0-634.0s",
    "10.5 singal_182823.mp4 634.0-635.0s",
    "10.5 singal_182823.mp4 648.5-649.5s",
    "10.5 singal_182823.mp4 659.6-660.6s",
    "10.5 singal_182823.mp4 661.6-664.2s",
    "10.5 singal_182823.mp4 669.0-670.2s",
    "10.5 singal_182823.mp4 670.2-675.2s",
    "10.5 singal_182823.mp4 675.2-682.0s",
    "10.5 singal_182823.mp4 682.5-685.8s",
    "10.5 singal_182823.mp4 685.8-690.2s",
    "10.5 singal_182823.mp4 690.6-698.6s",
    "10.5 singal_182823.mp4 702.6-705.6s",
    "10.5 singal_182823.mp4 705.6-706.6s",
    "10.5 singal_182823.mp4 708.6-710.6s",
    "10.5 singal_182823.mp4 711.6-713.6s",
    "10.5 singal_182823.mp4 714.6-723.6s",
    "10.5 singal_182823.mp4 730.6-734.6s",
    "10.5 singal_182823.mp4 734.6-739.6s",
    "10.5 singal_182823.mp4 739.6-741.6s",
    "10.5 singal_182823.mp4 743.6-746.6s",
    "10.5 singal_182823.mp4 774.6-783.6s",
    "10.5 singal_182823.mp4 783.6-786.6s",
    "10.5 singal_182823.mp4 786.6-789.6s",
    "10.5 singal_182823.mp4 796.6-799.6s",
    "10.5 singal_182823.mp4 804.6-806.6s",
    "10.5 singal_182823.mp4 806.6-808.6s",
    "10.5 singal_182823.mp4 808.6-811.6s",
    "10.5 singal_182823.mp4 812.6-815.6s",
    "10.5 singal_182823.mp4 815.6-819.6s",
    "10.5 singal_182823.mp4 819.6-822.6s",
    "10.5 singal_182823.mp4 822.6-825.6s",
    "10.5 singal_182823.mp4 825.6-828.6s",
    "10.5 singal_182823.mp4 828.6-832.6s",
    "10.5 singal_182823.mp4 833.6-836.6s",
    "10.5 singal_182823.mp4 836.6-839.6s",
    "10.5 singal_182823.mp4 839.6-842.6s",
    "10.5 singal_182823.mp4 843.6-846.6s",
    "10.5 singal_182823.mp4 847.6-849.6s",
    "10.5 singal_182823.mp4 851.6-855.6s",
    "10.5 singal_182823.mp4 855.6-859.6s",
    "10.5 singal_182823.mp4 859.6-861.6s",
    "10.5 singal_182823.mp4 864.6-866.6s",
    "10.5 singal_182823.mp4 866.6-869.6s",
    "10.5 singal_182823.mp4 873.6-875.6s",
    "10.5 singal_182823.mp4 880.6-882.6s",
    "10.5 singal_182823.mp4 882.6-885.6s",
    "10.5 singal_182823.mp4 887.6-891.6s",
    "10.5 singal_182823.mp4 893.6-897.6s",
    "10.5 singal_182823.mp4 897.6-900.6s",
    "10.5 singal_182823.mp4 900.6-904.6s",
    "10.5 singal_182823.mp4 904.6-907.6s",
    "10.5 singal_182823.mp4 907.6-908.6s",
    "10.5 singal_182823.mp4 908.6-912.6s",
    "10.5 singal_182823.mp4 919.6-922.6s",
    "10.5 singal_182823.mp4 923.6-927.6s",
    "10.5 singal_182823.mp4 927.6-929.6s",
    "10.5 singal_182823.mp4 929.6-933.6s",
    "10.5 singal_182823.mp4 933.6-935.6s",
    "10.5 singal_182823.mp4 935.6-937.6s",
    "10.5 singal_182823.mp4 938.6-940.6s",
    "10.5 singal_182823.mp4 940.6-941.6s",
    "01 认识TensorFlow.js-1_162707.mp4 0.0-13.8s",
    "01 认识TensorFlow.js-1_162707.mp4 13.8-20.4s",
    "01 认识TensorFlow.js-1_162707.mp4 20.4-26.8s",
    "01 认识TensorFlow.js-1_162707.mp4 26.8-30.4s",
    "01 认识TensorFlow.js-1_162707.mp4 30.4-36.0s",
    "01 认识TensorFlow.js-1_162707.mp4 36.0-42.0s",
    "01 认识TensorFlow.js-1_162707.mp4 42.0-48.0s",
    "01 认识TensorFlow.js-1_162707.mp4 48.0-53.3s",
    "01 认识TensorFlow.js-1_162707.mp4 53.3-62.9s",
    "01 认识TensorFlow.js-1_162707.mp4 62.9-67.7s",
    "01 认识TensorFlow.js-1_162707.mp4 67.7-78.8s",
    "01 认识TensorFlow.js-1_162707.mp4 78.8-84.9s",
    "01 认识TensorFlow.js-1_162707.mp4 84.9-91.8s",
    "01 认识TensorFlow.js-1_162707.mp4 91.8-96.6s",
    "01 认识TensorFlow.js-1_162707.mp4 96.6-100.3s",
    "01 认识TensorFlow.js-1_162707.mp4 100.3-105.3s",
    "01 认识TensorFlow.js-1_162707.mp4 105.3-108.7s",
    "01 认识TensorFlow.js-1_162707.mp4 108.7-112.4s",
    "01 认识TensorFlow.js-1_162707.mp4 112.4-117.8s",
    "01 认识TensorFlow.js-1_162707.mp4 117.8-123.4s",
    "01 认识TensorFlow.js-1_162707.mp4 123.4-130.3s",
    "01 认识TensorFlow.js-1_162707.mp4 130.3-134.7s",
    "01 认识TensorFlow.js-1_162707.mp4 134.7-137.2s",
    "01 认识TensorFlow.js-1_162707.mp4 137.2-140.0s",
    "01 认识TensorFlow.js-1_162707.mp4 140.0-144.6s",
    "01 认识TensorFlow.js-1_162707.mp4 144.6-147.4s",
    "01 认识TensorFlow.js-1_162707.mp4 147.4-154.0s",
    "01 认识TensorFlow.js-1_162707.mp4 154.0-157.2s",
    "01 认识TensorFlow.js-1_162707.mp4 157.2-160.3s",
    "01 认识TensorFlow.js-1_162707.mp4 160.3-164.6s",
    "01 认识TensorFlow.js-1_162707.mp4 166.4-170.4s",
    "01 认识TensorFlow.js-1_162707.mp4 171.5-174.7s",
    "01 认识TensorFlow.js-1_162707.mp4 174.7-179.4s",
    "01 认识TensorFlow.js-1_162707.mp4 181.2-184.2s",
    "01 认识TensorFlow.js-1_162707.mp4 184.6-188.6s",
    "01 认识TensorFlow.js-1_162707.mp4 189.4-194.7s",
    "01 认识TensorFlow.js-1_162707.mp4 195.1-199.0s",
    "01 认识TensorFlow.js-1_162707.mp4 199.0-201.8s",
    "01 认识TensorFlow.js-1_162707.mp4 203.0-206.2s",
    "01 认识TensorFlow.js-1_162707.mp4 206.2-209.8s",
    "01 认识TensorFlow.js-1_162707.mp4 211.5-216.8s",
    "01 认识TensorFlow.js-1_162707.mp4 217.2-221.8s",
    "01 认识TensorFlow.js-1_162707.mp4 221.8-224.5s",
    "01 认识TensorFlow.js-1_162707.mp4 225.6-228.6s",
    "01 认识TensorFlow.js-1_162707.mp4 228.6-230.4s",
    "01 认识TensorFlow.js-1_162707.mp4 231.1-233.4s",
    "01 认识TensorFlow.js-1_162707.mp4 234.4-240.4s",
    "01 认识TensorFlow.js-1_162707.mp4 240.4-243.5s",
    "01 认识TensorFlow.js-1_162707.mp4 244.5-250.5s",
    "01 认识TensorFlow.js-1_162707.mp4 251.5-259.5s",
    "01 认识TensorFlow.js-1_162707.mp4 260.5-263.5s",
    "01 认识TensorFlow.js-1_162707.mp4 264.5-267.5s",
    "01 认识TensorFlow.js-1_162707.mp4 267.5-271.5s",
    "01 认识TensorFlow.js-1_162707.mp4 272.5-276.5s",
    "01 认识TensorFlow.js-1_162707.mp4 276.5-278.5s",
    "01 认识TensorFlow.js-1_162707.mp4 279.5-284.5s",
    "01 认识TensorFlow.js-1_162707.mp4 285.5-288.5s",
    "01 认识TensorFlow.js-1_162707.mp4 288.5-291.5s",
    "01 认识TensorFlow.js-1_162707.mp4 291.5-295.5s",
    "01 认识TensorFlow.js-1_162707.mp4 296.5-300.5s",
    "01 认识TensorFlow.js-1_162707.mp4 300.5-303.5s",
    "01 认识TensorFlow.js-1_162707.mp4 307.5-313.5s",
    "01 认识TensorFlow.js-1_162707.mp4 313.5-319.5s",
    "01 认识TensorFlow.js-1_162707.mp4 319.5-323.5s",
    "01 认识TensorFlow.js-1_162707.mp4 323.5-327.5s",
    "01 认识TensorFlow.js-1_162707.mp4 328.5-330.5s",
    "01 认识TensorFlow.js-1_162707.mp4 330.5-334.5s",
    "01 认识TensorFlow.js-1_162707.mp4 335.5-339.5s",
    "01 认识TensorFlow.js-1_162707.mp4 340.5-346.5s",
    "01 认识TensorFlow.js-1_162707.mp4 346.5-349.5s",
    "01 认识TensorFlow.js-1_162707.mp4 349.5-354.5s",
    "01 认识TensorFlow.js-1_162707.mp4 354.5-357.5s",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第8段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第9段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第11段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第12段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第13段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第14段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第15段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第16段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第20段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第21段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第22段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第23段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第24段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第25段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第26段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第27段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第28段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第29段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第30段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第31段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第32段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第33段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第34段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第35段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第36段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第37段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第38段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第39段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第40段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第41段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第42段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第43段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第44段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第45段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第46段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第47段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第48段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第49段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第50段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第51段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第52段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第53段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第54段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第55段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第56段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第57段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第58段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第59段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第60段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第61段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第62段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第63段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第64段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第65段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第66段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第67段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第68段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第69段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第70段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第71段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第72段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第73段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第74段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第75段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第88段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第106段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第108段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第109段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第110段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第111段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第113段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第114段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第115段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第116段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第117段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第118段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第119段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第121段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第122段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第123段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第125段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第126段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第127段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第128段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第129段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第130段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第131段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第132段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第133段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第134段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第135段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第136段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第137段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第138段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第139段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第140段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第141段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第142段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第143段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第144段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第145段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第146段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第148段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第154段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第155段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第161段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第164段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第165段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第166段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第167段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第168段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第170段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第171段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第172段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第173段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第174段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第175段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第177段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第178段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第179段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第183段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第184段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第188段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第189段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第190段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第191段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第192段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第193段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第194段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第195段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第196段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第197段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第198段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第199段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第200段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第201段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第202段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第204段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第205段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第206段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第207段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第208段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第209段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第210段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第211段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第213段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第214段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第215段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第216段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第217段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第218段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第219段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第220段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第221段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第222段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第228段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第230段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第231段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第232段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第233段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第234段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第235段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第236段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第237段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第238段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第239段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第240段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第241段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第242段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第243段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第244段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第245段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第246段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第247段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第249段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第250段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第251段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第252段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第253段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第254段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第255段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第256段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第257段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第258段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第259段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 第260段",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 表格1",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 表格1",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 表格1",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 表格1",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 表格1",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 表格1",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 表格1",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 表格1",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 表格1",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 表格1",
    "upload-6205368425486093403-23371112-彭思奇-2025年 “社会实践”报告_172413.docx 表格1",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第1段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第2段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第3段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第4段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第5段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第6段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第7段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第8段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第9段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第10段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第11段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第12段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第13段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第14段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第15段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第16段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第17段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第18段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第19段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第20段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第21段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第22段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第23段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第24段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第25段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第26段",
    "upload-155483731672042548-成绩排名数据_174920.jpg 第27段"
  ]
}